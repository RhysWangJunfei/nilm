{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nilm_rnn_cwe.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RhysWangJunfei/nilm/blob/master/nilm_rnn_cwe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "S85I81geO2wa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import io\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split \n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7a4nAW57PDP_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''Sliding window function'''\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX = []\n",
        "    for i in range(len(dataset)-look_back+1):\n",
        "        a = dataset[i:(i+look_back)]\n",
        "        dataX.append(a)\n",
        "    return np.array(dataX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fDv8Gl4yPFN3",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "f39398d7-0497-4e63-e51c-e7bf0085921a"
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "'''Load data'''\n",
        "WHE_data = pd.read_csv(io.BytesIO(uploaded['Electricity_WHE.csv']))['P']\n",
        "#WHE_data = pd.read_csv('Electricity_WHE.csv')['P']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5e4c7f27-a846-4e20-be5e-62236357eda5\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-5e4c7f27-a846-4e20-be5e-62236357eda5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Electricity_WHE.csv to Electricity_WHE.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RJE_A1b1PQLm",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "68bdb9f3-ebe6-4708-f0dd-0e435100ed71"
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "CWE_data = pd.read_csv(io.BytesIO(uploaded['Electricity_CWE.csv']))['P']\n",
        "#CWE_data = pd.read_csv('Electricity_CWE.csv')['P']"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e4cadb6d-f173-43bb-b15e-1ac14fd60fd6\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-e4cadb6d-f173-43bb-b15e-1ac14fd60fd6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Electricity_CWE.csv to Electricity_CWE.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f4CJBm-IPe44",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "window_size=60\n",
        "\n",
        "dataX_raw = create_dataset(WHE_data.as_matrix(), window_size)\n",
        "\n",
        "#S0,S1:1-350,S2:350+\n",
        "\n",
        "cwe_Y_raw = CWE_data[window_size-1:].values.reshape([CWE_data.shape[0]-window_size+1,1])\n",
        "dataX = np.concatenate([dataX_raw[0:472500,:],dataX_raw[475500:,:]],axis=0)\n",
        "cwe_Y = np.concatenate([cwe_Y_raw[0:472500,:],cwe_Y_raw[475500:,:]],axis=0)\n",
        "categorized_cwe_Y = np.ones(cwe_Y.shape)*2\n",
        "categorized_cwe_Y[[np.where(cwe_Y==0)[0]],:]=0\n",
        "categorized_cwe_Y[[np.where((cwe_Y>0)&(cwe_Y<=350))[0]],:]=1\n",
        "#categorized_cwe_Y[[np.where((cwe_Y>350))[0]],:]=2\n",
        "\n",
        "encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
        "cweY_1hot = encoder.fit_transform(categorized_cwe_Y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataX, cweY_1hot, test_size=0.1, shuffle=True)\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train.astype(float))\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-k8WkraGPlxm",
        "colab_type": "code",
        "outputId": "1d90934d-5ad8-4a95-a5b5-1fa4aa47a039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "cell_type": "code",
      "source": [
        "max_indice = np.argmax(cweY_1hot,1)\n",
        "df = pd.Series(max_indice)\n",
        "df.value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1018321\n",
              "1      26515\n",
              "2       3305\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "rvPM-4Q_PgN3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "tl = RandomUnderSampler(sampling_strategy={0:5000,1:5000,2:2900})\n",
        "X_train, y_train = tl.fit_resample(X_train, y_train)\n",
        "whole_train = np.concatenate([X_train,y_train],axis=1)\n",
        "#from imblearn.under_sampling import EditedNearestNeighbours\n",
        "#enn = EditedNearestNeighbours()\n",
        "#X_train, y_train = enn.fit_resample(X_train, y_train)\n",
        "\n",
        "#from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
        "#ncr = NeighbourhoodCleaningRule()\n",
        "#X_train, y_train = ncr.fit_resample(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "68SC7UsgPpYl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''Hyper parameters for deep learning'''\n",
        "# Hyper Parameters\n",
        "LR = 0.001               # learning rate\n",
        "#cfg_list = nf.model_configs()\n",
        "#error_list = []\n",
        "\n",
        "#hyperparameters\n",
        "batch_size=512\n",
        "unit_num=128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hSQGumpHPqNp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "6b418bbe-e487-468a-d986-82246b3d6728"
      },
      "cell_type": "code",
      "source": [
        "'''RNN Model Definition'''\n",
        "tf.reset_default_graph()\n",
        "''''''\n",
        "#define inputs\n",
        "tf_x = tf.placeholder(tf.float32, [None, window_size,1],name='x')\n",
        "tf_y = tf.placeholder(tf.int32, [None, 3],name='y')\n",
        "\n",
        "lstm_cell =tf.contrib.rnn.BasicLSTMCell(num_units=unit_num,name='lstm_cell')\n",
        "outputs, (h_c, h_n) = tf.nn.dynamic_rnn(\n",
        "    lstm_cell,                   # cell you have chosen\n",
        "    tf_x,                      # input\n",
        "    initial_state=None,         # the initial hidden state\n",
        "    dtype=tf.float32,           # must given if set initial_state = None\n",
        "    time_major=False,           # False: (batch, time step, input); True: (time step, batch, input)\n",
        ")\n",
        "l1 = tf.layers.dense(outputs[:, -1, :],512,activation=tf.nn.leaky_relu,name='l1')\n",
        "l2 = tf.layers.dense(l1,1024,activation=tf.nn.leaky_relu,name='l2')\n",
        "l3 = tf.layers.dense(l2,512,activation=tf.nn.leaky_relu,name='l3')\n",
        "l4 = tf.layers.dense(l3,256,activation=tf.nn.leaky_relu,name='l4')\n",
        "l5 = tf.layers.dense(l4,128,activation=tf.nn.leaky_relu,name='l5')\n",
        "l6 = tf.layers.dense(l5,84,activation=tf.nn.leaky_relu,name='l6')\n",
        "l7 = tf.layers.dense(l6,64,activation=tf.nn.leaky_relu,name='l7')\n",
        "l8 = tf.layers.dense(l7,48,activation=tf.nn.leaky_relu,name='l8')\n",
        "l9 = tf.layers.dense(l8,32,activation=tf.nn.leaky_relu,name='l9')\n",
        "l10 = tf.layers.dense(l9,24,activation=tf.nn.leaky_relu,name='l10')\n",
        "l11 = tf.layers.dense(l10,16,activation=tf.nn.leaky_relu,name='l11')\n",
        "l12 = tf.layers.dense(l11,8,activation=tf.nn.leaky_relu,name='l12')\n",
        "pred = tf.layers.dense(l12,3,activation=tf.nn.relu,name='pred')\n",
        "\n",
        "with tf.name_scope('loss'):\n",
        "    cross_entropy =  tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_y, logits=pred) \n",
        "    loss = tf.reduce_mean(cross_entropy)\n",
        "    tf.summary.scalar(\"loss\",tensor=loss)\n",
        "\n",
        "train_op = tf.train.AdamOptimizer(LR).minimize(loss)\n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(tf_y, axis=1), tf.argmax(pred, axis=1)), tf.float32))\n",
        "\n",
        "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer()) \n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-10-a97c03e7227e>:8: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-10-a97c03e7227e>:14: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From <ipython-input-10-a97c03e7227e>:16: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pLMeA183PtzM",
        "colab_type": "code",
        "outputId": "db10ba46-3c63-4507-9fef-d686f6a5908b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 59220
        }
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "#sess.run(init_op)\n",
        "saver.restore(sess, 'my_net_cwe/save_cwe_rnn.ckpt')\n",
        "\n",
        "flag = False\n",
        "for j in range(0,1000):\n",
        "    print('###iteration: '+str(j)+'###')\n",
        "    batch_index = np.random.choice(12800,batch_size)\n",
        "    batch_train = whole_train[batch_index,:]\n",
        "    batch_X = batch_train[:,:-3].reshape([batch_size,window_size,1])\n",
        "    batch_y = batch_train[:,-3:]\n",
        "    sess.run(train_op,{tf_x:batch_X , tf_y:batch_y})\n",
        "    cost_ = sess.run(loss,{tf_x:batch_X, tf_y:batch_y})\n",
        "    acc_train = sess.run(accuracy,{tf_x:batch_X, tf_y:batch_y})\n",
        "    acc_test = sess.run(accuracy,feed_dict={tf_x: X_test.reshape([X_test.shape[0],window_size,1]), tf_y:y_test})\n",
        "    print('train loss= %.4f' % cost_+', Acc=%.2f'% acc_train)\n",
        "    print('Test Acc=%.2f'% acc_test)\n",
        "    \n",
        "    pre = sess.run(pred,feed_dict={tf_x: batch_X, tf_y:batch_y})\n",
        "    y_lables_argmax = tf.argmax(tf_y,axis=1)  \n",
        "    y_pred_argmax = tf.argmax(pre,axis=1)\n",
        "    confusion = tf.confusion_matrix(labels=y_lables_argmax, predictions=y_pred_argmax, num_classes=3)\n",
        "    #print('Confusion Matrix: \\n\\n', tf.Tensor.eval(confusion,feed_dict=None))\n",
        "    print(confusion.eval(session=sess,feed_dict={tf_x: batch_X, tf_y:batch_y}))\n",
        "    if acc_train>=0.99:\n",
        "      print(j)\n",
        "      flag = True\n",
        "      break\n",
        "    if(flag==True):\n",
        "        print(flag)\n",
        "        break\n",
        "    if(j//100==0):\n",
        "      save_path = saver.save(sess, \"my_net_cwe/save_cwe_rnn.ckpt\")\n",
        "pre = sess.run(pred,feed_dict={tf_x: X_test.reshape([X_test.shape[0],window_size,1]), tf_y: y_test})\n",
        "y_lables_argmax = np.argmax(y_test,1)\n",
        "y_pred_argmax = np.argmax(pre,1)\n",
        "confusion = tf.confusion_matrix(labels=y_lables_argmax, predictions=y_pred_argmax, num_classes=3)\n",
        "#print('Confusion Matrix: \\n\\n', tf.Tensor.eval(confusion,feed_dict=None))\n",
        "print(confusion.eval(session=sess))\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from my_net_cwe/save_cwe_rnn.ckpt\n",
            "###iteration: 0###\n",
            "train loss= 0.9096, Acc=0.53\n",
            "Test Acc=0.53\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/confusion_matrix.py:193: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/confusion_matrix.py:194: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "[[112  83  15]\n",
            " [ 45 115  26]\n",
            " [  4  68  44]]\n",
            "###iteration: 1###\n",
            "train loss= 0.8638, Acc=0.57\n",
            "Test Acc=0.53\n",
            "[[105  50  41]\n",
            " [ 43  96  50]\n",
            " [  1  35  91]]\n",
            "###iteration: 2###\n",
            "train loss= 0.9113, Acc=0.54\n",
            "Test Acc=0.58\n",
            "[[109  60  38]\n",
            " [ 48 125  45]\n",
            " [  6  41  40]]\n",
            "###iteration: 3###\n",
            "train loss= 0.9059, Acc=0.57\n",
            "Test Acc=0.50\n",
            "[[101  63  26]\n",
            " [ 32 121  39]\n",
            " [  3  58  69]]\n",
            "###iteration: 4###\n",
            "train loss= 0.9221, Acc=0.55\n",
            "Test Acc=0.35\n",
            "[[ 74  85  34]\n",
            " [  8 122  50]\n",
            " [  0  51  88]]\n",
            "###iteration: 5###\n",
            "train loss= 0.9363, Acc=0.53\n",
            "Test Acc=0.39\n",
            "[[ 71  75  45]\n",
            " [ 15 123  54]\n",
            " [  1  53  75]]\n",
            "###iteration: 6###\n",
            "train loss= 0.8711, Acc=0.57\n",
            "Test Acc=0.56\n",
            "[[112  70  13]\n",
            " [ 46 123  20]\n",
            " [  5  64  59]]\n",
            "###iteration: 7###\n",
            "train loss= 0.9070, Acc=0.56\n",
            "Test Acc=0.60\n",
            "[[131  64  10]\n",
            " [ 63 108  20]\n",
            " [ 14  54  48]]\n",
            "###iteration: 8###\n",
            "train loss= 0.8592, Acc=0.59\n",
            "Test Acc=0.52\n",
            "[[112  61  29]\n",
            " [ 40 115  33]\n",
            " [  0  46  76]]\n",
            "###iteration: 9###\n",
            "train loss= 0.9442, Acc=0.51\n",
            "Test Acc=0.41\n",
            "[[ 69  80  44]\n",
            " [ 19 108  73]\n",
            " [  0  35  84]]\n",
            "###iteration: 10###\n",
            "train loss= 0.8677, Acc=0.58\n",
            "Test Acc=0.44\n",
            "[[ 99  66  28]\n",
            " [ 21 113  58]\n",
            " [  0  43  84]]\n",
            "###iteration: 11###\n",
            "train loss= 0.9021, Acc=0.57\n",
            "Test Acc=0.53\n",
            "[[ 91  78  17]\n",
            " [ 36 133  31]\n",
            " [  3  55  68]]\n",
            "###iteration: 12###\n",
            "train loss= 0.8927, Acc=0.56\n",
            "Test Acc=0.54\n",
            "[[105  78   6]\n",
            " [ 45 133  22]\n",
            " [  5  70  48]]\n",
            "###iteration: 13###\n",
            "train loss= 0.8680, Acc=0.58\n",
            "Test Acc=0.44\n",
            "[[ 89  96  13]\n",
            " [ 28 150  32]\n",
            " [  2  43  59]]\n",
            "###iteration: 14###\n",
            "train loss= 0.9198, Acc=0.56\n",
            "Test Acc=0.41\n",
            "[[ 76  98  29]\n",
            " [ 10 132  51]\n",
            " [  0  39  77]]\n",
            "###iteration: 15###\n",
            "train loss= 0.8643, Acc=0.59\n",
            "Test Acc=0.48\n",
            "[[ 91  75  23]\n",
            " [ 30 155  29]\n",
            " [  0  52  57]]\n",
            "###iteration: 16###\n",
            "train loss= 0.8738, Acc=0.56\n",
            "Test Acc=0.55\n",
            "[[105  79  16]\n",
            " [ 45 140  22]\n",
            " [  1  61  43]]\n",
            "###iteration: 17###\n",
            "train loss= 0.9115, Acc=0.53\n",
            "Test Acc=0.55\n",
            "[[109  75  11]\n",
            " [ 55 144  15]\n",
            " [  5  78  20]]\n",
            "###iteration: 18###\n",
            "train loss= 0.8850, Acc=0.56\n",
            "Test Acc=0.47\n",
            "[[ 88  98  10]\n",
            " [ 30 161  19]\n",
            " [  2  67  37]]\n",
            "###iteration: 19###\n",
            "train loss= 0.8579, Acc=0.60\n",
            "Test Acc=0.41\n",
            "[[ 88 103  17]\n",
            " [ 17 154  28]\n",
            " [  0  38  67]]\n",
            "###iteration: 20###\n",
            "train loss= 0.8806, Acc=0.57\n",
            "Test Acc=0.44\n",
            "[[ 70  92  30]\n",
            " [ 16 146  44]\n",
            " [  0  38  76]]\n",
            "###iteration: 21###\n",
            "train loss= 0.8991, Acc=0.56\n",
            "Test Acc=0.49\n",
            "[[ 80  70  30]\n",
            " [ 37 138  32]\n",
            " [  2  56  67]]\n",
            "###iteration: 22###\n",
            "train loss= 0.8567, Acc=0.56\n",
            "Test Acc=0.55\n",
            "[[125  68  21]\n",
            " [ 46 118  28]\n",
            " [  3  60  43]]\n",
            "###iteration: 23###\n",
            "train loss= 0.8595, Acc=0.57\n",
            "Test Acc=0.55\n",
            "[[111  70  14]\n",
            " [ 56 138  25]\n",
            " [  3  50  45]]\n",
            "###iteration: 24###\n",
            "train loss= 0.8239, Acc=0.60\n",
            "Test Acc=0.50\n",
            "[[104  86  27]\n",
            " [ 28 145  22]\n",
            " [  0  42  58]]\n",
            "###iteration: 25###\n",
            "train loss= 0.8525, Acc=0.60\n",
            "Test Acc=0.42\n",
            "[[ 88  99  16]\n",
            " [ 22 154  34]\n",
            " [  1  31  67]]\n",
            "###iteration: 26###\n",
            "train loss= 0.8401, Acc=0.60\n",
            "Test Acc=0.43\n",
            "[[ 86  89  17]\n",
            " [ 14 155  32]\n",
            " [  0  53  66]]\n",
            "###iteration: 27###\n",
            "train loss= 0.8468, Acc=0.58\n",
            "Test Acc=0.49\n",
            "[[101  76  27]\n",
            " [ 31 119  37]\n",
            " [  2  40  79]]\n",
            "###iteration: 28###\n",
            "train loss= 0.8298, Acc=0.62\n",
            "Test Acc=0.58\n",
            "[[130  81   9]\n",
            " [ 44 145  19]\n",
            " [  4  40  40]]\n",
            "###iteration: 29###\n",
            "train loss= 0.8306, Acc=0.59\n",
            "Test Acc=0.54\n",
            "[[105  68  19]\n",
            " [ 51 128  31]\n",
            " [  1  38  71]]\n",
            "###iteration: 30###\n",
            "train loss= 0.8961, Acc=0.54\n",
            "Test Acc=0.42\n",
            "[[101  63  45]\n",
            " [ 17  85  79]\n",
            " [  0  31  91]]\n",
            "###iteration: 31###\n",
            "train loss= 0.8628, Acc=0.58\n",
            "Test Acc=0.47\n",
            "[[ 85  93  24]\n",
            " [ 18 141  38]\n",
            " [  1  39  73]]\n",
            "###iteration: 32###\n",
            "train loss= 0.8900, Acc=0.56\n",
            "Test Acc=0.53\n",
            "[[105  75  14]\n",
            " [ 45 151   7]\n",
            " [  2  84  29]]\n",
            "###iteration: 33###\n",
            "train loss= 0.9130, Acc=0.53\n",
            "Test Acc=0.50\n",
            "[[ 91  85  13]\n",
            " [ 35 144  14]\n",
            " [  1  94  35]]\n",
            "###iteration: 34###\n",
            "train loss= 0.8482, Acc=0.59\n",
            "Test Acc=0.45\n",
            "[[ 85  98  14]\n",
            " [ 26 139  26]\n",
            " [  0  46  78]]\n",
            "###iteration: 35###\n",
            "train loss= 0.8879, Acc=0.54\n",
            "Test Acc=0.42\n",
            "[[ 77  95  30]\n",
            " [ 19 118  59]\n",
            " [  1  29  84]]\n",
            "###iteration: 36###\n",
            "train loss= 0.8741, Acc=0.54\n",
            "Test Acc=0.46\n",
            "[[ 91  64  47]\n",
            " [ 20 101  77]\n",
            " [  0  26  86]]\n",
            "###iteration: 37###\n",
            "train loss= 0.8910, Acc=0.54\n",
            "Test Acc=0.50\n",
            "[[ 88  75  32]\n",
            " [ 34 134  42]\n",
            " [  3  52  52]]\n",
            "###iteration: 38###\n",
            "train loss= 0.8670, Acc=0.57\n",
            "Test Acc=0.52\n",
            "[[ 95  88   9]\n",
            " [ 41 145  17]\n",
            " [  4  61  52]]\n",
            "###iteration: 39###\n",
            "train loss= 0.8367, Acc=0.58\n",
            "Test Acc=0.49\n",
            "[[ 92  88   6]\n",
            " [ 31 158  18]\n",
            " [  0  73  46]]\n",
            "###iteration: 40###\n",
            "train loss= 0.8185, Acc=0.57\n",
            "Test Acc=0.45\n",
            "[[ 91 103   6]\n",
            " [ 18 167  16]\n",
            " [  0  78  33]]\n",
            "###iteration: 41###\n",
            "train loss= 0.8497, Acc=0.58\n",
            "Test Acc=0.41\n",
            "[[ 71 104   8]\n",
            " [ 15 193  20]\n",
            " [  1  65  35]]\n",
            "###iteration: 42###\n",
            "train loss= 0.8354, Acc=0.59\n",
            "Test Acc=0.46\n",
            "[[ 96  91  23]\n",
            " [ 12 148  22]\n",
            " [  1  60  59]]\n",
            "###iteration: 43###\n",
            "train loss= 0.8450, Acc=0.60\n",
            "Test Acc=0.51\n",
            "[[ 81  74  21]\n",
            " [ 31 148  42]\n",
            " [  1  38  76]]\n",
            "###iteration: 44###\n",
            "train loss= 0.8510, Acc=0.58\n",
            "Test Acc=0.54\n",
            "[[110  64  29]\n",
            " [ 50 117  43]\n",
            " [  1  29  69]]\n",
            "###iteration: 45###\n",
            "train loss= 0.7971, Acc=0.62\n",
            "Test Acc=0.52\n",
            "[[105  73  23]\n",
            " [ 37 141  29]\n",
            " [  1  32  71]]\n",
            "###iteration: 46###\n",
            "train loss= 0.8520, Acc=0.57\n",
            "Test Acc=0.46\n",
            "[[ 89  88  33]\n",
            " [ 18 134  35]\n",
            " [  1  44  70]]\n",
            "###iteration: 47###\n",
            "train loss= 0.8781, Acc=0.57\n",
            "Test Acc=0.35\n",
            "[[ 58 108  27]\n",
            " [ 10 150  41]\n",
            " [  1  34  83]]\n",
            "###iteration: 48###\n",
            "train loss= 0.8532, Acc=0.59\n",
            "Test Acc=0.40\n",
            "[[ 82 112   9]\n",
            " [ 15 168  24]\n",
            " [  1  50  51]]\n",
            "###iteration: 49###\n",
            "train loss= 0.8870, Acc=0.55\n",
            "Test Acc=0.51\n",
            "[[ 87  98   9]\n",
            " [ 36 148  22]\n",
            " [  0  66  46]]\n",
            "###iteration: 50###\n",
            "train loss= 0.8710, Acc=0.59\n",
            "Test Acc=0.52\n",
            "[[101  71  19]\n",
            " [ 42 137  27]\n",
            " [  0  49  66]]\n",
            "###iteration: 51###\n",
            "train loss= 0.8960, Acc=0.53\n",
            "Test Acc=0.51\n",
            "[[88 59 43]\n",
            " [35 95 71]\n",
            " [ 0 33 88]]\n",
            "###iteration: 52###\n",
            "train loss= 0.8926, Acc=0.51\n",
            "Test Acc=0.52\n",
            "[[95 68 42]\n",
            " [51 94 54]\n",
            " [ 0 38 70]]\n",
            "###iteration: 53###\n",
            "train loss= 0.8688, Acc=0.56\n",
            "Test Acc=0.56\n",
            "[[113  77  16]\n",
            " [ 46 126  26]\n",
            " [  1  57  50]]\n",
            "###iteration: 54###\n",
            "train loss= 0.8914, Acc=0.54\n",
            "Test Acc=0.51\n",
            "[[ 77  96  13]\n",
            " [ 36 164  12]\n",
            " [  0  77  37]]\n",
            "###iteration: 55###\n",
            "train loss= 0.8203, Acc=0.63\n",
            "Test Acc=0.41\n",
            "[[ 84 103   8]\n",
            " [  7 171  20]\n",
            " [  0  49  70]]\n",
            "###iteration: 56###\n",
            "train loss= 0.8494, Acc=0.58\n",
            "Test Acc=0.40\n",
            "[[ 78 107  26]\n",
            " [  9 150  33]\n",
            " [  0  41  68]]\n",
            "###iteration: 57###\n",
            "train loss= 0.8204, Acc=0.58\n",
            "Test Acc=0.47\n",
            "[[107  79  38]\n",
            " [ 22 109  42]\n",
            " [  0  32  83]]\n",
            "###iteration: 58###\n",
            "train loss= 0.8538, Acc=0.58\n",
            "Test Acc=0.51\n",
            "[[ 80  82  16]\n",
            " [ 36 140  39]\n",
            " [  1  41  77]]\n",
            "###iteration: 59###\n",
            "train loss= 0.8169, Acc=0.59\n",
            "Test Acc=0.49\n",
            "[[103  88   8]\n",
            " [ 34 173  12]\n",
            " [  0  66  28]]\n",
            "###iteration: 60###\n",
            "train loss= 0.8479, Acc=0.58\n",
            "Test Acc=0.40\n",
            "[[ 87 119   9]\n",
            " [  8 178  14]\n",
            " [  0  65  32]]\n",
            "###iteration: 61###\n",
            "train loss= 0.8778, Acc=0.56\n",
            "Test Acc=0.32\n",
            "[[ 61 112  29]\n",
            " [  6 136  46]\n",
            " [  0  30  92]]\n",
            "###iteration: 62###\n",
            "train loss= 0.8573, Acc=0.57\n",
            "Test Acc=0.43\n",
            "[[ 85  93  29]\n",
            " [ 14 142  44]\n",
            " [  1  39  65]]\n",
            "###iteration: 63###\n",
            "train loss= 0.8716, Acc=0.56\n",
            "Test Acc=0.55\n",
            "[[115  86  13]\n",
            " [ 45 128  13]\n",
            " [  2  68  42]]\n",
            "###iteration: 64###\n",
            "train loss= 0.8524, Acc=0.58\n",
            "Test Acc=0.51\n",
            "[[ 95  73  10]\n",
            " [ 39 155  18]\n",
            " [  1  76  45]]\n",
            "###iteration: 65###\n",
            "train loss= 0.8460, Acc=0.59\n",
            "Test Acc=0.40\n",
            "[[ 80 104  20]\n",
            " [ 13 160  25]\n",
            " [  0  47  63]]\n",
            "###iteration: 66###\n",
            "train loss= 0.8990, Acc=0.55\n",
            "Test Acc=0.33\n",
            "[[ 60 105  38]\n",
            " [  9 138  50]\n",
            " [  0  26  86]]\n",
            "###iteration: 67###\n",
            "train loss= 0.8498, Acc=0.59\n",
            "Test Acc=0.39\n",
            "[[ 78  96  25]\n",
            " [ 13 152  31]\n",
            " [  0  44  73]]\n",
            "###iteration: 68###\n",
            "train loss= 0.8390, Acc=0.59\n",
            "Test Acc=0.50\n",
            "[[ 90  86  11]\n",
            " [ 39 158  17]\n",
            " [  1  56  54]]\n",
            "###iteration: 69###\n",
            "train loss= 0.8849, Acc=0.54\n",
            "Test Acc=0.55\n",
            "[[ 98  80  18]\n",
            " [ 53 128  24]\n",
            " [  5  57  49]]\n",
            "###iteration: 70###\n",
            "train loss= 0.8428, Acc=0.57\n",
            "Test Acc=0.52\n",
            "[[ 95  87  20]\n",
            " [ 45 141  29]\n",
            " [  2  37  56]]\n",
            "###iteration: 71###\n",
            "train loss= 0.8828, Acc=0.52\n",
            "Test Acc=0.47\n",
            "[[ 78 103  28]\n",
            " [ 27 115  51]\n",
            " [  0  35  75]]\n",
            "###iteration: 72###\n",
            "train loss= 0.8474, Acc=0.60\n",
            "Test Acc=0.43\n",
            "[[ 71  88  27]\n",
            " [ 17 151  45]\n",
            " [  0  26  87]]\n",
            "###iteration: 73###\n",
            "train loss= 0.8516, Acc=0.59\n",
            "Test Acc=0.41\n",
            "[[ 74 100  21]\n",
            " [ 12 158  40]\n",
            " [  0  39  68]]\n",
            "###iteration: 74###\n",
            "train loss= 0.8588, Acc=0.59\n",
            "Test Acc=0.43\n",
            "[[ 83  89  31]\n",
            " [ 17 147  21]\n",
            " [  1  52  71]]\n",
            "###iteration: 75###\n",
            "train loss= 0.8212, Acc=0.59\n",
            "Test Acc=0.46\n",
            "[[ 99  86  16]\n",
            " [ 33 141  28]\n",
            " [  2  43  64]]\n",
            "###iteration: 76###\n",
            "train loss= 0.8325, Acc=0.60\n",
            "Test Acc=0.48\n",
            "[[102  78  24]\n",
            " [ 32 131  27]\n",
            " [  1  44  73]]\n",
            "###iteration: 77###\n",
            "train loss= 0.8282, Acc=0.59\n",
            "Test Acc=0.48\n",
            "[[ 82  84  24]\n",
            " [ 33 133  34]\n",
            " [  0  37  85]]\n",
            "###iteration: 78###\n",
            "train loss= 0.7929, Acc=0.59\n",
            "Test Acc=0.45\n",
            "[[ 96 103  17]\n",
            " [ 28 138  25]\n",
            " [  0  35  70]]\n",
            "###iteration: 79###\n",
            "train loss= 0.8650, Acc=0.56\n",
            "Test Acc=0.42\n",
            "[[ 66 111  21]\n",
            " [ 18 164  26]\n",
            " [  0  47  59]]\n",
            "###iteration: 80###\n",
            "train loss= 0.8170, Acc=0.60\n",
            "Test Acc=0.42\n",
            "[[ 83 100  18]\n",
            " [ 14 156  35]\n",
            " [  0  37  69]]\n",
            "###iteration: 81###\n",
            "train loss= 0.8347, Acc=0.57\n",
            "Test Acc=0.42\n",
            "[[ 76  98  24]\n",
            " [ 21 150  39]\n",
            " [  0  40  64]]\n",
            "###iteration: 82###\n",
            "train loss= 0.7708, Acc=0.62\n",
            "Test Acc=0.45\n",
            "[[ 84  84  15]\n",
            " [ 21 159  39]\n",
            " [  0  33  77]]\n",
            "###iteration: 83###\n",
            "train loss= 0.8135, Acc=0.58\n",
            "Test Acc=0.52\n",
            "[[105  97   9]\n",
            " [ 29 154  17]\n",
            " [  0  65  36]]\n",
            "###iteration: 84###\n",
            "train loss= 0.8956, Acc=0.53\n",
            "Test Acc=0.51\n",
            "[[104 103  10]\n",
            " [ 42 133  14]\n",
            " [  1  73  32]]\n",
            "###iteration: 85###\n",
            "train loss= 0.8263, Acc=0.57\n",
            "Test Acc=0.44\n",
            "[[ 75 101   9]\n",
            " [ 25 177  14]\n",
            " [  0  70  41]]\n",
            "###iteration: 86###\n",
            "train loss= 0.8426, Acc=0.58\n",
            "Test Acc=0.37\n",
            "[[ 66 116  16]\n",
            " [  8 171  36]\n",
            " [  0  39  60]]\n",
            "###iteration: 87###\n",
            "train loss= 0.8063, Acc=0.62\n",
            "Test Acc=0.36\n",
            "[[ 62  95  24]\n",
            " [  9 162  35]\n",
            " [  0  29  96]]\n",
            "###iteration: 88###\n",
            "train loss= 0.8142, Acc=0.58\n",
            "Test Acc=0.42\n",
            "[[ 81 112  10]\n",
            " [  9 158  30]\n",
            " [  0  52  60]]\n",
            "###iteration: 89###\n",
            "train loss= 0.7937, Acc=0.62\n",
            "Test Acc=0.53\n",
            "[[122  88   9]\n",
            " [ 38 135  15]\n",
            " [  1  42  62]]\n",
            "###iteration: 90###\n",
            "train loss= 0.8415, Acc=0.58\n",
            "Test Acc=0.53\n",
            "[[107  69  16]\n",
            " [ 51 143  18]\n",
            " [  3  56  49]]\n",
            "###iteration: 91###\n",
            "train loss= 0.8211, Acc=0.58\n",
            "Test Acc=0.46\n",
            "[[104  85  25]\n",
            " [ 31 126  35]\n",
            " [  0  39  67]]\n",
            "###iteration: 92###\n",
            "train loss= 0.8462, Acc=0.56\n",
            "Test Acc=0.41\n",
            "[[ 92 107  30]\n",
            " [ 14 131  38]\n",
            " [  1  35  64]]\n",
            "###iteration: 93###\n",
            "train loss= 0.8309, Acc=0.59\n",
            "Test Acc=0.38\n",
            "[[ 61 100  27]\n",
            " [ 13 164  35]\n",
            " [  0  35  77]]\n",
            "###iteration: 94###\n",
            "train loss= 0.8214, Acc=0.60\n",
            "Test Acc=0.40\n",
            "[[ 65 112  13]\n",
            " [ 13 178  22]\n",
            " [  0  47  62]]\n",
            "###iteration: 95###\n",
            "train loss= 0.7934, Acc=0.63\n",
            "Test Acc=0.47\n",
            "[[102  89  15]\n",
            " [ 19 160  18]\n",
            " [  1  49  59]]\n",
            "###iteration: 96###\n",
            "train loss= 0.8157, Acc=0.58\n",
            "Test Acc=0.51\n",
            "[[ 96  93  14]\n",
            " [ 34 127  30]\n",
            " [  0  42  76]]\n",
            "###iteration: 97###\n",
            "train loss= 0.8085, Acc=0.57\n",
            "Test Acc=0.52\n",
            "[[114  84  16]\n",
            " [ 52 121  31]\n",
            " [  0  35  59]]\n",
            "###iteration: 98###\n",
            "train loss= 0.8050, Acc=0.60\n",
            "Test Acc=0.49\n",
            "[[ 90  95   7]\n",
            " [ 36 148  21]\n",
            " [  2  46  67]]\n",
            "###iteration: 99###\n",
            "train loss= 0.8468, Acc=0.57\n",
            "Test Acc=0.45\n",
            "[[ 67 111  13]\n",
            " [ 22 166  16]\n",
            " [  0  58  59]]\n",
            "###iteration: 100###\n",
            "train loss= 0.8361, Acc=0.57\n",
            "Test Acc=0.45\n",
            "[[ 85 106  10]\n",
            " [ 25 156  24]\n",
            " [  0  53  53]]\n",
            "###iteration: 101###\n",
            "train loss= 0.7557, Acc=0.62\n",
            "Test Acc=0.46\n",
            "[[103  83  11]\n",
            " [ 32 162  21]\n",
            " [  0  45  55]]\n",
            "###iteration: 102###\n",
            "train loss= 0.8163, Acc=0.59\n",
            "Test Acc=0.48\n",
            "[[ 79  79  30]\n",
            " [ 23 157  39]\n",
            " [  0  37  68]]\n",
            "###iteration: 103###\n",
            "train loss= 0.7794, Acc=0.61\n",
            "Test Acc=0.50\n",
            "[[113  88   7]\n",
            " [ 41 136  28]\n",
            " [  0  35  64]]\n",
            "###iteration: 104###\n",
            "train loss= 0.8126, Acc=0.59\n",
            "Test Acc=0.43\n",
            "[[ 77  98   8]\n",
            " [ 25 168  22]\n",
            " [  0  57  57]]\n",
            "###iteration: 105###\n",
            "train loss= 0.8408, Acc=0.59\n",
            "Test Acc=0.39\n",
            "[[ 59 112  24]\n",
            " [  7 178  17]\n",
            " [  0  52  63]]\n",
            "###iteration: 106###\n",
            "train loss= 0.8152, Acc=0.60\n",
            "Test Acc=0.39\n",
            "[[ 76  89  23]\n",
            " [ 10 159  37]\n",
            " [  0  44  74]]\n",
            "###iteration: 107###\n",
            "train loss= 0.8250, Acc=0.59\n",
            "Test Acc=0.44\n",
            "[[ 82  95  20]\n",
            " [ 18 155  35]\n",
            " [  0  42  65]]\n",
            "###iteration: 108###\n",
            "train loss= 0.7849, Acc=0.62\n",
            "Test Acc=0.49\n",
            "[[115  83  13]\n",
            " [ 34 138  28]\n",
            " [  1  37  63]]\n",
            "###iteration: 109###\n",
            "train loss= 0.8210, Acc=0.60\n",
            "Test Acc=0.52\n",
            "[[104  82  17]\n",
            " [ 32 133  23]\n",
            " [  1  50  70]]\n",
            "###iteration: 110###\n",
            "train loss= 0.8445, Acc=0.56\n",
            "Test Acc=0.53\n",
            "[[ 96  89  10]\n",
            " [ 42 125  27]\n",
            " [  0  57  66]]\n",
            "###iteration: 111###\n",
            "train loss= 0.7975, Acc=0.58\n",
            "Test Acc=0.48\n",
            "[[ 77  92  12]\n",
            " [ 37 162  22]\n",
            " [  0  50  60]]\n",
            "###iteration: 112###\n",
            "train loss= 0.7826, Acc=0.58\n",
            "Test Acc=0.44\n",
            "[[ 87 109  20]\n",
            " [ 27 126  33]\n",
            " [  0  25  85]]\n",
            "###iteration: 113###\n",
            "train loss= 0.8198, Acc=0.61\n",
            "Test Acc=0.49\n",
            "[[ 94  88  19]\n",
            " [ 24 147  26]\n",
            " [  0  42  72]]\n",
            "###iteration: 114###\n",
            "train loss= 0.8285, Acc=0.54\n",
            "Test Acc=0.59\n",
            "[[ 96  80  12]\n",
            " [ 64 135  18]\n",
            " [  1  58  48]]\n",
            "###iteration: 115###\n",
            "train loss= 0.8807, Acc=0.54\n",
            "Test Acc=0.61\n",
            "[[122  81  14]\n",
            " [ 59 113  21]\n",
            " [  4  56  42]]\n",
            "###iteration: 116###\n",
            "train loss= 0.8690, Acc=0.54\n",
            "Test Acc=0.50\n",
            "[[107  84  36]\n",
            " [ 33  89  58]\n",
            " [  0  26  79]]\n",
            "###iteration: 117###\n",
            "train loss= 0.7957, Acc=0.58\n",
            "Test Acc=0.49\n",
            "[[104  71  30]\n",
            " [ 34 108  47]\n",
            " [  1  33  84]]\n",
            "###iteration: 118###\n",
            "train loss= 0.7914, Acc=0.59\n",
            "Test Acc=0.51\n",
            "[[112  98   6]\n",
            " [ 34 139  15]\n",
            " [  1  55  52]]\n",
            "###iteration: 119###\n",
            "train loss= 0.8344, Acc=0.57\n",
            "Test Acc=0.49\n",
            "[[ 98 101   5]\n",
            " [ 28 171   3]\n",
            " [  0  81  25]]\n",
            "###iteration: 120###\n",
            "train loss= 0.8568, Acc=0.56\n",
            "Test Acc=0.43\n",
            "[[ 77 107   5]\n",
            " [ 22 178   4]\n",
            " [  1  87  31]]\n",
            "###iteration: 121###\n",
            "train loss= 0.8515, Acc=0.55\n",
            "Test Acc=0.42\n",
            "[[ 83 117   8]\n",
            " [ 12 149  22]\n",
            " [  1  68  52]]\n",
            "###iteration: 122###\n",
            "train loss= 0.8225, Acc=0.63\n",
            "Test Acc=0.43\n",
            "[[ 82  74  21]\n",
            " [ 13 150  47]\n",
            " [  0  32  93]]\n",
            "###iteration: 123###\n",
            "train loss= 0.8556, Acc=0.59\n",
            "Test Acc=0.43\n",
            "[[ 72  68  41]\n",
            " [ 16 135  57]\n",
            " [  1  26  96]]\n",
            "###iteration: 124###\n",
            "train loss= 0.7882, Acc=0.62\n",
            "Test Acc=0.45\n",
            "[[ 83  86  21]\n",
            " [ 18 168  33]\n",
            " [  1  34  68]]\n",
            "###iteration: 125###\n",
            "train loss= 0.7942, Acc=0.62\n",
            "Test Acc=0.44\n",
            "[[ 83  98  11]\n",
            " [ 22 183  19]\n",
            " [  0  46  50]]\n",
            "###iteration: 126###\n",
            "train loss= 0.7736, Acc=0.61\n",
            "Test Acc=0.42\n",
            "[[ 96  95   6]\n",
            " [ 12 176  16]\n",
            " [  0  70  41]]\n",
            "###iteration: 127###\n",
            "train loss= 0.8411, Acc=0.55\n",
            "Test Acc=0.40\n",
            "[[ 71 127  14]\n",
            " [ 11 165  23]\n",
            " [  1  56  44]]\n",
            "###iteration: 128###\n",
            "train loss= 0.7947, Acc=0.61\n",
            "Test Acc=0.39\n",
            "[[ 74 104  11]\n",
            " [ 10 182  28]\n",
            " [  0  46  57]]\n",
            "###iteration: 129###\n",
            "train loss= 0.7989, Acc=0.61\n",
            "Test Acc=0.40\n",
            "[[ 75  95  19]\n",
            " [ 13 147  39]\n",
            " [  0  34  90]]\n",
            "###iteration: 130###\n",
            "train loss= 0.8042, Acc=0.61\n",
            "Test Acc=0.45\n",
            "[[ 92  88  19]\n",
            " [ 12 156  32]\n",
            " [  1  49  63]]\n",
            "###iteration: 131###\n",
            "train loss= 0.8195, Acc=0.59\n",
            "Test Acc=0.45\n",
            "[[ 78 101  17]\n",
            " [ 29 161  20]\n",
            " [  0  44  62]]\n",
            "###iteration: 132###\n",
            "train loss= 0.8184, Acc=0.58\n",
            "Test Acc=0.45\n",
            "[[ 85 106  18]\n",
            " [ 11 155  17]\n",
            " [  1  63  56]]\n",
            "###iteration: 133###\n",
            "train loss= 0.8301, Acc=0.61\n",
            "Test Acc=0.43\n",
            "[[ 77  91  15]\n",
            " [ 10 179  20]\n",
            " [  0  62  58]]\n",
            "###iteration: 134###\n",
            "train loss= 0.8036, Acc=0.59\n",
            "Test Acc=0.42\n",
            "[[ 86 105  16]\n",
            " [ 13 151  34]\n",
            " [  0  43  64]]\n",
            "###iteration: 135###\n",
            "train loss= 0.8010, Acc=0.58\n",
            "Test Acc=0.41\n",
            "[[ 75 111  16]\n",
            " [ 22 153  31]\n",
            " [  0  34  70]]\n",
            "###iteration: 136###\n",
            "train loss= 0.8133, Acc=0.60\n",
            "Test Acc=0.45\n",
            "[[ 77  97  15]\n",
            " [ 17 153  35]\n",
            " [  0  41  77]]\n",
            "###iteration: 137###\n",
            "train loss= 0.8012, Acc=0.57\n",
            "Test Acc=0.53\n",
            "[[111  93  14]\n",
            " [ 39 133  16]\n",
            " [  0  57  49]]\n",
            "###iteration: 138###\n",
            "train loss= 0.8257, Acc=0.55\n",
            "Test Acc=0.58\n",
            "[[ 96  93  13]\n",
            " [ 49 116  21]\n",
            " [  3  52  69]]\n",
            "###iteration: 139###\n",
            "train loss= 0.7685, Acc=0.61\n",
            "Test Acc=0.57\n",
            "[[123  70  16]\n",
            " [ 45 122  20]\n",
            " [  0  48  68]]\n",
            "###iteration: 140###\n",
            "train loss= 0.8180, Acc=0.59\n",
            "Test Acc=0.52\n",
            "[[105  70  23]\n",
            " [ 40 123  35]\n",
            " [  0  42  74]]\n",
            "###iteration: 141###\n",
            "train loss= 0.8552, Acc=0.58\n",
            "Test Acc=0.48\n",
            "[[ 90  95  26]\n",
            " [ 26 117  43]\n",
            " [  1  25  89]]\n",
            "###iteration: 142###\n",
            "train loss= 0.8254, Acc=0.59\n",
            "Test Acc=0.50\n",
            "[[ 92  80  17]\n",
            " [ 38 144  41]\n",
            " [  2  33  65]]\n",
            "###iteration: 143###\n",
            "train loss= 0.7592, Acc=0.63\n",
            "Test Acc=0.56\n",
            "[[126  68  14]\n",
            " [ 50 127  23]\n",
            " [  0  36  68]]\n",
            "###iteration: 144###\n",
            "train loss= 0.7989, Acc=0.60\n",
            "Test Acc=0.56\n",
            "[[125  67  10]\n",
            " [ 62 141  19]\n",
            " [  2  47  39]]\n",
            "###iteration: 145###\n",
            "train loss= 0.8269, Acc=0.56\n",
            "Test Acc=0.54\n",
            "[[107  87  12]\n",
            " [ 35 111  38]\n",
            " [  0  52  70]]\n",
            "###iteration: 146###\n",
            "train loss= 0.7902, Acc=0.60\n",
            "Test Acc=0.49\n",
            "[[ 99  83  38]\n",
            " [ 21 112  38]\n",
            " [  0  23  98]]\n",
            "###iteration: 147###\n",
            "train loss= 0.7970, Acc=0.59\n",
            "Test Acc=0.47\n",
            "[[ 77  89  28]\n",
            " [ 20 140  42]\n",
            " [  0  29  87]]\n",
            "###iteration: 148###\n",
            "train loss= 0.8039, Acc=0.59\n",
            "Test Acc=0.43\n",
            "[[ 78  88  31]\n",
            " [ 18 148  24]\n",
            " [  0  47  78]]\n",
            "###iteration: 149###\n",
            "train loss= 0.8149, Acc=0.58\n",
            "Test Acc=0.45\n",
            "[[ 93 126  11]\n",
            " [ 14 150  15]\n",
            " [  1  46  56]]\n",
            "###iteration: 150###\n",
            "train loss= 0.8041, Acc=0.64\n",
            "Test Acc=0.48\n",
            "[[ 95  86   8]\n",
            " [ 21 177  11]\n",
            " [  1  59  54]]\n",
            "###iteration: 151###\n",
            "train loss= 0.8238, Acc=0.59\n",
            "Test Acc=0.46\n",
            "[[ 79  99  10]\n",
            " [ 21 167  27]\n",
            " [  1  51  57]]\n",
            "###iteration: 152###\n",
            "train loss= 0.8267, Acc=0.59\n",
            "Test Acc=0.46\n",
            "[[ 87  95  23]\n",
            " [ 17 129  35]\n",
            " [  1  41  84]]\n",
            "###iteration: 153###\n",
            "train loss= 0.7690, Acc=0.63\n",
            "Test Acc=0.44\n",
            "[[ 92  86  17]\n",
            " [ 21 157  37]\n",
            " [  0  30  72]]\n",
            "###iteration: 154###\n",
            "train loss= 0.7966, Acc=0.61\n",
            "Test Acc=0.45\n",
            "[[ 89 102  13]\n",
            " [ 24 157  22]\n",
            " [  0  37  68]]\n",
            "###iteration: 155###\n",
            "train loss= 0.8164, Acc=0.63\n",
            "Test Acc=0.43\n",
            "[[ 88  84  16]\n",
            " [ 19 170  16]\n",
            " [  1  54  64]]\n",
            "###iteration: 156###\n",
            "train loss= 0.7936, Acc=0.62\n",
            "Test Acc=0.43\n",
            "[[ 82 109  10]\n",
            " [ 11 177  19]\n",
            " [  0  47  57]]\n",
            "###iteration: 157###\n",
            "train loss= 0.7995, Acc=0.62\n",
            "Test Acc=0.40\n",
            "[[ 68  85  17]\n",
            " [ 15 164  46]\n",
            " [  1  32  84]]\n",
            "###iteration: 158###\n",
            "train loss= 0.8074, Acc=0.63\n",
            "Test Acc=0.43\n",
            "[[ 83  91  20]\n",
            " [ 11 154  36]\n",
            " [  0  31  86]]\n",
            "###iteration: 159###\n",
            "train loss= 0.7969, Acc=0.60\n",
            "Test Acc=0.48\n",
            "[[ 89  87  21]\n",
            " [ 31 150  27]\n",
            " [  0  39  68]]\n",
            "###iteration: 160###\n",
            "train loss= 0.7978, Acc=0.59\n",
            "Test Acc=0.46\n",
            "[[ 97 106  10]\n",
            " [ 27 146  15]\n",
            " [  0  53  58]]\n",
            "###iteration: 161###\n",
            "train loss= 0.8228, Acc=0.60\n",
            "Test Acc=0.42\n",
            "[[ 82 109  13]\n",
            " [ 10 174  15]\n",
            " [  0  56  53]]\n",
            "###iteration: 162###\n",
            "train loss= 0.7876, Acc=0.62\n",
            "Test Acc=0.39\n",
            "[[ 85  99  12]\n",
            " [  8 162  22]\n",
            " [  1  52  71]]\n",
            "###iteration: 163###\n",
            "train loss= 0.7965, Acc=0.60\n",
            "Test Acc=0.39\n",
            "[[ 69 100  12]\n",
            " [ 10 170  34]\n",
            " [  1  47  69]]\n",
            "###iteration: 164###\n",
            "train loss= 0.8109, Acc=0.61\n",
            "Test Acc=0.43\n",
            "[[ 93 106   8]\n",
            " [ 16 169  21]\n",
            " [  0  50  49]]\n",
            "###iteration: 165###\n",
            "train loss= 0.8120, Acc=0.60\n",
            "Test Acc=0.47\n",
            "[[ 88 107   8]\n",
            " [ 22 158  13]\n",
            " [  1  55  60]]\n",
            "###iteration: 166###\n",
            "train loss= 0.8386, Acc=0.56\n",
            "Test Acc=0.42\n",
            "[[ 59 108  13]\n",
            " [ 17 162  23]\n",
            " [  1  64  65]]\n",
            "###iteration: 167###\n",
            "train loss= 0.8085, Acc=0.57\n",
            "Test Acc=0.36\n",
            "[[ 71 115  11]\n",
            " [  6 157  36]\n",
            " [  0  50  66]]\n",
            "###iteration: 168###\n",
            "train loss= 0.7647, Acc=0.64\n",
            "Test Acc=0.42\n",
            "[[ 95  74  20]\n",
            " [ 11 159  35]\n",
            " [  1  43  74]]\n",
            "###iteration: 169###\n",
            "train loss= 0.7911, Acc=0.58\n",
            "Test Acc=0.50\n",
            "[[ 86  77  17]\n",
            " [ 31 135  38]\n",
            " [  0  50  78]]\n",
            "###iteration: 170###\n",
            "train loss= 0.7922, Acc=0.61\n",
            "Test Acc=0.53\n",
            "[[111  83  14]\n",
            " [ 41 140  23]\n",
            " [  1  39  60]]\n",
            "###iteration: 171###\n",
            "train loss= 0.7722, Acc=0.60\n",
            "Test Acc=0.53\n",
            "[[116  78  22]\n",
            " [ 35 120  25]\n",
            " [  0  44  72]]\n",
            "###iteration: 172###\n",
            "train loss= 0.8286, Acc=0.56\n",
            "Test Acc=0.49\n",
            "[[ 75  94  25]\n",
            " [ 25 133  34]\n",
            " [  0  48  78]]\n",
            "###iteration: 173###\n",
            "train loss= 0.8329, Acc=0.59\n",
            "Test Acc=0.47\n",
            "[[ 84  88  22]\n",
            " [ 21 155  34]\n",
            " [  0  43  65]]\n",
            "###iteration: 174###\n",
            "train loss= 0.7775, Acc=0.60\n",
            "Test Acc=0.47\n",
            "[[ 86  84  11]\n",
            " [ 33 143  27]\n",
            " [  0  50  78]]\n",
            "###iteration: 175###\n",
            "train loss= 0.7591, Acc=0.61\n",
            "Test Acc=0.48\n",
            "[[ 91  98   6]\n",
            " [ 27 153  23]\n",
            " [  3  42  69]]\n",
            "###iteration: 176###\n",
            "train loss= 0.7702, Acc=0.60\n",
            "Test Acc=0.49\n",
            "[[109  87  11]\n",
            " [ 30 142  21]\n",
            " [  1  53  58]]\n",
            "###iteration: 177###\n",
            "train loss= 0.7920, Acc=0.61\n",
            "Test Acc=0.46\n",
            "[[ 91  99  10]\n",
            " [ 22 179  20]\n",
            " [  2  46  43]]\n",
            "###iteration: 178###\n",
            "train loss= 0.7986, Acc=0.59\n",
            "Test Acc=0.44\n",
            "[[ 84 111  11]\n",
            " [ 12 158  26]\n",
            " [  0  49  61]]\n",
            "###iteration: 179###\n",
            "train loss= 0.7732, Acc=0.63\n",
            "Test Acc=0.42\n",
            "[[ 88  99   9]\n",
            " [ 13 164  23]\n",
            " [  0  46  70]]\n",
            "###iteration: 180###\n",
            "train loss= 0.7558, Acc=0.62\n",
            "Test Acc=0.45\n",
            "[[ 86  98  12]\n",
            " [ 12 166  13]\n",
            " [  0  58  67]]\n",
            "###iteration: 181###\n",
            "train loss= 0.8025, Acc=0.58\n",
            "Test Acc=0.49\n",
            "[[ 92  91  16]\n",
            " [ 21 150  22]\n",
            " [  0  65  55]]\n",
            "###iteration: 182###\n",
            "train loss= 0.8214, Acc=0.57\n",
            "Test Acc=0.48\n",
            "[[ 93 106  15]\n",
            " [ 33 155  23]\n",
            " [  0  42  45]]\n",
            "###iteration: 183###\n",
            "train loss= 0.7900, Acc=0.59\n",
            "Test Acc=0.47\n",
            "[[ 81 103  18]\n",
            " [ 15 149  17]\n",
            " [  0  55  74]]\n",
            "###iteration: 184###\n",
            "train loss= 0.7786, Acc=0.63\n",
            "Test Acc=0.47\n",
            "[[100  92  28]\n",
            " [ 16 156  30]\n",
            " [  0  23  67]]\n",
            "###iteration: 185###\n",
            "train loss= 0.7908, Acc=0.62\n",
            "Test Acc=0.49\n",
            "[[ 86  94  12]\n",
            " [ 28 152  26]\n",
            " [  1  36  77]]\n",
            "###iteration: 186###\n",
            "train loss= 0.7746, Acc=0.60\n",
            "Test Acc=0.57\n",
            "[[130  72  14]\n",
            " [ 41 115  23]\n",
            " [  2  52  63]]\n",
            "###iteration: 187###\n",
            "train loss= 0.7697, Acc=0.58\n",
            "Test Acc=0.61\n",
            "[[138  64  14]\n",
            " [ 64 107  30]\n",
            " [  5  39  51]]\n",
            "###iteration: 188###\n",
            "train loss= 0.7448, Acc=0.62\n",
            "Test Acc=0.58\n",
            "[[119  65  16]\n",
            " [ 51 147  16]\n",
            " [  6  39  53]]\n",
            "###iteration: 189###\n",
            "train loss= 0.8256, Acc=0.60\n",
            "Test Acc=0.49\n",
            "[[ 91  86   9]\n",
            " [ 33 157  30]\n",
            " [  2  45  59]]\n",
            "###iteration: 190###\n",
            "train loss= 0.7517, Acc=0.64\n",
            "Test Acc=0.42\n",
            "[[ 79 105   4]\n",
            " [ 13 170  26]\n",
            " [  1  35  79]]\n",
            "###iteration: 191###\n",
            "train loss= 0.7602, Acc=0.65\n",
            "Test Acc=0.44\n",
            "[[ 98 103  12]\n",
            " [ 11 165  18]\n",
            " [  2  35  68]]\n",
            "###iteration: 192###\n",
            "train loss= 0.7747, Acc=0.61\n",
            "Test Acc=0.50\n",
            "[[101 101   7]\n",
            " [ 32 154  14]\n",
            " [  2  45  56]]\n",
            "###iteration: 193###\n",
            "train loss= 0.8201, Acc=0.58\n",
            "Test Acc=0.46\n",
            "[[ 86 100  14]\n",
            " [ 32 160  19]\n",
            " [  1  49  51]]\n",
            "###iteration: 194###\n",
            "train loss= 0.7750, Acc=0.63\n",
            "Test Acc=0.42\n",
            "[[ 76  80  31]\n",
            " [ 12 164  37]\n",
            " [  1  30  81]]\n",
            "###iteration: 195###\n",
            "train loss= 0.7829, Acc=0.59\n",
            "Test Acc=0.42\n",
            "[[ 77 114   9]\n",
            " [  6 164  37]\n",
            " [  0  42  63]]\n",
            "###iteration: 196###\n",
            "train loss= 0.7485, Acc=0.59\n",
            "Test Acc=0.46\n",
            "[[ 95 115   3]\n",
            " [ 18 156  14]\n",
            " [  2  56  53]]\n",
            "###iteration: 197###\n",
            "train loss= 0.7630, Acc=0.61\n",
            "Test Acc=0.45\n",
            "[[ 95 101   9]\n",
            " [ 16 157  16]\n",
            " [  1  55  62]]\n",
            "###iteration: 198###\n",
            "train loss= 0.8033, Acc=0.59\n",
            "Test Acc=0.43\n",
            "[[ 72 104  13]\n",
            " [ 12 162  33]\n",
            " [  1  46  69]]\n",
            "###iteration: 199###\n",
            "train loss= 0.8060, Acc=0.60\n",
            "Test Acc=0.44\n",
            "[[ 77 106  19]\n",
            " [ 11 153  34]\n",
            " [  1  36  75]]\n",
            "###iteration: 200###\n",
            "train loss= 0.7880, Acc=0.60\n",
            "Test Acc=0.50\n",
            "[[ 92  96  19]\n",
            " [ 22 147  20]\n",
            " [  1  45  70]]\n",
            "###iteration: 201###\n",
            "train loss= 0.7817, Acc=0.59\n",
            "Test Acc=0.53\n",
            "[[110  81   8]\n",
            " [ 39 136  26]\n",
            " [  1  55  56]]\n",
            "###iteration: 202###\n",
            "train loss= 0.7993, Acc=0.60\n",
            "Test Acc=0.49\n",
            "[[ 93  84  10]\n",
            " [ 24 159  21]\n",
            " [  2  62  57]]\n",
            "###iteration: 203###\n",
            "train loss= 0.7929, Acc=0.62\n",
            "Test Acc=0.39\n",
            "[[ 74  93  23]\n",
            " [  9 160  32]\n",
            " [  1  37  83]]\n",
            "###iteration: 204###\n",
            "train loss= 0.7680, Acc=0.61\n",
            "Test Acc=0.40\n",
            "[[ 77 102  14]\n",
            " [ 11 147  38]\n",
            " [  0  33  90]]\n",
            "###iteration: 205###\n",
            "train loss= 0.7806, Acc=0.62\n",
            "Test Acc=0.50\n",
            "[[ 95  92  13]\n",
            " [ 24 161  21]\n",
            " [  3  41  62]]\n",
            "###iteration: 206###\n",
            "train loss= 0.8001, Acc=0.61\n",
            "Test Acc=0.55\n",
            "[[110  71  12]\n",
            " [ 45 129  16]\n",
            " [  1  55  73]]\n",
            "###iteration: 207###\n",
            "train loss= 0.7356, Acc=0.61\n",
            "Test Acc=0.53\n",
            "[[101  80   9]\n",
            " [ 41 137  22]\n",
            " [  2  45  75]]\n",
            "###iteration: 208###\n",
            "train loss= 0.7578, Acc=0.62\n",
            "Test Acc=0.49\n",
            "[[107  84  10]\n",
            " [ 26 138  29]\n",
            " [  0  45  73]]\n",
            "###iteration: 209###\n",
            "train loss= 0.7550, Acc=0.63\n",
            "Test Acc=0.39\n",
            "[[ 81 103  13]\n",
            " [  9 172  28]\n",
            " [  0  38  68]]\n",
            "###iteration: 210###\n",
            "train loss= 0.8209, Acc=0.59\n",
            "Test Acc=0.39\n",
            "[[ 63 120  16]\n",
            " [  6 176  22]\n",
            " [  3  41  65]]\n",
            "###iteration: 211###\n",
            "train loss= 0.7843, Acc=0.62\n",
            "Test Acc=0.43\n",
            "[[ 84 109   9]\n",
            " [ 14 165  16]\n",
            " [  0  47  68]]\n",
            "###iteration: 212###\n",
            "train loss= 0.7495, Acc=0.62\n",
            "Test Acc=0.51\n",
            "[[118  85   7]\n",
            " [ 29 146  25]\n",
            " [  2  47  53]]\n",
            "###iteration: 213###\n",
            "train loss= 0.7142, Acc=0.65\n",
            "Test Acc=0.50\n",
            "[[108  64  14]\n",
            " [ 32 155  26]\n",
            " [  3  39  71]]\n",
            "###iteration: 214###\n",
            "train loss= 0.7859, Acc=0.64\n",
            "Test Acc=0.43\n",
            "[[ 91  80  20]\n",
            " [ 15 158  37]\n",
            " [  2  31  78]]\n",
            "###iteration: 215###\n",
            "train loss= 0.7782, Acc=0.59\n",
            "Test Acc=0.40\n",
            "[[ 74 116  17]\n",
            " [ 17 174  24]\n",
            " [  2  33  55]]\n",
            "###iteration: 216###\n",
            "train loss= 0.7554, Acc=0.63\n",
            "Test Acc=0.43\n",
            "[[ 89 104  10]\n",
            " [ 12 162  16]\n",
            " [  0  48  71]]\n",
            "###iteration: 217###\n",
            "train loss= 0.7480, Acc=0.62\n",
            "Test Acc=0.49\n",
            "[[ 97  97   3]\n",
            " [ 26 163  30]\n",
            " [  1  40  55]]\n",
            "###iteration: 218###\n",
            "train loss= 0.8116, Acc=0.61\n",
            "Test Acc=0.50\n",
            "[[ 94  85  15]\n",
            " [ 29 150  19]\n",
            " [  3  48  69]]\n",
            "###iteration: 219###\n",
            "train loss= 0.7606, Acc=0.64\n",
            "Test Acc=0.46\n",
            "[[ 96  87   9]\n",
            " [ 13 161  30]\n",
            " [  1  43  72]]\n",
            "###iteration: 220###\n",
            "train loss= 0.7440, Acc=0.63\n",
            "Test Acc=0.42\n",
            "[[ 86  97  11]\n",
            " [  9 147  32]\n",
            " [  2  40  88]]\n",
            "###iteration: 221###\n",
            "train loss= 0.8500, Acc=0.53\n",
            "Test Acc=0.40\n",
            "[[ 63 134  14]\n",
            " [ 18 156  20]\n",
            " [  2  53  52]]\n",
            "###iteration: 222###\n",
            "train loss= 0.7778, Acc=0.63\n",
            "Test Acc=0.43\n",
            "[[ 80  94  12]\n",
            " [ 13 186  16]\n",
            " [  0  55  56]]\n",
            "###iteration: 223###\n",
            "train loss= 0.7681, Acc=0.61\n",
            "Test Acc=0.50\n",
            "[[ 93  99  12]\n",
            " [ 22 159  18]\n",
            " [  1  48  60]]\n",
            "###iteration: 224###\n",
            "train loss= 0.7487, Acc=0.63\n",
            "Test Acc=0.51\n",
            "[[ 98  84  18]\n",
            " [ 33 148  26]\n",
            " [  1  27  77]]\n",
            "###iteration: 225###\n",
            "train loss= 0.8129, Acc=0.58\n",
            "Test Acc=0.50\n",
            "[[ 84  87  20]\n",
            " [ 25 129  47]\n",
            " [  1  34  85]]\n",
            "###iteration: 226###\n",
            "train loss= 0.7306, Acc=0.63\n",
            "Test Acc=0.47\n",
            "[[ 98  85  23]\n",
            " [ 20 137  33]\n",
            " [  0  27  89]]\n",
            "###iteration: 227###\n",
            "train loss= 0.7920, Acc=0.64\n",
            "Test Acc=0.47\n",
            "[[ 84  85  13]\n",
            " [ 18 168  26]\n",
            " [  1  42  75]]\n",
            "###iteration: 228###\n",
            "train loss= 0.7550, Acc=0.65\n",
            "Test Acc=0.48\n",
            "[[108  80  18]\n",
            " [ 19 153  19]\n",
            " [  1  44  70]]\n",
            "###iteration: 229###\n",
            "train loss= 0.8071, Acc=0.58\n",
            "Test Acc=0.49\n",
            "[[ 85  90  17]\n",
            " [ 24 133  26]\n",
            " [  0  56  81]]\n",
            "###iteration: 230###\n",
            "train loss= 0.7703, Acc=0.62\n",
            "Test Acc=0.51\n",
            "[[100  68  29]\n",
            " [ 25 140  39]\n",
            " [  1  30  80]]\n",
            "###iteration: 231###\n",
            "train loss= 0.7646, Acc=0.62\n",
            "Test Acc=0.52\n",
            "[[107  76  21]\n",
            " [ 33 137  29]\n",
            " [  5  28  76]]\n",
            "###iteration: 232###\n",
            "train loss= 0.7927, Acc=0.59\n",
            "Test Acc=0.51\n",
            "[[ 97  87  23]\n",
            " [ 34 145  25]\n",
            " [  8  31  62]]\n",
            "###iteration: 233###\n",
            "train loss= 0.8039, Acc=0.60\n",
            "Test Acc=0.49\n",
            "[[ 92  81  14]\n",
            " [ 33 161  21]\n",
            " [  5  49  56]]\n",
            "###iteration: 234###\n",
            "train loss= 0.7821, Acc=0.62\n",
            "Test Acc=0.44\n",
            "[[ 87  95  14]\n",
            " [ 20 159  14]\n",
            " [  6  46  71]]\n",
            "###iteration: 235###\n",
            "train loss= 0.7731, Acc=0.61\n",
            "Test Acc=0.48\n",
            "[[108  88  17]\n",
            " [ 17 126  35]\n",
            " [  2  39  80]]\n",
            "###iteration: 236###\n",
            "train loss= 0.7621, Acc=0.63\n",
            "Test Acc=0.50\n",
            "[[109  60  29]\n",
            " [ 26 124  50]\n",
            " [  2  24  88]]\n",
            "###iteration: 237###\n",
            "train loss= 0.7619, Acc=0.61\n",
            "Test Acc=0.50\n",
            "[[ 84  84  22]\n",
            " [ 38 142  30]\n",
            " [  4  20  88]]\n",
            "###iteration: 238###\n",
            "train loss= 0.7541, Acc=0.60\n",
            "Test Acc=0.46\n",
            "[[ 98  93   8]\n",
            " [ 27 141  20]\n",
            " [  1  56  68]]\n",
            "###iteration: 239###\n",
            "train loss= 0.8317, Acc=0.57\n",
            "Test Acc=0.44\n",
            "[[ 78  96   9]\n",
            " [ 22 169  30]\n",
            " [  2  62  44]]\n",
            "###iteration: 240###\n",
            "train loss= 0.7956, Acc=0.61\n",
            "Test Acc=0.45\n",
            "[[ 68 105  14]\n",
            " [ 20 168  24]\n",
            " [  0  37  76]]\n",
            "###iteration: 241###\n",
            "train loss= 0.7662, Acc=0.62\n",
            "Test Acc=0.48\n",
            "[[ 92  66  19]\n",
            " [ 19 138  57]\n",
            " [  1  35  85]]\n",
            "###iteration: 242###\n",
            "train loss= 0.8012, Acc=0.62\n",
            "Test Acc=0.50\n",
            "[[ 85  74  30]\n",
            " [ 28 155  40]\n",
            " [  1  21  78]]\n",
            "###iteration: 243###\n",
            "train loss= 0.7192, Acc=0.65\n",
            "Test Acc=0.53\n",
            "[[101  79  18]\n",
            " [ 31 144  30]\n",
            " [  1  22  86]]\n",
            "###iteration: 244###\n",
            "train loss= 0.7642, Acc=0.65\n",
            "Test Acc=0.46\n",
            "[[ 95  84   7]\n",
            " [ 17 191  21]\n",
            " [  1  51  45]]\n",
            "###iteration: 245###\n",
            "train loss= 0.8323, Acc=0.54\n",
            "Test Acc=0.33\n",
            "[[ 53 139   7]\n",
            " [ 12 175  13]\n",
            " [  1  63  49]]\n",
            "###iteration: 246###\n",
            "train loss= 0.8089, Acc=0.58\n",
            "Test Acc=0.38\n",
            "[[ 79 123  12]\n",
            " [ 19 168  20]\n",
            " [  2  41  48]]\n",
            "###iteration: 247###\n",
            "train loss= 0.7521, Acc=0.63\n",
            "Test Acc=0.54\n",
            "[[110  79  13]\n",
            " [ 35 138  19]\n",
            " [  3  41  74]]\n",
            "###iteration: 248###\n",
            "train loss= 0.8021, Acc=0.58\n",
            "Test Acc=0.62\n",
            "[[124  55  22]\n",
            " [ 64  89  34]\n",
            " [  7  31  86]]\n",
            "###iteration: 249###\n",
            "train loss= 0.7719, Acc=0.61\n",
            "Test Acc=0.64\n",
            "[[142  42  34]\n",
            " [ 60 100  41]\n",
            " [  7  17  69]]\n",
            "###iteration: 250###\n",
            "train loss= 0.8149, Acc=0.58\n",
            "Test Acc=0.63\n",
            "[[117  52  32]\n",
            " [ 60  95  45]\n",
            " [  6  21  84]]\n",
            "###iteration: 251###\n",
            "train loss= 0.7421, Acc=0.64\n",
            "Test Acc=0.61\n",
            "[[136  47  27]\n",
            " [ 56 111  29]\n",
            " [  6  21  79]]\n",
            "###iteration: 252###\n",
            "train loss= 0.8033, Acc=0.59\n",
            "Test Acc=0.56\n",
            "[[110  69  16]\n",
            " [ 52 129  30]\n",
            " [  2  41  63]]\n",
            "###iteration: 253###\n",
            "train loss= 0.7996, Acc=0.60\n",
            "Test Acc=0.52\n",
            "[[103  85   9]\n",
            " [ 39 153  10]\n",
            " [  5  56  52]]\n",
            "###iteration: 254###\n",
            "train loss= 0.7759, Acc=0.63\n",
            "Test Acc=0.49\n",
            "[[ 99  90   8]\n",
            " [ 20 162  19]\n",
            " [  3  51  60]]\n",
            "###iteration: 255###\n",
            "train loss= 0.8036, Acc=0.60\n",
            "Test Acc=0.48\n",
            "[[ 86  91  18]\n",
            " [ 26 152  30]\n",
            " [  3  38  68]]\n",
            "###iteration: 256###\n",
            "train loss= 0.7634, Acc=0.61\n",
            "Test Acc=0.52\n",
            "[[106  94  16]\n",
            " [ 26 133  29]\n",
            " [  5  28  75]]\n",
            "###iteration: 257###\n",
            "train loss= 0.7791, Acc=0.61\n",
            "Test Acc=0.56\n",
            "[[133  69  10]\n",
            " [ 49 121  25]\n",
            " [  7  40  58]]\n",
            "###iteration: 258###\n",
            "train loss= 0.7928, Acc=0.61\n",
            "Test Acc=0.56\n",
            "[[101  89   3]\n",
            " [ 46 155  15]\n",
            " [  6  42  55]]\n",
            "###iteration: 259###\n",
            "train loss= 0.8054, Acc=0.57\n",
            "Test Acc=0.53\n",
            "[[ 98  97  11]\n",
            " [ 39 142  12]\n",
            " [  2  57  54]]\n",
            "###iteration: 260###\n",
            "train loss= 0.7940, Acc=0.63\n",
            "Test Acc=0.49\n",
            "[[103  80  12]\n",
            " [ 21 151  32]\n",
            " [  4  42  67]]\n",
            "###iteration: 261###\n",
            "train loss= 0.7995, Acc=0.62\n",
            "Test Acc=0.49\n",
            "[[ 99  89  12]\n",
            " [ 19 160  26]\n",
            " [  3  48  56]]\n",
            "###iteration: 262###\n",
            "train loss= 0.8030, Acc=0.61\n",
            "Test Acc=0.50\n",
            "[[ 98  92   4]\n",
            " [ 33 170  21]\n",
            " [  3  49  42]]\n",
            "###iteration: 263###\n",
            "train loss= 0.8192, Acc=0.62\n",
            "Test Acc=0.52\n",
            "[[ 90  84   7]\n",
            " [ 33 162  12]\n",
            " [  2  59  63]]\n",
            "###iteration: 264###\n",
            "train loss= 0.7892, Acc=0.61\n",
            "Test Acc=0.51\n",
            "[[101  87  12]\n",
            " [ 39 140  20]\n",
            " [  0  44  69]]\n",
            "###iteration: 265###\n",
            "train loss= 0.7875, Acc=0.60\n",
            "Test Acc=0.50\n",
            "[[105  96  18]\n",
            " [ 27 123  33]\n",
            " [  2  31  77]]\n",
            "###iteration: 266###\n",
            "train loss= 0.8157, Acc=0.61\n",
            "Test Acc=0.49\n",
            "[[ 96  80  20]\n",
            " [ 27 130  35]\n",
            " [  7  32  85]]\n",
            "###iteration: 267###\n",
            "train loss= 0.8012, Acc=0.61\n",
            "Test Acc=0.47\n",
            "[[ 88  81  22]\n",
            " [ 29 144  24]\n",
            " [  2  43  79]]\n",
            "###iteration: 268###\n",
            "train loss= 0.7968, Acc=0.63\n",
            "Test Acc=0.44\n",
            "[[ 89  88  12]\n",
            " [ 16 171  30]\n",
            " [  1  44  61]]\n",
            "###iteration: 269###\n",
            "train loss= 0.8123, Acc=0.56\n",
            "Test Acc=0.45\n",
            "[[ 79 113  14]\n",
            " [ 15 165  20]\n",
            " [  1  60  45]]\n",
            "###iteration: 270###\n",
            "train loss= 0.7751, Acc=0.63\n",
            "Test Acc=0.49\n",
            "[[ 99  90  10]\n",
            " [ 16 166  19]\n",
            " [  4  51  57]]\n",
            "###iteration: 271###\n",
            "train loss= 0.7613, Acc=0.61\n",
            "Test Acc=0.53\n",
            "[[102  86  10]\n",
            " [ 32 140  25]\n",
            " [  0  48  69]]\n",
            "###iteration: 272###\n",
            "train loss= 0.7673, Acc=0.63\n",
            "Test Acc=0.54\n",
            "[[114  79  16]\n",
            " [ 29 136  32]\n",
            " [  3  31  72]]\n",
            "###iteration: 273###\n",
            "train loss= 0.8165, Acc=0.60\n",
            "Test Acc=0.54\n",
            "[[ 90  71  24]\n",
            " [ 44 117  42]\n",
            " [  4  22  98]]\n",
            "###iteration: 274###\n",
            "train loss= 0.7890, Acc=0.60\n",
            "Test Acc=0.53\n",
            "[[106  82  17]\n",
            " [ 34 129  35]\n",
            " [  3  33  73]]\n",
            "###iteration: 275###\n",
            "train loss= 0.7882, Acc=0.61\n",
            "Test Acc=0.52\n",
            "[[105  66  14]\n",
            " [ 43 137  25]\n",
            " [  1  49  72]]\n",
            "###iteration: 276###\n",
            "train loss= 0.7493, Acc=0.64\n",
            "Test Acc=0.51\n",
            "[[110  86   9]\n",
            " [ 29 155  16]\n",
            " [  7  39  61]]\n",
            "###iteration: 277###\n",
            "train loss= 0.7923, Acc=0.65\n",
            "Test Acc=0.49\n",
            "[[112  78  15]\n",
            " [ 19 156  19]\n",
            " [  5  43  65]]\n",
            "###iteration: 278###\n",
            "train loss= 0.7932, Acc=0.63\n",
            "Test Acc=0.50\n",
            "[[105  71  26]\n",
            " [ 20 117  44]\n",
            " [  5  25  99]]\n",
            "###iteration: 279###\n",
            "train loss= 0.8064, Acc=0.60\n",
            "Test Acc=0.53\n",
            "[[101  66  31]\n",
            " [ 34 108  54]\n",
            " [  2  18  98]]\n",
            "###iteration: 280###\n",
            "train loss= 0.7988, Acc=0.61\n",
            "Test Acc=0.58\n",
            "[[125  54  25]\n",
            " [ 42 120  48]\n",
            " [  4  27  67]]\n",
            "###iteration: 281###\n",
            "train loss= 0.7818, Acc=0.61\n",
            "Test Acc=0.62\n",
            "[[127  54  16]\n",
            " [ 53  98  31]\n",
            " [  6  38  89]]\n",
            "###iteration: 282###\n",
            "train loss= 0.7927, Acc=0.57\n",
            "Test Acc=0.59\n",
            "[[114  71  12]\n",
            " [ 64 118  26]\n",
            " [  3  43  61]]\n",
            "###iteration: 283###\n",
            "train loss= 0.7636, Acc=0.64\n",
            "Test Acc=0.54\n",
            "[[125  91  14]\n",
            " [ 21 150  15]\n",
            " [  1  41  54]]\n",
            "###iteration: 284###\n",
            "train loss= 0.7783, Acc=0.64\n",
            "Test Acc=0.47\n",
            "[[107  84  20]\n",
            " [ 15 149  23]\n",
            " [  1  40  73]]\n",
            "###iteration: 285###\n",
            "train loss= 0.7717, Acc=0.63\n",
            "Test Acc=0.44\n",
            "[[ 93  89  18]\n",
            " [ 12 170  28]\n",
            " [  1  40  61]]\n",
            "###iteration: 286###\n",
            "train loss= 0.7629, Acc=0.63\n",
            "Test Acc=0.46\n",
            "[[ 91  99  23]\n",
            " [ 11 167  22]\n",
            " [  3  31  65]]\n",
            "###iteration: 287###\n",
            "train loss= 0.7827, Acc=0.58\n",
            "Test Acc=0.51\n",
            "[[101 120   9]\n",
            " [ 22 141  24]\n",
            " [  1  39  55]]\n",
            "###iteration: 288###\n",
            "train loss= 0.8005, Acc=0.60\n",
            "Test Acc=0.48\n",
            "[[ 81  97  15]\n",
            " [ 26 158  19]\n",
            " [  1  48  67]]\n",
            "###iteration: 289###\n",
            "train loss= 0.7876, Acc=0.63\n",
            "Test Acc=0.44\n",
            "[[ 86  87  20]\n",
            " [ 19 157  39]\n",
            " [  1  24  79]]\n",
            "###iteration: 290###\n",
            "train loss= 0.7765, Acc=0.63\n",
            "Test Acc=0.44\n",
            "[[ 87  92  23]\n",
            " [ 16 138  29]\n",
            " [  2  26  99]]\n",
            "###iteration: 291###\n",
            "train loss= 0.7948, Acc=0.56\n",
            "Test Acc=0.47\n",
            "[[ 87 106  20]\n",
            " [ 23 136  29]\n",
            " [  2  44  65]]\n",
            "###iteration: 292###\n",
            "train loss= 0.7668, Acc=0.61\n",
            "Test Acc=0.54\n",
            "[[106  75   9]\n",
            " [ 47 151  21]\n",
            " [  1  46  56]]\n",
            "###iteration: 293###\n",
            "train loss= 0.7589, Acc=0.61\n",
            "Test Acc=0.59\n",
            "[[130  78   6]\n",
            " [ 38 123  26]\n",
            " [  8  43  60]]\n",
            "###iteration: 294###\n",
            "train loss= 0.7436, Acc=0.62\n",
            "Test Acc=0.62\n",
            "[[140  60  16]\n",
            " [ 49 105  27]\n",
            " [ 11  34  70]]\n",
            "###iteration: 295###\n",
            "train loss= 0.7743, Acc=0.60\n",
            "Test Acc=0.56\n",
            "[[109  70  18]\n",
            " [ 49 141  34]\n",
            " [  6  29  56]]\n",
            "###iteration: 296###\n",
            "train loss= 0.7890, Acc=0.63\n",
            "Test Acc=0.48\n",
            "[[ 86  77  21]\n",
            " [ 20 155  36]\n",
            " [  9  24  84]]\n",
            "###iteration: 297###\n",
            "train loss= 0.8132, Acc=0.59\n",
            "Test Acc=0.42\n",
            "[[ 95  80  25]\n",
            " [ 13 129  40]\n",
            " [  7  43  80]]\n",
            "###iteration: 298###\n",
            "train loss= 0.7628, Acc=0.63\n",
            "Test Acc=0.44\n",
            "[[ 89  90  17]\n",
            " [ 12 159  26]\n",
            " [  1  42  76]]\n",
            "###iteration: 299###\n",
            "train loss= 0.7861, Acc=0.63\n",
            "Test Acc=0.48\n",
            "[[101  85   6]\n",
            " [ 18 172  19]\n",
            " [  4  57  50]]\n",
            "###iteration: 300###\n",
            "train loss= 0.7381, Acc=0.64\n",
            "Test Acc=0.49\n",
            "[[ 90  92   9]\n",
            " [ 22 167  14]\n",
            " [  2  47  69]]\n",
            "###iteration: 301###\n",
            "train loss= 0.8216, Acc=0.61\n",
            "Test Acc=0.46\n",
            "[[ 77  88  17]\n",
            " [ 15 163  30]\n",
            " [  2  46  74]]\n",
            "###iteration: 302###\n",
            "train loss= 0.8211, Acc=0.61\n",
            "Test Acc=0.44\n",
            "[[ 92  84  34]\n",
            " [  5 143  42]\n",
            " [  1  36  75]]\n",
            "###iteration: 303###\n",
            "train loss= 0.7623, Acc=0.63\n",
            "Test Acc=0.47\n",
            "[[100  78  31]\n",
            " [ 18 131  35]\n",
            " [  0  29  90]]\n",
            "###iteration: 304###\n",
            "train loss= 0.7877, Acc=0.60\n",
            "Test Acc=0.51\n",
            "[[ 98  82  22]\n",
            " [ 37 129  28]\n",
            " [  3  31  82]]\n",
            "###iteration: 305###\n",
            "train loss= 0.8049, Acc=0.60\n",
            "Test Acc=0.57\n",
            "[[114  80  10]\n",
            " [ 40 132  21]\n",
            " [  5  50  60]]\n",
            "###iteration: 306###\n",
            "train loss= 0.7833, Acc=0.60\n",
            "Test Acc=0.56\n",
            "[[124  65  18]\n",
            " [ 58 121  27]\n",
            " [  3  35  61]]\n",
            "###iteration: 307###\n",
            "train loss= 0.7421, Acc=0.65\n",
            "Test Acc=0.53\n",
            "[[ 90  87  10]\n",
            " [ 26 171  20]\n",
            " [  2  35  71]]\n",
            "###iteration: 308###\n",
            "train loss= 0.7797, Acc=0.63\n",
            "Test Acc=0.50\n",
            "[[ 95  99  15]\n",
            " [ 15 159  25]\n",
            " [  3  34  67]]\n",
            "###iteration: 309###\n",
            "train loss= 0.7322, Acc=0.62\n",
            "Test Acc=0.48\n",
            "[[ 99  98  19]\n",
            " [ 21 155  25]\n",
            " [  3  26  66]]\n",
            "###iteration: 310###\n",
            "train loss= 0.7723, Acc=0.62\n",
            "Test Acc=0.47\n",
            "[[ 87 100  13]\n",
            " [ 22 169  23]\n",
            " [  3  35  60]]\n",
            "###iteration: 311###\n",
            "train loss= 0.7345, Acc=0.63\n",
            "Test Acc=0.46\n",
            "[[ 94  93  11]\n",
            " [ 20 150  21]\n",
            " [  4  39  80]]\n",
            "###iteration: 312###\n",
            "train loss= 0.7378, Acc=0.66\n",
            "Test Acc=0.46\n",
            "[[100  86   9]\n",
            " [ 15 167  22]\n",
            " [  1  43  69]]\n",
            "###iteration: 313###\n",
            "train loss= 0.8009, Acc=0.62\n",
            "Test Acc=0.47\n",
            "[[ 86 100  15]\n",
            " [ 13 165  25]\n",
            " [  1  42  65]]\n",
            "###iteration: 314###\n",
            "train loss= 0.8037, Acc=0.63\n",
            "Test Acc=0.47\n",
            "[[ 89  84  20]\n",
            " [ 20 164  25]\n",
            " [  3  36  71]]\n",
            "###iteration: 315###\n",
            "train loss= 0.7828, Acc=0.60\n",
            "Test Acc=0.47\n",
            "[[ 97 103  17]\n",
            " [ 21 128  34]\n",
            " [  2  30  80]]\n",
            "###iteration: 316###\n",
            "train loss= 0.7786, Acc=0.60\n",
            "Test Acc=0.49\n",
            "[[ 91 102  16]\n",
            " [ 21 149  34]\n",
            " [  2  32  65]]\n",
            "###iteration: 317###\n",
            "train loss= 0.7347, Acc=0.64\n",
            "Test Acc=0.50\n",
            "[[107  75  13]\n",
            " [ 22 135  28]\n",
            " [  5  39  88]]\n",
            "###iteration: 318###\n",
            "train loss= 0.7606, Acc=0.62\n",
            "Test Acc=0.49\n",
            "[[ 96  80  22]\n",
            " [ 24 131  30]\n",
            " [  3  34  92]]\n",
            "###iteration: 319###\n",
            "train loss= 0.7508, Acc=0.59\n",
            "Test Acc=0.55\n",
            "[[119  84  13]\n",
            " [ 43 103  40]\n",
            " [  4  26  80]]\n",
            "###iteration: 320###\n",
            "train loss= 0.7793, Acc=0.62\n",
            "Test Acc=0.65\n",
            "[[148  52  13]\n",
            " [ 62 109  27]\n",
            " [  8  34  59]]\n",
            "###iteration: 321###\n",
            "train loss= 0.7878, Acc=0.59\n",
            "Test Acc=0.67\n",
            "[[142  46   9]\n",
            " [ 86 107  22]\n",
            " [ 10  38  52]]\n",
            "###iteration: 322###\n",
            "train loss= 0.7717, Acc=0.63\n",
            "Test Acc=0.60\n",
            "[[127  64  10]\n",
            " [ 43 142  20]\n",
            " [  4  48  54]]\n",
            "###iteration: 323###\n",
            "train loss= 0.7636, Acc=0.61\n",
            "Test Acc=0.51\n",
            "[[101  94  14]\n",
            " [ 22 134  26]\n",
            " [  5  39  77]]\n",
            "###iteration: 324###\n",
            "train loss= 0.7560, Acc=0.66\n",
            "Test Acc=0.43\n",
            "[[ 78  81  16]\n",
            " [ 20 161  34]\n",
            " [  2  23  97]]\n",
            "###iteration: 325###\n",
            "train loss= 0.7743, Acc=0.63\n",
            "Test Acc=0.42\n",
            "[[ 81  85  22]\n",
            " [ 12 159  32]\n",
            " [  2  34  85]]\n",
            "###iteration: 326###\n",
            "train loss= 0.7413, Acc=0.64\n",
            "Test Acc=0.45\n",
            "[[ 90  92   9]\n",
            " [ 11 166  32]\n",
            " [  1  41  70]]\n",
            "###iteration: 327###\n",
            "train loss= 0.7886, Acc=0.62\n",
            "Test Acc=0.47\n",
            "[[ 88  96   8]\n",
            " [ 16 170  12]\n",
            " [  0  63  59]]\n",
            "###iteration: 328###\n",
            "train loss= 0.7570, Acc=0.62\n",
            "Test Acc=0.47\n",
            "[[105  99   5]\n",
            " [ 25 162  15]\n",
            " [  5  46  50]]\n",
            "###iteration: 329###\n",
            "train loss= 0.7094, Acc=0.67\n",
            "Test Acc=0.47\n",
            "[[101  94   9]\n",
            " [ 13 157  23]\n",
            " [  1  28  86]]\n",
            "###iteration: 330###\n",
            "train loss= 0.7934, Acc=0.61\n",
            "Test Acc=0.47\n",
            "[[ 86  95  13]\n",
            " [ 12 156  41]\n",
            " [  1  39  69]]\n",
            "###iteration: 331###\n",
            "train loss= 0.8111, Acc=0.61\n",
            "Test Acc=0.50\n",
            "[[ 83  80  23]\n",
            " [ 21 148  31]\n",
            " [  0  44  82]]\n",
            "###iteration: 332###\n",
            "train loss= 0.7531, Acc=0.61\n",
            "Test Acc=0.56\n",
            "[[108  79  15]\n",
            " [ 46 149  23]\n",
            " [  4  32  56]]\n",
            "###iteration: 333###\n",
            "train loss= 0.8080, Acc=0.62\n",
            "Test Acc=0.56\n",
            "[[128  65  13]\n",
            " [ 40 134  18]\n",
            " [ 11  45  58]]\n",
            "###iteration: 334###\n",
            "train loss= 0.8153, Acc=0.60\n",
            "Test Acc=0.56\n",
            "[[115  74  14]\n",
            " [ 35 136  24]\n",
            " [ 15  43  56]]\n",
            "###iteration: 335###\n",
            "train loss= 0.7599, Acc=0.63\n",
            "Test Acc=0.55\n",
            "[[122  83  12]\n",
            " [ 35 131  15]\n",
            " [ 15  27  72]]\n",
            "###iteration: 336###\n",
            "train loss= 0.7365, Acc=0.64\n",
            "Test Acc=0.57\n",
            "[[124  76  14]\n",
            " [ 40 129  27]\n",
            " [  9  20  73]]\n",
            "###iteration: 337###\n",
            "train loss= 0.7579, Acc=0.66\n",
            "Test Acc=0.55\n",
            "[[105  73  12]\n",
            " [ 34 152  23]\n",
            " [ 12  22  79]]\n",
            "###iteration: 338###\n",
            "train loss= 0.7174, Acc=0.66\n",
            "Test Acc=0.51\n",
            "[[106  73  10]\n",
            " [ 34 163  28]\n",
            " [  7  23  68]]\n",
            "###iteration: 339###\n",
            "train loss= 0.7688, Acc=0.62\n",
            "Test Acc=0.44\n",
            "[[ 93 101   9]\n",
            " [ 16 167  20]\n",
            " [  5  43  58]]\n",
            "###iteration: 340###\n",
            "train loss= 0.7815, Acc=0.62\n",
            "Test Acc=0.42\n",
            "[[ 96  99  11]\n",
            " [ 10 148  30]\n",
            " [  3  42  73]]\n",
            "###iteration: 341###\n",
            "train loss= 0.7390, Acc=0.64\n",
            "Test Acc=0.46\n",
            "[[107  84  22]\n",
            " [ 13 130  33]\n",
            " [  3  27  93]]\n",
            "###iteration: 342###\n",
            "train loss= 0.7775, Acc=0.60\n",
            "Test Acc=0.52\n",
            "[[111  66  32]\n",
            " [ 27 110  50]\n",
            " [  5  25  86]]\n",
            "###iteration: 343###\n",
            "train loss= 0.7857, Acc=0.63\n",
            "Test Acc=0.59\n",
            "[[127  50  20]\n",
            " [ 46 112  44]\n",
            " [  9  22  82]]\n",
            "###iteration: 344###\n",
            "train loss= 0.7883, Acc=0.63\n",
            "Test Acc=0.64\n",
            "[[141  50  13]\n",
            " [ 56 100  31]\n",
            " [ 11  30  80]]\n",
            "###iteration: 345###\n",
            "train loss= 0.7533, Acc=0.63\n",
            "Test Acc=0.59\n",
            "[[115  53   8]\n",
            " [ 43 149  31]\n",
            " [ 17  36  60]]\n",
            "###iteration: 346###\n",
            "train loss= 0.7348, Acc=0.65\n",
            "Test Acc=0.53\n",
            "[[130  82  11]\n",
            " [ 33 126  22]\n",
            " [  3  29  76]]\n",
            "###iteration: 347###\n",
            "train loss= 0.7843, Acc=0.62\n",
            "Test Acc=0.46\n",
            "[[ 87  94  16]\n",
            " [ 15 156  29]\n",
            " [  5  37  73]]\n",
            "###iteration: 348###\n",
            "train loss= 0.7407, Acc=0.66\n",
            "Test Acc=0.46\n",
            "[[119  81  17]\n",
            " [ 18 145  35]\n",
            " [  1  21  75]]\n",
            "###iteration: 349###\n",
            "train loss= 0.7553, Acc=0.65\n",
            "Test Acc=0.51\n",
            "[[110  84  13]\n",
            " [ 25 156  23]\n",
            " [  4  28  69]]\n",
            "###iteration: 350###\n",
            "train loss= 0.7806, Acc=0.62\n",
            "Test Acc=0.53\n",
            "[[110  72  15]\n",
            " [ 36 138  21]\n",
            " [  3  46  71]]\n",
            "###iteration: 351###\n",
            "train loss= 0.7729, Acc=0.60\n",
            "Test Acc=0.58\n",
            "[[129  84  16]\n",
            " [ 37 128  14]\n",
            " [  8  45  51]]\n",
            "###iteration: 352###\n",
            "train loss= 0.7734, Acc=0.60\n",
            "Test Acc=0.58\n",
            "[[102  69  12]\n",
            " [ 50 125  30]\n",
            " [  4  41  79]]\n",
            "###iteration: 353###\n",
            "train loss= 0.7535, Acc=0.62\n",
            "Test Acc=0.53\n",
            "[[ 96  69  22]\n",
            " [ 31 140  38]\n",
            " [  3  29  84]]\n",
            "###iteration: 354###\n",
            "train loss= 0.7621, Acc=0.63\n",
            "Test Acc=0.50\n",
            "[[104  89  24]\n",
            " [ 15 131  32]\n",
            " [  3  27  87]]\n",
            "###iteration: 355###\n",
            "train loss= 0.7773, Acc=0.62\n",
            "Test Acc=0.49\n",
            "[[ 95  78  26]\n",
            " [ 23 143  43]\n",
            " [  2  20  82]]\n",
            "###iteration: 356###\n",
            "train loss= 0.7902, Acc=0.62\n",
            "Test Acc=0.50\n",
            "[[ 96  74  17]\n",
            " [ 20 144  42]\n",
            " [  2  39  78]]\n",
            "###iteration: 357###\n",
            "train loss= 0.7882, Acc=0.63\n",
            "Test Acc=0.51\n",
            "[[ 97  88  15]\n",
            " [ 25 157  21]\n",
            " [  3  39  67]]\n",
            "###iteration: 358###\n",
            "train loss= 0.7879, Acc=0.63\n",
            "Test Acc=0.50\n",
            "[[ 90  83  19]\n",
            " [ 24 153  20]\n",
            " [  4  39  80]]\n",
            "###iteration: 359###\n",
            "train loss= 0.7286, Acc=0.66\n",
            "Test Acc=0.49\n",
            "[[112  73  16]\n",
            " [ 20 163  29]\n",
            " [  5  32  62]]\n",
            "###iteration: 360###\n",
            "train loss= 0.7341, Acc=0.63\n",
            "Test Acc=0.47\n",
            "[[103  94  15]\n",
            " [ 18 132  33]\n",
            " [  3  27  87]]\n",
            "###iteration: 361###\n",
            "train loss= 0.7724, Acc=0.63\n",
            "Test Acc=0.46\n",
            "[[ 89  85  11]\n",
            " [ 16 158  33]\n",
            " [  8  36  76]]\n",
            "###iteration: 362###\n",
            "train loss= 0.7773, Acc=0.59\n",
            "Test Acc=0.48\n",
            "[[ 92 111  16]\n",
            " [ 19 138  21]\n",
            " [  3  41  71]]\n",
            "###iteration: 363###\n",
            "train loss= 0.8279, Acc=0.58\n",
            "Test Acc=0.51\n",
            "[[ 87  94  11]\n",
            " [ 25 156  26]\n",
            " [  5  53  55]]\n",
            "###iteration: 364###\n",
            "train loss= 0.7673, Acc=0.62\n",
            "Test Acc=0.52\n",
            "[[ 96  75  14]\n",
            " [ 29 146  22]\n",
            " [  5  50  75]]\n",
            "###iteration: 365###\n",
            "train loss= 0.7920, Acc=0.63\n",
            "Test Acc=0.50\n",
            "[[ 94  77  25]\n",
            " [ 16 151  35]\n",
            " [  7  28  79]]\n",
            "###iteration: 366###\n",
            "train loss= 0.7596, Acc=0.62\n",
            "Test Acc=0.48\n",
            "[[100  88  19]\n",
            " [ 21 138  39]\n",
            " [  3  26  78]]\n",
            "###iteration: 367###\n",
            "train loss= 0.6884, Acc=0.66\n",
            "Test Acc=0.47\n",
            "[[113  78  15]\n",
            " [ 15 141  38]\n",
            " [  1  26  85]]\n",
            "###iteration: 368###\n",
            "train loss= 0.7644, Acc=0.62\n",
            "Test Acc=0.47\n",
            "[[ 91 103  14]\n",
            " [ 15 143  30]\n",
            " [  2  33  81]]\n",
            "###iteration: 369###\n",
            "train loss= 0.7718, Acc=0.61\n",
            "Test Acc=0.49\n",
            "[[107  89  14]\n",
            " [ 25 137  27]\n",
            " [  2  41  70]]\n",
            "###iteration: 370###\n",
            "train loss= 0.7189, Acc=0.64\n",
            "Test Acc=0.50\n",
            "[[114  90  14]\n",
            " [ 24 144  23]\n",
            " [  2  29  72]]\n",
            "###iteration: 371###\n",
            "train loss= 0.7121, Acc=0.66\n",
            "Test Acc=0.49\n",
            "[[107  74  20]\n",
            " [ 21 135  31]\n",
            " [  4  26  94]]\n",
            "###iteration: 372###\n",
            "train loss= 0.7495, Acc=0.64\n",
            "Test Acc=0.47\n",
            "[[ 98  70  32]\n",
            " [ 23 141  40]\n",
            " [  6  15  87]]\n",
            "###iteration: 373###\n",
            "train loss= 0.7841, Acc=0.61\n",
            "Test Acc=0.45\n",
            "[[ 83  94  21]\n",
            " [ 14 151  43]\n",
            " [  4  25  77]]\n",
            "###iteration: 374###\n",
            "train loss= 0.7615, Acc=0.61\n",
            "Test Acc=0.48\n",
            "[[ 94 106  18]\n",
            " [ 11 156  18]\n",
            " [  3  43  63]]\n",
            "###iteration: 375###\n",
            "train loss= 0.7115, Acc=0.68\n",
            "Test Acc=0.50\n",
            "[[100  65   9]\n",
            " [ 19 172  28]\n",
            " [  3  40  76]]\n",
            "###iteration: 376###\n",
            "train loss= 0.7193, Acc=0.69\n",
            "Test Acc=0.51\n",
            "[[107  79  11]\n",
            " [ 18 172  18]\n",
            " [  5  30  72]]\n",
            "###iteration: 377###\n",
            "train loss= 0.7702, Acc=0.65\n",
            "Test Acc=0.52\n",
            "[[107  89  12]\n",
            " [ 25 147  28]\n",
            " [  3  24  77]]\n",
            "###iteration: 378###\n",
            "train loss= 0.7698, Acc=0.63\n",
            "Test Acc=0.50\n",
            "[[ 93  69  20]\n",
            " [ 24 142  43]\n",
            " [  2  32  87]]\n",
            "###iteration: 379###\n",
            "train loss= 0.7004, Acc=0.69\n",
            "Test Acc=0.48\n",
            "[[109  65  27]\n",
            " [ 14 155  30]\n",
            " [  2  22  88]]\n",
            "###iteration: 380###\n",
            "train loss= 0.7576, Acc=0.63\n",
            "Test Acc=0.48\n",
            "[[ 95  99  21]\n",
            " [ 16 146  28]\n",
            " [  1  25  81]]\n",
            "###iteration: 381###\n",
            "train loss= 0.7790, Acc=0.62\n",
            "Test Acc=0.48\n",
            "[[ 86  86  16]\n",
            " [ 23 149  24]\n",
            " [  4  40  84]]\n",
            "###iteration: 382###\n",
            "train loss= 0.7837, Acc=0.57\n",
            "Test Acc=0.52\n",
            "[[102  98  19]\n",
            " [ 28 129  27]\n",
            " [ 10  38  61]]\n",
            "###iteration: 383###\n",
            "train loss= 0.7806, Acc=0.59\n",
            "Test Acc=0.55\n",
            "[[107  87  18]\n",
            " [ 34 132  29]\n",
            " [ 14  30  61]]\n",
            "###iteration: 384###\n",
            "train loss= 0.7314, Acc=0.67\n",
            "Test Acc=0.53\n",
            "[[102  67  12]\n",
            " [ 35 154  32]\n",
            " [  5  16  89]]\n",
            "###iteration: 385###\n",
            "train loss= 0.7040, Acc=0.68\n",
            "Test Acc=0.53\n",
            "[[107  60  21]\n",
            " [ 26 135  36]\n",
            " [  0  20 107]]\n",
            "###iteration: 386###\n",
            "train loss= 0.8076, Acc=0.59\n",
            "Test Acc=0.51\n",
            "[[ 92  87  26]\n",
            " [ 31 137  33]\n",
            " [  9  25  72]]\n",
            "###iteration: 387###\n",
            "train loss= 0.7546, Acc=0.63\n",
            "Test Acc=0.48\n",
            "[[ 93  72  16]\n",
            " [ 25 148  26]\n",
            " [  4  44  84]]\n",
            "###iteration: 388###\n",
            "train loss= 0.7823, Acc=0.60\n",
            "Test Acc=0.51\n",
            "[[ 98  90  11]\n",
            " [ 30 162  22]\n",
            " [  4  49  46]]\n",
            "###iteration: 389###\n",
            "train loss= 0.7765, Acc=0.57\n",
            "Test Acc=0.58\n",
            "[[128  90  15]\n",
            " [ 45 102  16]\n",
            " [  3  53  60]]\n",
            "###iteration: 390###\n",
            "train loss= 0.7659, Acc=0.63\n",
            "Test Acc=0.59\n",
            "[[126  66  16]\n",
            " [ 43 130  34]\n",
            " [  1  27  69]]\n",
            "###iteration: 391###\n",
            "train loss= 0.8188, Acc=0.60\n",
            "Test Acc=0.51\n",
            "[[ 79  61  41]\n",
            " [ 28 122  55]\n",
            " [  0  19 107]]\n",
            "###iteration: 392###\n",
            "train loss= 0.7704, Acc=0.62\n",
            "Test Acc=0.47\n",
            "[[ 93  57  35]\n",
            " [ 18 123  70]\n",
            " [  1  16  99]]\n",
            "###iteration: 393###\n",
            "train loss= 0.7458, Acc=0.66\n",
            "Test Acc=0.48\n",
            "[[ 89  73  23]\n",
            " [ 22 169  36]\n",
            " [  3  18  79]]\n",
            "###iteration: 394###\n",
            "train loss= 0.7546, Acc=0.63\n",
            "Test Acc=0.51\n",
            "[[116  80  12]\n",
            " [ 25 154  14]\n",
            " [  7  50  54]]\n",
            "###iteration: 395###\n",
            "train loss= 0.7672, Acc=0.62\n",
            "Test Acc=0.50\n",
            "[[104  90   5]\n",
            " [ 23 162  14]\n",
            " [  4  57  53]]\n",
            "###iteration: 396###\n",
            "train loss= 0.7460, Acc=0.63\n",
            "Test Acc=0.47\n",
            "[[107  95  12]\n",
            " [ 22 151  19]\n",
            " [  2  41  63]]\n",
            "###iteration: 397###\n",
            "train loss= 0.8144, Acc=0.58\n",
            "Test Acc=0.47\n",
            "[[ 90  92  15]\n",
            " [ 23 145  39]\n",
            " [  5  39  64]]\n",
            "###iteration: 398###\n",
            "train loss= 0.7402, Acc=0.64\n",
            "Test Acc=0.51\n",
            "[[118  78  16]\n",
            " [ 30 120  33]\n",
            " [  4  25  88]]\n",
            "###iteration: 399###\n",
            "train loss= 0.7615, Acc=0.63\n",
            "Test Acc=0.56\n",
            "[[109  56  20]\n",
            " [ 34 129  45]\n",
            " [  3  29  87]]\n",
            "###iteration: 400###\n",
            "train loss= 0.7970, Acc=0.59\n",
            "Test Acc=0.57\n",
            "[[109  64  23]\n",
            " [ 44 117  43]\n",
            " [  7  30  75]]\n",
            "###iteration: 401###\n",
            "train loss= 0.7532, Acc=0.63\n",
            "Test Acc=0.53\n",
            "[[115  77  20]\n",
            " [ 38 133  31]\n",
            " [  2  20  76]]\n",
            "###iteration: 402###\n",
            "train loss= 0.7683, Acc=0.62\n",
            "Test Acc=0.49\n",
            "[[ 94  93  13]\n",
            " [ 29 137  27]\n",
            " [  7  24  88]]\n",
            "###iteration: 403###\n",
            "train loss= 0.7582, Acc=0.66\n",
            "Test Acc=0.48\n",
            "[[107  74  17]\n",
            " [  8 156  31]\n",
            " [  4  39  76]]\n",
            "###iteration: 404###\n",
            "train loss= 0.7642, Acc=0.61\n",
            "Test Acc=0.50\n",
            "[[ 95  85  16]\n",
            " [ 29 145  32]\n",
            " [  6  30  74]]\n",
            "###iteration: 405###\n",
            "train loss= 0.8102, Acc=0.60\n",
            "Test Acc=0.51\n",
            "[[ 88  85  21]\n",
            " [ 19 143  30]\n",
            " [  6  42  78]]\n",
            "###iteration: 406###\n",
            "train loss= 0.7189, Acc=0.66\n",
            "Test Acc=0.50\n",
            "[[105  76  16]\n",
            " [ 18 150  33]\n",
            " [  3  28  83]]\n",
            "###iteration: 407###\n",
            "train loss= 0.7572, Acc=0.64\n",
            "Test Acc=0.46\n",
            "[[ 94  82  20]\n",
            " [  8 152  33]\n",
            " [  6  37  80]]\n",
            "###iteration: 408###\n",
            "train loss= 0.7394, Acc=0.68\n",
            "Test Acc=0.47\n",
            "[[ 98  82  17]\n",
            " [ 11 166  25]\n",
            " [  3  27  83]]\n",
            "###iteration: 409###\n",
            "train loss= 0.8034, Acc=0.59\n",
            "Test Acc=0.53\n",
            "[[ 94  95  13]\n",
            " [ 28 135  27]\n",
            " [  2  45  73]]\n",
            "###iteration: 410###\n",
            "train loss= 0.7709, Acc=0.61\n",
            "Test Acc=0.56\n",
            "[[ 93  71  18]\n",
            " [ 42 131  22]\n",
            " [  5  44  86]]\n",
            "###iteration: 411###\n",
            "train loss= 0.7835, Acc=0.59\n",
            "Test Acc=0.57\n",
            "[[112  66  20]\n",
            " [ 50 116  38]\n",
            " [  2  32  76]]\n",
            "###iteration: 412###\n",
            "train loss= 0.7505, Acc=0.57\n",
            "Test Acc=0.56\n",
            "[[107  86  20]\n",
            " [ 50 112  35]\n",
            " [  2  25  75]]\n",
            "###iteration: 413###\n",
            "train loss= 0.7656, Acc=0.63\n",
            "Test Acc=0.54\n",
            "[[104  63  16]\n",
            " [ 33 129  43]\n",
            " [  4  32  88]]\n",
            "###iteration: 414###\n",
            "train loss= 0.7587, Acc=0.63\n",
            "Test Acc=0.54\n",
            "[[110  90  12]\n",
            " [ 26 144  23]\n",
            " [  3  36  68]]\n",
            "###iteration: 415###\n",
            "train loss= 0.7322, Acc=0.65\n",
            "Test Acc=0.51\n",
            "[[112  82  15]\n",
            " [ 26 137  22]\n",
            " [  4  32  82]]\n",
            "###iteration: 416###\n",
            "train loss= 0.7694, Acc=0.60\n",
            "Test Acc=0.45\n",
            "[[ 81  95  21]\n",
            " [ 28 153  28]\n",
            " [  1  31  74]]\n",
            "###iteration: 417###\n",
            "train loss= 0.7722, Acc=0.64\n",
            "Test Acc=0.43\n",
            "[[ 97  86  14]\n",
            " [ 16 154  27]\n",
            " [  3  40  75]]\n",
            "###iteration: 418###\n",
            "train loss= 0.7310, Acc=0.62\n",
            "Test Acc=0.47\n",
            "[[ 91 102  14]\n",
            " [ 22 146  22]\n",
            " [  1  35  79]]\n",
            "###iteration: 419###\n",
            "train loss= 0.7736, Acc=0.63\n",
            "Test Acc=0.52\n",
            "[[ 98  84   9]\n",
            " [ 31 170  26]\n",
            " [  1  38  55]]\n",
            "###iteration: 420###\n",
            "train loss= 0.7787, Acc=0.64\n",
            "Test Acc=0.54\n",
            "[[116  87   7]\n",
            " [ 31 135  22]\n",
            " [  2  33  79]]\n",
            "###iteration: 421###\n",
            "train loss= 0.7114, Acc=0.65\n",
            "Test Acc=0.51\n",
            "[[110  78  17]\n",
            " [ 24 139  30]\n",
            " [  7  22  85]]\n",
            "###iteration: 422###\n",
            "train loss= 0.7376, Acc=0.64\n",
            "Test Acc=0.48\n",
            "[[ 88  81  18]\n",
            " [ 19 150  32]\n",
            " [  2  31  91]]\n",
            "###iteration: 423###\n",
            "train loss= 0.7993, Acc=0.60\n",
            "Test Acc=0.47\n",
            "[[ 86  94  23]\n",
            " [ 20 130  44]\n",
            " [  1  24  90]]\n",
            "###iteration: 424###\n",
            "train loss= 0.7088, Acc=0.66\n",
            "Test Acc=0.52\n",
            "[[108  85  12]\n",
            " [ 20 158  25]\n",
            " [  3  31  70]]\n",
            "###iteration: 425###\n",
            "train loss= 0.7827, Acc=0.64\n",
            "Test Acc=0.53\n",
            "[[100  80  10]\n",
            " [ 24 160  18]\n",
            " [  7  46  67]]\n",
            "###iteration: 426###\n",
            "train loss= 0.7554, Acc=0.64\n",
            "Test Acc=0.50\n",
            "[[106  79  13]\n",
            " [ 22 149  30]\n",
            " [  5  34  74]]\n",
            "###iteration: 427###\n",
            "train loss= 0.7669, Acc=0.64\n",
            "Test Acc=0.48\n",
            "[[103  93  12]\n",
            " [ 12 169  32]\n",
            " [  6  27  58]]\n",
            "###iteration: 428###\n",
            "train loss= 0.7612, Acc=0.64\n",
            "Test Acc=0.48\n",
            "[[103  95   9]\n",
            " [ 13 166  18]\n",
            " [  7  44  57]]\n",
            "###iteration: 429###\n",
            "train loss= 0.7269, Acc=0.69\n",
            "Test Acc=0.50\n",
            "[[127  72  14]\n",
            " [ 17 139  23]\n",
            " [  4  30  86]]\n",
            "###iteration: 430###\n",
            "train loss= 0.7725, Acc=0.61\n",
            "Test Acc=0.53\n",
            "[[115  74  24]\n",
            " [ 34 109  31]\n",
            " [  4  34  87]]\n",
            "###iteration: 431###\n",
            "train loss= 0.7172, Acc=0.64\n",
            "Test Acc=0.53\n",
            "[[106  70  14]\n",
            " [ 42 142  29]\n",
            " [  3  28  78]]\n",
            "###iteration: 432###\n",
            "train loss= 0.7422, Acc=0.63\n",
            "Test Acc=0.54\n",
            "[[112  81  15]\n",
            " [ 30 145  25]\n",
            " [  2  37  65]]\n",
            "###iteration: 433###\n",
            "train loss= 0.7615, Acc=0.60\n",
            "Test Acc=0.53\n",
            "[[ 97  85  15]\n",
            " [ 30 156  23]\n",
            " [  2  48  56]]\n",
            "###iteration: 434###\n",
            "train loss= 0.7539, Acc=0.63\n",
            "Test Acc=0.49\n",
            "[[101  94  19]\n",
            " [ 18 146  22]\n",
            " [  2  32  78]]\n",
            "###iteration: 435###\n",
            "train loss= 0.7396, Acc=0.62\n",
            "Test Acc=0.47\n",
            "[[ 87  87  20]\n",
            " [ 25 145  46]\n",
            " [  1  17  84]]\n",
            "###iteration: 436###\n",
            "train loss= 0.7995, Acc=0.60\n",
            "Test Acc=0.47\n",
            "[[ 89 100  16]\n",
            " [ 22 153  35]\n",
            " [  2  30  65]]\n",
            "###iteration: 437###\n",
            "train loss= 0.7528, Acc=0.61\n",
            "Test Acc=0.50\n",
            "[[103  94   9]\n",
            " [ 29 149  18]\n",
            " [  8  44  58]]\n",
            "###iteration: 438###\n",
            "train loss= 0.7481, Acc=0.63\n",
            "Test Acc=0.51\n",
            "[[ 99  94   6]\n",
            " [ 30 147  17]\n",
            " [  5  39  75]]\n",
            "###iteration: 439###\n",
            "train loss= 0.7250, Acc=0.64\n",
            "Test Acc=0.51\n",
            "[[ 94  85  16]\n",
            " [ 21 150  30]\n",
            " [  6  26  84]]\n",
            "###iteration: 440###\n",
            "train loss= 0.7323, Acc=0.65\n",
            "Test Acc=0.51\n",
            "[[100  70  24]\n",
            " [ 17 130  41]\n",
            " [ 10  18 102]]\n",
            "###iteration: 441###\n",
            "train loss= 0.8244, Acc=0.57\n",
            "Test Acc=0.51\n",
            "[[ 94  71  36]\n",
            " [ 41 128  46]\n",
            " [  5  23  68]]\n",
            "###iteration: 442###\n",
            "train loss= 0.7730, Acc=0.62\n",
            "Test Acc=0.53\n",
            "[[107  81  18]\n",
            " [ 31 143  34]\n",
            " [  6  24  68]]\n",
            "###iteration: 443###\n",
            "train loss= 0.7324, Acc=0.66\n",
            "Test Acc=0.54\n",
            "[[101  67  12]\n",
            " [ 31 162  25]\n",
            " [  2  36  76]]\n",
            "###iteration: 444###\n",
            "train loss= 0.7732, Acc=0.61\n",
            "Test Acc=0.52\n",
            "[[107  83  17]\n",
            " [ 36 119  29]\n",
            " [  3  32  86]]\n",
            "###iteration: 445###\n",
            "train loss= 0.7367, Acc=0.66\n",
            "Test Acc=0.47\n",
            "[[ 93  70  13]\n",
            " [ 22 150  49]\n",
            " [  2  18  95]]\n",
            "###iteration: 446###\n",
            "train loss= 0.7000, Acc=0.64\n",
            "Test Acc=0.46\n",
            "[[ 85  95  13]\n",
            " [ 16 147  33]\n",
            " [  1  24  98]]\n",
            "###iteration: 447###\n",
            "train loss= 0.7274, Acc=0.64\n",
            "Test Acc=0.48\n",
            "[[ 98  95  22]\n",
            " [ 12 152  29]\n",
            " [  0  26  78]]\n",
            "###iteration: 448###\n",
            "train loss= 0.7487, Acc=0.63\n",
            "Test Acc=0.51\n",
            "[[108  94  11]\n",
            " [ 23 152  20]\n",
            " [  3  38  63]]\n",
            "###iteration: 449###\n",
            "train loss= 0.7422, Acc=0.63\n",
            "Test Acc=0.53\n",
            "[[117  78   9]\n",
            " [ 32 144  23]\n",
            " [  2  47  60]]\n",
            "###iteration: 450###\n",
            "train loss= 0.7661, Acc=0.62\n",
            "Test Acc=0.50\n",
            "[[105  82   9]\n",
            " [ 24 147  34]\n",
            " [  1  42  68]]\n",
            "###iteration: 451###\n",
            "train loss= 0.7692, Acc=0.65\n",
            "Test Acc=0.47\n",
            "[[ 89  76  28]\n",
            " [ 20 145  31]\n",
            " [  4  21  98]]\n",
            "###iteration: 452###\n",
            "train loss= 0.7713, Acc=0.62\n",
            "Test Acc=0.47\n",
            "[[ 76  87  19]\n",
            " [ 11 144  43]\n",
            " [  9  27  96]]\n",
            "###iteration: 453###\n",
            "train loss= 0.7633, Acc=0.62\n",
            "Test Acc=0.51\n",
            "[[106  84  16]\n",
            " [ 28 121  36]\n",
            " [  4  28  89]]\n",
            "###iteration: 454###\n",
            "train loss= 0.7541, Acc=0.63\n",
            "Test Acc=0.54\n",
            "[[106  79  16]\n",
            " [ 37 163  16]\n",
            " [  3  36  56]]\n",
            "###iteration: 455###\n",
            "train loss= 0.7413, Acc=0.62\n",
            "Test Acc=0.57\n",
            "[[116  84  16]\n",
            " [ 36 152  14]\n",
            " [  2  43  49]]\n",
            "###iteration: 456###\n",
            "train loss= 0.7371, Acc=0.66\n",
            "Test Acc=0.54\n",
            "[[107  75  14]\n",
            " [ 30 166  14]\n",
            " [  8  34  64]]\n",
            "###iteration: 457###\n",
            "train loss= 0.7167, Acc=0.64\n",
            "Test Acc=0.49\n",
            "[[116  84   7]\n",
            " [ 21 141  34]\n",
            " [  6  30  73]]\n",
            "###iteration: 458###\n",
            "train loss= 0.7359, Acc=0.64\n",
            "Test Acc=0.47\n",
            "[[106  73  21]\n",
            " [ 27 138  33]\n",
            " [  8  24  82]]\n",
            "###iteration: 459###\n",
            "train loss= 0.7810, Acc=0.62\n",
            "Test Acc=0.50\n",
            "[[ 88  81  27]\n",
            " [ 28 131  39]\n",
            " [  0  21  97]]\n",
            "###iteration: 460###\n",
            "train loss= 0.6899, Acc=0.67\n",
            "Test Acc=0.55\n",
            "[[123  70   9]\n",
            " [ 37 137  27]\n",
            " [  9  18  82]]\n",
            "###iteration: 461###\n",
            "train loss= 0.7645, Acc=0.58\n",
            "Test Acc=0.60\n",
            "[[119  74  12]\n",
            " [ 60 121  24]\n",
            " [  3  41  58]]\n",
            "###iteration: 462###\n",
            "train loss= 0.7713, Acc=0.60\n",
            "Test Acc=0.59\n",
            "[[115  57  14]\n",
            " [ 49 146  13]\n",
            " [  4  66  48]]\n",
            "###iteration: 463###\n",
            "train loss= 0.7114, Acc=0.66\n",
            "Test Acc=0.49\n",
            "[[115  74  13]\n",
            " [ 26 136  24]\n",
            " [  4  31  89]]\n",
            "###iteration: 464###\n",
            "train loss= 0.7908, Acc=0.61\n",
            "Test Acc=0.39\n",
            "[[ 79  94  27]\n",
            " [ 12 141  46]\n",
            " [  5  18  90]]\n",
            "###iteration: 465###\n",
            "train loss= 0.7896, Acc=0.59\n",
            "Test Acc=0.43\n",
            "[[ 86 100  32]\n",
            " [ 11 142  39]\n",
            " [  3  23  76]]\n",
            "###iteration: 466###\n",
            "train loss= 0.7530, Acc=0.65\n",
            "Test Acc=0.52\n",
            "[[115  71  24]\n",
            " [ 24 118  35]\n",
            " [  4  21 100]]\n",
            "###iteration: 467###\n",
            "train loss= 0.7497, Acc=0.62\n",
            "Test Acc=0.59\n",
            "[[109  68  17]\n",
            " [ 53 135  27]\n",
            " [  3  24  76]]\n",
            "###iteration: 468###\n",
            "train loss= 0.7552, Acc=0.63\n",
            "Test Acc=0.57\n",
            "[[117  67  12]\n",
            " [ 44 145  23]\n",
            " [  6  39  59]]\n",
            "###iteration: 469###\n",
            "train loss= 0.7662, Acc=0.61\n",
            "Test Acc=0.51\n",
            "[[104  86  21]\n",
            " [ 29 148  26]\n",
            " [  5  31  62]]\n",
            "###iteration: 470###\n",
            "train loss= 0.7341, Acc=0.66\n",
            "Test Acc=0.45\n",
            "[[102  88  17]\n",
            " [  9 168  27]\n",
            " [  5  26  70]]\n",
            "###iteration: 471###\n",
            "train loss= 0.7824, Acc=0.59\n",
            "Test Acc=0.47\n",
            "[[101  99  20]\n",
            " [ 22 134  33]\n",
            " [ 10  25  68]]\n",
            "###iteration: 472###\n",
            "train loss= 0.7445, Acc=0.63\n",
            "Test Acc=0.50\n",
            "[[ 96  72  24]\n",
            " [ 22 140  40]\n",
            " [  5  24  89]]\n",
            "###iteration: 473###\n",
            "train loss= 0.7400, Acc=0.64\n",
            "Test Acc=0.53\n",
            "[[ 99  70  18]\n",
            " [ 25 154  36]\n",
            " [  5  28  77]]\n",
            "###iteration: 474###\n",
            "train loss= 0.7315, Acc=0.64\n",
            "Test Acc=0.55\n",
            "[[124  71  12]\n",
            " [ 41 133  24]\n",
            " [  3  31  73]]\n",
            "###iteration: 475###\n",
            "train loss= 0.7415, Acc=0.65\n",
            "Test Acc=0.58\n",
            "[[127  72  12]\n",
            " [ 33 146  22]\n",
            " [  7  31  62]]\n",
            "###iteration: 476###\n",
            "train loss= 0.7759, Acc=0.61\n",
            "Test Acc=0.57\n",
            "[[112  81  12]\n",
            " [ 45 129  15]\n",
            " [  6  40  72]]\n",
            "###iteration: 477###\n",
            "train loss= 0.7070, Acc=0.64\n",
            "Test Acc=0.52\n",
            "[[115  78  12]\n",
            " [ 26 139  32]\n",
            " [  6  31  73]]\n",
            "###iteration: 478###\n",
            "train loss= 0.7617, Acc=0.63\n",
            "Test Acc=0.49\n",
            "[[111  75  27]\n",
            " [ 28 119  39]\n",
            " [  5  16  92]]\n",
            "###iteration: 479###\n",
            "train loss= 0.7456, Acc=0.65\n",
            "Test Acc=0.51\n",
            "[[100  74  22]\n",
            " [ 27 129  39]\n",
            " [  6  13 102]]\n",
            "###iteration: 480###\n",
            "train loss= 0.7136, Acc=0.64\n",
            "Test Acc=0.61\n",
            "[[148  62  25]\n",
            " [ 44 106  30]\n",
            " [  9  14  74]]\n",
            "###iteration: 481###\n",
            "train loss= 0.7589, Acc=0.61\n",
            "Test Acc=0.69\n",
            "[[140  54   8]\n",
            " [ 77 105  26]\n",
            " [ 10  27  65]]\n",
            "###iteration: 482###\n",
            "train loss= 0.7002, Acc=0.66\n",
            "Test Acc=0.63\n",
            "[[150  53   8]\n",
            " [ 61 122  18]\n",
            " [  7  28  65]]\n",
            "###iteration: 483###\n",
            "train loss= 0.7177, Acc=0.61\n",
            "Test Acc=0.53\n",
            "[[105  88  13]\n",
            " [ 37 128  28]\n",
            " [  6  27  80]]\n",
            "###iteration: 484###\n",
            "train loss= 0.7391, Acc=0.63\n",
            "Test Acc=0.44\n",
            "[[ 83 106  24]\n",
            " [ 15 160  18]\n",
            " [  1  26  79]]\n",
            "###iteration: 485###\n",
            "train loss= 0.7720, Acc=0.62\n",
            "Test Acc=0.42\n",
            "[[ 79 105  17]\n",
            " [  8 164  28]\n",
            " [  0  34  77]]\n",
            "###iteration: 486###\n",
            "train loss= 0.7981, Acc=0.59\n",
            "Test Acc=0.45\n",
            "[[ 81 110  14]\n",
            " [ 12 174  24]\n",
            " [  2  46  49]]\n",
            "###iteration: 487###\n",
            "train loss= 0.7469, Acc=0.63\n",
            "Test Acc=0.48\n",
            "[[110  97   5]\n",
            " [ 25 161  18]\n",
            " [  2  44  50]]\n",
            "###iteration: 488###\n",
            "train loss= 0.7929, Acc=0.62\n",
            "Test Acc=0.50\n",
            "[[ 93  93  12]\n",
            " [ 23 154  19]\n",
            " [  1  45  72]]\n",
            "###iteration: 489###\n",
            "train loss= 0.7640, Acc=0.63\n",
            "Test Acc=0.47\n",
            "[[ 84  86  18]\n",
            " [ 20 154  27]\n",
            " [  2  36  85]]\n",
            "###iteration: 490###\n",
            "train loss= 0.7719, Acc=0.63\n",
            "Test Acc=0.46\n",
            "[[ 86  73  33]\n",
            " [ 10 132  48]\n",
            " [  1  24 105]]\n",
            "###iteration: 491###\n",
            "train loss= 0.7481, Acc=0.66\n",
            "Test Acc=0.50\n",
            "[[ 92  73  29]\n",
            " [ 20 149  29]\n",
            " [  1  20  99]]\n",
            "###iteration: 492###\n",
            "train loss= 0.7970, Acc=0.62\n",
            "Test Acc=0.54\n",
            "[[101  70  22]\n",
            " [ 32 143  36]\n",
            " [  5  30  73]]\n",
            "###iteration: 493###\n",
            "train loss= 0.7723, Acc=0.62\n",
            "Test Acc=0.56\n",
            "[[117  64  12]\n",
            " [ 46 121  23]\n",
            " [  4  45  80]]\n",
            "###iteration: 494###\n",
            "train loss= 0.7686, Acc=0.66\n",
            "Test Acc=0.55\n",
            "[[100  68  16]\n",
            " [ 40 152  21]\n",
            " [ 12  17  86]]\n",
            "###iteration: 495###\n",
            "train loss= 0.7616, Acc=0.63\n",
            "Test Acc=0.54\n",
            "[[107  80  16]\n",
            " [ 33 134  23]\n",
            " [ 10  29  80]]\n",
            "###iteration: 496###\n",
            "train loss= 0.7383, Acc=0.65\n",
            "Test Acc=0.52\n",
            "[[100  85  16]\n",
            " [ 22 146  30]\n",
            " [  7  18  88]]\n",
            "###iteration: 497###\n",
            "train loss= 0.7115, Acc=0.65\n",
            "Test Acc=0.52\n",
            "[[105  81  16]\n",
            " [ 28 148  27]\n",
            " [  4  23  80]]\n",
            "###iteration: 498###\n",
            "train loss= 0.7005, Acc=0.66\n",
            "Test Acc=0.51\n",
            "[[116  75  18]\n",
            " [ 27 147  25]\n",
            " [  1  29  74]]\n",
            "###iteration: 499###\n",
            "train loss= 0.7795, Acc=0.63\n",
            "Test Acc=0.49\n",
            "[[109  77  11]\n",
            " [ 25 141  27]\n",
            " [  1  48  73]]\n",
            "###iteration: 500###\n",
            "train loss= 0.7444, Acc=0.64\n",
            "Test Acc=0.47\n",
            "[[ 83  91  15]\n",
            " [ 16 159  35]\n",
            " [  1  26  86]]\n",
            "###iteration: 501###\n",
            "train loss= 0.7374, Acc=0.61\n",
            "Test Acc=0.49\n",
            "[[ 88 113  19]\n",
            " [ 23 131  29]\n",
            " [  2  15  92]]\n",
            "###iteration: 502###\n",
            "train loss= 0.7858, Acc=0.59\n",
            "Test Acc=0.50\n",
            "[[ 81  95  22]\n",
            " [ 20 154  29]\n",
            " [  6  38  67]]\n",
            "###iteration: 503###\n",
            "train loss= 0.7332, Acc=0.66\n",
            "Test Acc=0.50\n",
            "[[101  58  13]\n",
            " [ 25 155  33]\n",
            " [  1  45  81]]\n",
            "###iteration: 504###\n",
            "train loss= 0.7518, Acc=0.64\n",
            "Test Acc=0.51\n",
            "[[102  59  29]\n",
            " [ 31 151  29]\n",
            " [  3  35  73]]\n",
            "###iteration: 505###\n",
            "train loss= 0.7795, Acc=0.60\n",
            "Test Acc=0.55\n",
            "[[110  79  26]\n",
            " [ 39 114  33]\n",
            " [ 10  20  81]]\n",
            "###iteration: 506###\n",
            "train loss= 0.7569, Acc=0.63\n",
            "Test Acc=0.58\n",
            "[[125  68  17]\n",
            " [ 39 120  32]\n",
            " [ 10  24  77]]\n",
            "###iteration: 507###\n",
            "train loss= 0.7098, Acc=0.66\n",
            "Test Acc=0.57\n",
            "[[119  60  15]\n",
            " [ 36 139  32]\n",
            " [  6  27  78]]\n",
            "###iteration: 508###\n",
            "train loss= 0.7605, Acc=0.62\n",
            "Test Acc=0.56\n",
            "[[124  71  17]\n",
            " [ 40 129  32]\n",
            " [ 10  22  67]]\n",
            "###iteration: 509###\n",
            "train loss= 0.7728, Acc=0.61\n",
            "Test Acc=0.52\n",
            "[[ 99  80  16]\n",
            " [ 35 137  31]\n",
            " [  8  28  78]]\n",
            "###iteration: 510###\n",
            "train loss= 0.7675, Acc=0.61\n",
            "Test Acc=0.47\n",
            "[[ 95 103  15]\n",
            " [ 20 142  24]\n",
            " [  5  34  74]]\n",
            "###iteration: 511###\n",
            "train loss= 0.7262, Acc=0.65\n",
            "Test Acc=0.47\n",
            "[[104  85  16]\n",
            " [ 14 145  32]\n",
            " [  2  30  84]]\n",
            "###iteration: 512###\n",
            "train loss= 0.7457, Acc=0.64\n",
            "Test Acc=0.48\n",
            "[[106  81  22]\n",
            " [ 21 154  29]\n",
            " [  4  29  66]]\n",
            "###iteration: 513###\n",
            "train loss= 0.7519, Acc=0.62\n",
            "Test Acc=0.48\n",
            "[[102  80  25]\n",
            " [ 25 136  35]\n",
            " [  1  26  82]]\n",
            "###iteration: 514###\n",
            "train loss= 0.7315, Acc=0.65\n",
            "Test Acc=0.48\n",
            "[[114  74  19]\n",
            " [ 21 143  45]\n",
            " [  0  18  78]]\n",
            "###iteration: 515###\n",
            "train loss= 0.7820, Acc=0.61\n",
            "Test Acc=0.48\n",
            "[[ 87  99  21]\n",
            " [ 17 144  28]\n",
            " [  1  33  82]]\n",
            "###iteration: 516###\n",
            "train loss= 0.7260, Acc=0.63\n",
            "Test Acc=0.50\n",
            "[[111  97   7]\n",
            " [ 20 149  23]\n",
            " [  5  38  62]]\n",
            "###iteration: 517###\n",
            "train loss= 0.6995, Acc=0.67\n",
            "Test Acc=0.51\n",
            "[[101  72   8]\n",
            " [ 24 165  23]\n",
            " [  4  37  78]]\n",
            "###iteration: 518###\n",
            "train loss= 0.7599, Acc=0.61\n",
            "Test Acc=0.51\n",
            "[[ 94  90  11]\n",
            " [ 33 132  31]\n",
            " [  3  34  84]]\n",
            "###iteration: 519###\n",
            "train loss= 0.7283, Acc=0.63\n",
            "Test Acc=0.51\n",
            "[[101  84  14]\n",
            " [ 28 151  27]\n",
            " [  6  28  73]]\n",
            "###iteration: 520###\n",
            "train loss= 0.7244, Acc=0.65\n",
            "Test Acc=0.52\n",
            "[[113  68  22]\n",
            " [ 27 146  26]\n",
            " [  6  30  74]]\n",
            "###iteration: 521###\n",
            "train loss= 0.7429, Acc=0.66\n",
            "Test Acc=0.54\n",
            "[[117  65  16]\n",
            " [ 33 159  19]\n",
            " [  3  36  64]]\n",
            "###iteration: 522###\n",
            "train loss= 0.7940, Acc=0.63\n",
            "Test Acc=0.55\n",
            "[[113  66  22]\n",
            " [ 30 147  26]\n",
            " [  4  40  64]]\n",
            "###iteration: 523###\n",
            "train loss= 0.7423, Acc=0.65\n",
            "Test Acc=0.51\n",
            "[[ 93  78  19]\n",
            " [ 29 159  21]\n",
            " [  2  28  83]]\n",
            "###iteration: 524###\n",
            "train loss= 0.7131, Acc=0.65\n",
            "Test Acc=0.50\n",
            "[[106  93  16]\n",
            " [ 18 154  21]\n",
            " [  2  29  73]]\n",
            "###iteration: 525###\n",
            "train loss= 0.7211, Acc=0.65\n",
            "Test Acc=0.51\n",
            "[[ 92  89  10]\n",
            " [ 23 157  27]\n",
            " [  4  28  82]]\n",
            "###iteration: 526###\n",
            "train loss= 0.7393, Acc=0.62\n",
            "Test Acc=0.52\n",
            "[[ 88  92  14]\n",
            " [ 24 165  36]\n",
            " [  2  28  63]]\n",
            "###iteration: 527###\n",
            "train loss= 0.7381, Acc=0.64\n",
            "Test Acc=0.51\n",
            "[[102  83   4]\n",
            " [ 23 151  39]\n",
            " [  0  37  73]]\n",
            "###iteration: 528###\n",
            "train loss= 0.7521, Acc=0.63\n",
            "Test Acc=0.49\n",
            "[[108  83   9]\n",
            " [ 21 144  31]\n",
            " [  8  38  70]]\n",
            "###iteration: 529###\n",
            "train loss= 0.7076, Acc=0.66\n",
            "Test Acc=0.49\n",
            "[[119  78  17]\n",
            " [ 14 147  23]\n",
            " [  5  38  71]]\n",
            "###iteration: 530###\n",
            "train loss= 0.7667, Acc=0.63\n",
            "Test Acc=0.50\n",
            "[[103  84  13]\n",
            " [ 22 138  31]\n",
            " [  8  33  80]]\n",
            "###iteration: 531###\n",
            "train loss= 0.7247, Acc=0.64\n",
            "Test Acc=0.52\n",
            "[[ 97  82  13]\n",
            " [ 23 153  35]\n",
            " [  5  24  80]]\n",
            "###iteration: 532###\n",
            "train loss= 0.7786, Acc=0.62\n",
            "Test Acc=0.54\n",
            "[[ 94  83  14]\n",
            " [ 27 151  26]\n",
            " [  7  35  75]]\n",
            "###iteration: 533###\n",
            "train loss= 0.7260, Acc=0.64\n",
            "Test Acc=0.53\n",
            "[[106  70  12]\n",
            " [ 27 159  25]\n",
            " [  5  43  65]]\n",
            "###iteration: 534###\n",
            "train loss= 0.7389, Acc=0.63\n",
            "Test Acc=0.52\n",
            "[[ 91  90  11]\n",
            " [ 30 151  21]\n",
            " [  4  33  81]]\n",
            "###iteration: 535###\n",
            "train loss= 0.7290, Acc=0.63\n",
            "Test Acc=0.49\n",
            "[[105  79  16]\n",
            " [ 37 134  20]\n",
            " [  6  29  86]]\n",
            "###iteration: 536###\n",
            "train loss= 0.7693, Acc=0.64\n",
            "Test Acc=0.48\n",
            "[[ 85  80  21]\n",
            " [ 18 156  28]\n",
            " [  8  29  87]]\n",
            "###iteration: 537###\n",
            "train loss= 0.7356, Acc=0.63\n",
            "Test Acc=0.48\n",
            "[[ 92  79   8]\n",
            " [ 34 163  29]\n",
            " [  8  29  70]]\n",
            "###iteration: 538###\n",
            "train loss= 0.7295, Acc=0.65\n",
            "Test Acc=0.54\n",
            "[[110  82  11]\n",
            " [ 23 151  25]\n",
            " [  6  34  70]]\n",
            "###iteration: 539###\n",
            "train loss= 0.8128, Acc=0.62\n",
            "Test Acc=0.56\n",
            "[[102  69  17]\n",
            " [ 39 138  24]\n",
            " [ 14  34  75]]\n",
            "###iteration: 540###\n",
            "train loss= 0.7234, Acc=0.67\n",
            "Test Acc=0.56\n",
            "[[119  79  15]\n",
            " [ 30 148  24]\n",
            " [  5  16  76]]\n",
            "###iteration: 541###\n",
            "train loss= 0.7634, Acc=0.63\n",
            "Test Acc=0.53\n",
            "[[101  85  19]\n",
            " [ 31 140  21]\n",
            " [  6  29  80]]\n",
            "###iteration: 542###\n",
            "train loss= 0.7222, Acc=0.66\n",
            "Test Acc=0.48\n",
            "[[110  75  14]\n",
            " [ 21 149  25]\n",
            " [  6  34  78]]\n",
            "###iteration: 543###\n",
            "train loss= 0.7358, Acc=0.65\n",
            "Test Acc=0.49\n",
            "[[ 96  77  23]\n",
            " [ 12 150  43]\n",
            " [  0  26  85]]\n",
            "###iteration: 544###\n",
            "train loss= 0.7504, Acc=0.62\n",
            "Test Acc=0.49\n",
            "[[ 95  79  16]\n",
            " [ 29 139  36]\n",
            " [  1  34  83]]\n",
            "###iteration: 545###\n",
            "train loss= 0.7181, Acc=0.65\n",
            "Test Acc=0.52\n",
            "[[101  95  10]\n",
            " [ 21 162  21]\n",
            " [  0  34  68]]\n",
            "###iteration: 546###\n",
            "train loss= 0.7872, Acc=0.62\n",
            "Test Acc=0.55\n",
            "[[108  71  16]\n",
            " [ 32 149  29]\n",
            " [  0  44  63]]\n",
            "###iteration: 547###\n",
            "train loss= 0.7494, Acc=0.63\n",
            "Test Acc=0.53\n",
            "[[ 88  85  13]\n",
            " [ 27 166  28]\n",
            " [  1  34  70]]\n",
            "###iteration: 548###\n",
            "train loss= 0.7575, Acc=0.62\n",
            "Test Acc=0.51\n",
            "[[103  85  16]\n",
            " [ 26 136  41]\n",
            " [  0  26  79]]\n",
            "###iteration: 549###\n",
            "train loss= 0.7286, Acc=0.64\n",
            "Test Acc=0.50\n",
            "[[103  82  20]\n",
            " [ 25 128  38]\n",
            " [  0  21  95]]\n",
            "###iteration: 550###\n",
            "train loss= 0.7762, Acc=0.62\n",
            "Test Acc=0.48\n",
            "[[ 83  88  24]\n",
            " [ 17 156  39]\n",
            " [  0  28  77]]\n",
            "###iteration: 551###\n",
            "train loss= 0.7458, Acc=0.65\n",
            "Test Acc=0.50\n",
            "[[ 95  86  14]\n",
            " [ 23 163  14]\n",
            " [  0  41  76]]\n",
            "###iteration: 552###\n",
            "train loss= 0.7148, Acc=0.67\n",
            "Test Acc=0.52\n",
            "[[117  79  11]\n",
            " [ 16 159  16]\n",
            " [  4  41  69]]\n",
            "###iteration: 553###\n",
            "train loss= 0.7521, Acc=0.61\n",
            "Test Acc=0.53\n",
            "[[100  81  17]\n",
            " [ 26 135  33]\n",
            " [  5  37  78]]\n",
            "###iteration: 554###\n",
            "train loss= 0.7440, Acc=0.63\n",
            "Test Acc=0.53\n",
            "[[106  87  25]\n",
            " [ 25 137  22]\n",
            " [  3  25  82]]\n",
            "###iteration: 555###\n",
            "train loss= 0.7397, Acc=0.66\n",
            "Test Acc=0.54\n",
            "[[102  73  20]\n",
            " [ 20 137  35]\n",
            " [  4  21 100]]\n",
            "###iteration: 556###\n",
            "train loss= 0.7521, Acc=0.62\n",
            "Test Acc=0.53\n",
            "[[ 98  65  18]\n",
            " [ 32 134  53]\n",
            " [  2  23  87]]\n",
            "###iteration: 557###\n",
            "train loss= 0.7515, Acc=0.62\n",
            "Test Acc=0.55\n",
            "[[ 97  92  14]\n",
            " [ 32 152  19]\n",
            " [  6  34  66]]\n",
            "###iteration: 558###\n",
            "train loss= 0.7185, Acc=0.66\n",
            "Test Acc=0.54\n",
            "[[106  76   9]\n",
            " [ 30 157  14]\n",
            " [  7  36  77]]\n",
            "###iteration: 559###\n",
            "train loss= 0.7019, Acc=0.66\n",
            "Test Acc=0.52\n",
            "[[ 95  89   9]\n",
            " [ 27 163  15]\n",
            " [  9  27  78]]\n",
            "###iteration: 560###\n",
            "train loss= 0.7313, Acc=0.65\n",
            "Test Acc=0.52\n",
            "[[108  71  21]\n",
            " [ 28 149  29]\n",
            " [  7  23  76]]\n",
            "###iteration: 561###\n",
            "train loss= 0.7586, Acc=0.63\n",
            "Test Acc=0.52\n",
            "[[106  67  19]\n",
            " [ 23 123  42]\n",
            " [  5  35  92]]\n",
            "###iteration: 562###\n",
            "train loss= 0.7283, Acc=0.66\n",
            "Test Acc=0.50\n",
            "[[106  65  24]\n",
            " [ 24 148  36]\n",
            " [  7  18  84]]\n",
            "###iteration: 563###\n",
            "train loss= 0.6875, Acc=0.67\n",
            "Test Acc=0.53\n",
            "[[116  73  13]\n",
            " [ 25 152  25]\n",
            " [  4  28  76]]\n",
            "###iteration: 564###\n",
            "train loss= 0.7496, Acc=0.64\n",
            "Test Acc=0.52\n",
            "[[102  86  13]\n",
            " [ 25 163  13]\n",
            " [  4  42  64]]\n",
            "###iteration: 565###\n",
            "train loss= 0.7483, Acc=0.62\n",
            "Test Acc=0.53\n",
            "[[119  90   9]\n",
            " [ 29 144  20]\n",
            " [  8  39  54]]\n",
            "###iteration: 566###\n",
            "train loss= 0.7358, Acc=0.65\n",
            "Test Acc=0.51\n",
            "[[ 95  74  17]\n",
            " [ 28 170  24]\n",
            " [  3  34  67]]\n",
            "###iteration: 567###\n",
            "train loss= 0.7631, Acc=0.61\n",
            "Test Acc=0.49\n",
            "[[ 85 100  15]\n",
            " [ 19 154  32]\n",
            " [  6  26  75]]\n",
            "###iteration: 568###\n",
            "train loss= 0.7244, Acc=0.64\n",
            "Test Acc=0.51\n",
            "[[ 94  83  15]\n",
            " [ 21 154  33]\n",
            " [  7  26  79]]\n",
            "###iteration: 569###\n",
            "train loss= 0.7364, Acc=0.66\n",
            "Test Acc=0.52\n",
            "[[104  70  14]\n",
            " [ 22 146  35]\n",
            " [  6  26  89]]\n",
            "###iteration: 570###\n",
            "train loss= 0.7535, Acc=0.65\n",
            "Test Acc=0.54\n",
            "[[104  72  13]\n",
            " [ 32 134  30]\n",
            " [  6  28  93]]\n",
            "###iteration: 571###\n",
            "train loss= 0.7265, Acc=0.67\n",
            "Test Acc=0.54\n",
            "[[110  67  18]\n",
            " [ 26 142  26]\n",
            " [  5  29  89]]\n",
            "###iteration: 572###\n",
            "train loss= 0.7419, Acc=0.64\n",
            "Test Acc=0.52\n",
            "[[110  78  13]\n",
            " [ 28 145  28]\n",
            " [ 13  22  75]]\n",
            "###iteration: 573###\n",
            "train loss= 0.7673, Acc=0.63\n",
            "Test Acc=0.55\n",
            "[[112  76  14]\n",
            " [ 34 136  23]\n",
            " [  9  32  76]]\n",
            "###iteration: 574###\n",
            "train loss= 0.7680, Acc=0.61\n",
            "Test Acc=0.58\n",
            "[[116  81  10]\n",
            " [ 46 133  27]\n",
            " [  8  28  63]]\n",
            "###iteration: 575###\n",
            "train loss= 0.7080, Acc=0.67\n",
            "Test Acc=0.53\n",
            "[[ 86  69  12]\n",
            " [ 26 174  29]\n",
            " [  5  26  85]]\n",
            "###iteration: 576###\n",
            "train loss= 0.7420, Acc=0.64\n",
            "Test Acc=0.48\n",
            "[[ 94  75  18]\n",
            " [ 20 154  36]\n",
            " [  5  31  79]]\n",
            "###iteration: 577###\n",
            "train loss= 0.7067, Acc=0.66\n",
            "Test Acc=0.45\n",
            "[[ 89  87  11]\n",
            " [ 18 165  30]\n",
            " [  3  24  85]]\n",
            "###iteration: 578###\n",
            "train loss= 0.7503, Acc=0.63\n",
            "Test Acc=0.45\n",
            "[[ 84  95  10]\n",
            " [ 14 148  29]\n",
            " [  0  41  91]]\n",
            "###iteration: 579###\n",
            "train loss= 0.7255, Acc=0.63\n",
            "Test Acc=0.48\n",
            "[[106  83  18]\n",
            " [ 22 138  31]\n",
            " [  0  35  79]]\n",
            "###iteration: 580###\n",
            "train loss= 0.7605, Acc=0.59\n",
            "Test Acc=0.50\n",
            "[[ 81  99  12]\n",
            " [ 26 145  24]\n",
            " [  2  48  75]]\n",
            "###iteration: 581###\n",
            "train loss= 0.7564, Acc=0.65\n",
            "Test Acc=0.50\n",
            "[[101  83  10]\n",
            " [ 21 145  22]\n",
            " [  2  40  88]]\n",
            "###iteration: 582###\n",
            "train loss= 0.7709, Acc=0.62\n",
            "Test Acc=0.50\n",
            "[[ 97  76  15]\n",
            " [ 21 127  46]\n",
            " [  8  31  91]]\n",
            "###iteration: 583###\n",
            "train loss= 0.7434, Acc=0.65\n",
            "Test Acc=0.52\n",
            "[[103  66  23]\n",
            " [ 27 137  33]\n",
            " [  9  19  95]]\n",
            "###iteration: 584###\n",
            "train loss= 0.7020, Acc=0.65\n",
            "Test Acc=0.58\n",
            "[[141  80  12]\n",
            " [ 34 122  26]\n",
            " [  8  18  71]]\n",
            "###iteration: 585###\n",
            "train loss= 0.7049, Acc=0.64\n",
            "Test Acc=0.63\n",
            "[[134  61  10]\n",
            " [ 45 120  20]\n",
            " [  5  42  75]]\n",
            "###iteration: 586###\n",
            "train loss= 0.7502, Acc=0.62\n",
            "Test Acc=0.61\n",
            "[[110  68   9]\n",
            " [ 53 124  24]\n",
            " [  2  39  83]]\n",
            "###iteration: 587###\n",
            "train loss= 0.7446, Acc=0.62\n",
            "Test Acc=0.55\n",
            "[[124  68  17]\n",
            " [ 39 125  32]\n",
            " [  1  40  66]]\n",
            "###iteration: 588###\n",
            "train loss= 0.7513, Acc=0.60\n",
            "Test Acc=0.52\n",
            "[[113  97  13]\n",
            " [ 32 116  26]\n",
            " [  6  33  76]]\n",
            "###iteration: 589###\n",
            "train loss= 0.7060, Acc=0.67\n",
            "Test Acc=0.50\n",
            "[[110  73  15]\n",
            " [ 22 131  35]\n",
            " [  1  23 102]]\n",
            "###iteration: 590###\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uB902g-LbFOf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!mkdir my_net_cwe\n",
        "mv checkpoint save_cwe_rnn.ckpt.data-00000-of-00001 save_cwe_rnn.ckpt.index save_cwe_rnn.ckpt.meta my_net_cwe"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
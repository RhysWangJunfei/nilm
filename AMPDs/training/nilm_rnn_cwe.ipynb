{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nilm_rnn_cwe.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RhysWangJunfei/nilm/blob/master/AMPDs/training/nilm_rnn_cwe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "S85I81geO2wa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import io\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split \n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7a4nAW57PDP_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''Sliding window function'''\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX = []\n",
        "    for i in range(len(dataset)-look_back+1):\n",
        "        a = dataset[i:(i+look_back)]\n",
        "        dataX.append(a)\n",
        "    return np.array(dataX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fDv8Gl4yPFN3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "WHE_data = pd.read_csv('Electricity_WHE.csv')['P']\n",
        "CWE_data = pd.read_csv('Electricity_CWE.csv')['P']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f4CJBm-IPe44",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "window_size=60\n",
        "\n",
        "dataX_raw = create_dataset(WHE_data.as_matrix(), window_size)\n",
        "\n",
        "cwe_Y_raw = CWE_data[window_size-1:].values.reshape([CWE_data.shape[0]-window_size+1,1])\n",
        "\n",
        "dataX = np.concatenate([dataX_raw[0:472500,:],dataX_raw[475500:,:]],axis=0)\n",
        "cwe_Y = np.concatenate([cwe_Y_raw[0:472500,:],cwe_Y_raw[475500:,:]],axis=0)\n",
        "categorized_cwe_Y = np.ones(cwe_Y.shape)*2\n",
        "categorized_cwe_Y[[np.where(cwe_Y==0)[0]],:]=0\n",
        "categorized_cwe_Y[[np.where((cwe_Y>0)&(cwe_Y<=300))[0]],:]=1\n",
        "#categorized_cwe_Y[[np.where((cwe_Y>300))[0]],:]=2\n",
        "\n",
        "encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
        "cweY_1hot = encoder.fit_transform(categorized_cwe_Y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataX, cweY_1hot, test_size=0.01, shuffle=True)\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train.astype(float))\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-k8WkraGPlxm",
        "colab_type": "code",
        "outputId": "70e65833-55a3-4224-a07f-f7ff885e7f71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "max_indice = np.argmax(cweY_1hot,1)\n",
        "df = pd.Series(max_indice)\n",
        "df.value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1018321\n",
              "1      26327\n",
              "2       3493\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "S9YyyA_k22MH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyper Parameters\n",
        "LR = 0.001      # learning rate\n",
        "batch_size=128\n",
        "window_size=60\n",
        "num_units = [256, 128]\n",
        "\n",
        "'''RNN Model Definition'''\n",
        "tf.reset_default_graph()\n",
        "''''''\n",
        "#define inputs\n",
        "tf_x = tf.placeholder(tf.float32, [None, window_size,1],name='x')\n",
        "tf_y = tf.placeholder(tf.int32, [None, 3],name='y')\n",
        "\n",
        "\n",
        "cells = [tf.keras.layers.LSTMCell(units=n) for n in num_units]\n",
        "stacked_rnn_cell = tf.keras.layers.StackedRNNCells(cells)\n",
        "outputs, (h_c, h_n) = tf.nn.dynamic_rnn(\n",
        "        stacked_rnn_cell,                   # cell you have chosen\n",
        "        tf_x,                      # input\n",
        "        initial_state=None,         # the initial hidden state\n",
        "        dtype=tf.float32,           # must given if set initial_state = None\n",
        "        time_major=False,           # False: (batch, time step, input); True: (time step, batch, input)\n",
        ")\n",
        "l1 = tf.layers.dense(outputs[:, -1, :],64,activation=tf.nn.relu,name='l1')\n",
        "l2 = tf.layers.dense(l1,32,activation=tf.nn.relu,name='l2')\n",
        "l3 = tf.layers.dense(l2,16,activation=tf.nn.relu,name='l3')\n",
        "l4 = tf.layers.dense(l3,8,activation=tf.nn.relu,name='l4')\n",
        "#l5 = tf.layers.dense(l4,16,activation=tf.nn.relu,name='l5')\n",
        "#l6 = tf.layers.dense(l5,8,activation=tf.nn.relu,name='l6')\n",
        "pred = tf.layers.dense(l4,3,activation=tf.nn.relu,name='pred')\n",
        "\n",
        "with tf.name_scope('loss'):\n",
        "    cross_entropy =  tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_y, logits=pred) \n",
        "    loss = tf.reduce_mean(cross_entropy)\n",
        "    tf.summary.scalar(\"loss\",tensor=loss)\n",
        "\n",
        "train_op = tf.train.AdamOptimizer(LR).minimize(loss)\n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(tf_y, axis=1), tf.argmax(pred, axis=1)), tf.float32))\n",
        "\n",
        "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer()) \n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "giG7CCs12fTG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "file_name='tomekLinked_data'\n",
        "fileObject = open(file_name,'rb')\n",
        "X_train = pickle.load(fileObject)\n",
        "y_train = pickle.load(fileObject)\n",
        "fileObject.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pLMeA183PtzM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
        "tl = RandomUnderSampler(sampling_strategy={0:3000,1:3000,2:3000})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q6CYX629mxPp",
        "colab_type": "code",
        "outputId": "3e69571c-170d-4973-aff2-44f5671532ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 18329
        }
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "#sess.run(init_op)\n",
        "saver.restore(sess, 'my_net_cwe_central/save_cwe_rnn.ckpt')\n",
        "for i in range(0,1000):\n",
        "  X, y = tl.fit_resample(X_train, y_train)\n",
        "  #y = encoder.fit_transform(y.reshape([-1,1]))\n",
        "  whole_train = np.concatenate([X,y],axis=1)\n",
        "  batch_index = np.random.choice(9000,batch_size)\n",
        "  batch_train = whole_train[batch_index,:]\n",
        "  batch_X = batch_train[:,:-3].reshape([batch_size,window_size,1])\n",
        "  batch_y = batch_train[:,-3:]\n",
        "  print('##Â·##Loop:'+str(i))\n",
        "  sess.run(train_op,{tf_x:batch_X , tf_y:batch_y})\n",
        "  cost_ = sess.run(loss,{tf_x:batch_X, tf_y:batch_y})\n",
        "  print('train loss= %.16f' % cost_)\n",
        "  if(i%99==0):\n",
        "    acc_train = sess.run(accuracy,{tf_x:batch_X, tf_y:batch_y})\n",
        "    acc_test = sess.run(accuracy,feed_dict={tf_x: X_test.reshape([X_test.shape[0],window_size,1]), \\\n",
        "                                            tf_y:y_test})\n",
        "    print('train loss= %.16f' % cost_+', Acc=%.4f'% acc_train)\n",
        "    print('Test Acc=%.2f'% acc_test)\n",
        "    pre = sess.run(pred,feed_dict={tf_x: batch_X, tf_y:batch_y})\n",
        "    y_lables_argmax = tf.argmax(tf_y,axis=1)  \n",
        "    y_pred_argmax = tf.argmax(pre,axis=1)\n",
        "    confusion = tf.confusion_matrix(labels=y_lables_argmax, predictions=y_pred_argmax, num_classes=3)\n",
        "    #print('Confusion Matrix: \\n\\n', tf.Tensor.eval(confusion,feed_dict=None))\n",
        "    print(confusion.eval(session=sess,feed_dict={tf_x: batch_X, tf_y:batch_y}))\n",
        "    save_path = saver.save(sess, \"my_net_cwe_central/save_cwe_rnn.ckpt\")\n",
        "      \n",
        "#pre = sess.run(pred,feed_dict={tf_x: X_test.reshape([X_test.shape[0],window_size,1]), tf_y: y_test})\n",
        "#y_lables_argmax = np.argmax(y_test,1)\n",
        "#y_pred_argmax = np.argmax(pre,1)\n",
        "#confusion = tf.confusion_matrix(labels=y_lables_argmax, predictions=y_pred_argmax, num_classes=2)\n",
        "#print('Confusion Matrix: \\n\\n', tf.Tensor.eval(confusion,feed_dict=None))\n",
        "#print(confusion.eval(session=sess))\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from my_net_cwe_central/save_cwe_rnn.ckpt\n",
            "##Â·##Loop:0\n",
            "train loss= 0.2006096243858337\n",
            "train loss= 0.2006096243858337, Acc=0.9141\n",
            "Test Acc=0.85\n",
            "[[37  4  0]\n",
            " [ 4 39  2]\n",
            " [ 0  1 41]]\n",
            "##Â·##Loop:1\n",
            "train loss= 0.2464631944894791\n",
            "##Â·##Loop:2\n",
            "train loss= 0.2261790484189987\n",
            "##Â·##Loop:3\n",
            "train loss= 0.2423966079950333\n",
            "##Â·##Loop:4\n",
            "train loss= 0.2536152601242065\n",
            "##Â·##Loop:5\n",
            "train loss= 0.1777364313602448\n",
            "##Â·##Loop:6\n",
            "train loss= 0.3237663507461548\n",
            "##Â·##Loop:7\n",
            "train loss= 0.2081740349531174\n",
            "##Â·##Loop:8\n",
            "train loss= 0.2593451440334320\n",
            "##Â·##Loop:9\n",
            "train loss= 0.1776133924722672\n",
            "##Â·##Loop:10\n",
            "train loss= 0.2884507179260254\n",
            "##Â·##Loop:11\n",
            "train loss= 0.1359289437532425\n",
            "##Â·##Loop:12\n",
            "train loss= 0.1429767012596130\n",
            "##Â·##Loop:13\n",
            "train loss= 0.2053130567073822\n",
            "##Â·##Loop:14\n",
            "train loss= 0.2708986401557922\n",
            "##Â·##Loop:15\n",
            "train loss= 0.2020643502473831\n",
            "##Â·##Loop:16\n",
            "train loss= 0.2330212891101837\n",
            "##Â·##Loop:17\n",
            "train loss= 0.2462792694568634\n",
            "##Â·##Loop:18\n",
            "train loss= 0.1781722456216812\n",
            "##Â·##Loop:19\n",
            "train loss= 0.1942889392375946\n",
            "##Â·##Loop:20\n",
            "train loss= 0.1963672190904617\n",
            "##Â·##Loop:21\n",
            "train loss= 0.1847328245639801\n",
            "##Â·##Loop:22\n",
            "train loss= 0.1979549676179886\n",
            "##Â·##Loop:23\n",
            "train loss= 0.3226103782653809\n",
            "##Â·##Loop:24\n",
            "train loss= 0.2516406178474426\n",
            "##Â·##Loop:25\n",
            "train loss= 0.1755685210227966\n",
            "##Â·##Loop:26\n",
            "train loss= 0.1927726417779922\n",
            "##Â·##Loop:27\n",
            "train loss= 0.1804187744855881\n",
            "##Â·##Loop:28\n",
            "train loss= 0.2776642441749573\n",
            "##Â·##Loop:29\n",
            "train loss= 0.1831014752388000\n",
            "##Â·##Loop:30\n",
            "train loss= 0.3192026019096375\n",
            "##Â·##Loop:31\n",
            "train loss= 0.2684740424156189\n",
            "##Â·##Loop:32\n",
            "train loss= 0.2433590888977051\n",
            "##Â·##Loop:33\n",
            "train loss= 0.2049409002065659\n",
            "##Â·##Loop:34\n",
            "train loss= 0.2296602129936218\n",
            "##Â·##Loop:35\n",
            "train loss= 0.2704133987426758\n",
            "##Â·##Loop:36\n",
            "train loss= 0.2655397653579712\n",
            "##Â·##Loop:37\n",
            "train loss= 0.1356646269559860\n",
            "##Â·##Loop:38\n",
            "train loss= 0.1923244446516037\n",
            "##Â·##Loop:39\n",
            "train loss= 0.2031103074550629\n",
            "##Â·##Loop:40\n",
            "train loss= 0.2391449362039566\n",
            "##Â·##Loop:41\n",
            "train loss= 0.2430376708507538\n",
            "##Â·##Loop:42\n",
            "train loss= 0.2103542387485504\n",
            "##Â·##Loop:43\n",
            "train loss= 0.2446593344211578\n",
            "##Â·##Loop:44\n",
            "train loss= 0.1926961541175842\n",
            "##Â·##Loop:45\n",
            "train loss= 0.2327564805746078\n",
            "##Â·##Loop:46\n",
            "train loss= 0.1982419341802597\n",
            "##Â·##Loop:47\n",
            "train loss= 0.1692715287208557\n",
            "##Â·##Loop:48\n",
            "train loss= 0.1547882556915283\n",
            "##Â·##Loop:49\n",
            "train loss= 0.2089567482471466\n",
            "##Â·##Loop:50\n",
            "train loss= 0.0856552869081497\n",
            "##Â·##Loop:51\n",
            "train loss= 0.2113132327795029\n",
            "##Â·##Loop:52\n",
            "train loss= 0.1914221346378326\n",
            "##Â·##Loop:53\n",
            "train loss= 0.2264311909675598\n",
            "##Â·##Loop:54\n",
            "train loss= 0.2209084033966064\n",
            "##Â·##Loop:55\n",
            "train loss= 0.1948082745075226\n",
            "##Â·##Loop:56\n",
            "train loss= 0.2733667194843292\n",
            "##Â·##Loop:57\n",
            "train loss= 0.1590187102556229\n",
            "##Â·##Loop:58\n",
            "train loss= 0.1529859900474548\n",
            "##Â·##Loop:59\n",
            "train loss= 0.1714890152215958\n",
            "##Â·##Loop:60\n",
            "train loss= 0.2021976113319397\n",
            "##Â·##Loop:61\n",
            "train loss= 0.2015453130006790\n",
            "##Â·##Loop:62\n",
            "train loss= 0.2031242251396179\n",
            "##Â·##Loop:63\n",
            "train loss= 0.2143763899803162\n",
            "##Â·##Loop:64\n",
            "train loss= 0.1945862025022507\n",
            "##Â·##Loop:65\n",
            "train loss= 0.3136444687843323\n",
            "##Â·##Loop:66\n",
            "train loss= 0.1862364709377289\n",
            "##Â·##Loop:67\n",
            "train loss= 0.2157900333404541\n",
            "##Â·##Loop:68\n",
            "train loss= 0.2198733836412430\n",
            "##Â·##Loop:69\n",
            "train loss= 0.1765305697917938\n",
            "##Â·##Loop:70\n",
            "train loss= 0.2114225924015045\n",
            "##Â·##Loop:71\n",
            "train loss= 0.2532835900783539\n",
            "##Â·##Loop:72\n",
            "train loss= 0.2512235045433044\n",
            "##Â·##Loop:73\n",
            "train loss= 0.2057044357061386\n",
            "##Â·##Loop:74\n",
            "train loss= 0.1855630576610565\n",
            "##Â·##Loop:75\n",
            "train loss= 0.1759818941354752\n",
            "##Â·##Loop:76\n",
            "train loss= 0.2275524139404297\n",
            "##Â·##Loop:77\n",
            "train loss= 0.2252523899078369\n",
            "##Â·##Loop:78\n",
            "train loss= 0.2622375488281250\n",
            "##Â·##Loop:79\n",
            "train loss= 0.1595425158739090\n",
            "##Â·##Loop:80\n",
            "train loss= 0.2036934196949005\n",
            "##Â·##Loop:81\n",
            "train loss= 0.2154920399188995\n",
            "##Â·##Loop:82\n",
            "train loss= 0.1945607960224152\n",
            "##Â·##Loop:83\n",
            "train loss= 0.2894739508628845\n",
            "##Â·##Loop:84\n",
            "train loss= 0.2131973654031754\n",
            "##Â·##Loop:85\n",
            "train loss= 0.2212761938571930\n",
            "##Â·##Loop:86\n",
            "train loss= 0.1529958397150040\n",
            "##Â·##Loop:87\n",
            "train loss= 0.1474614888429642\n",
            "##Â·##Loop:88\n",
            "train loss= 0.1925706118345261\n",
            "##Â·##Loop:89\n",
            "train loss= 0.3053335249423981\n",
            "##Â·##Loop:90\n",
            "train loss= 0.2524768114089966\n",
            "##Â·##Loop:91\n",
            "train loss= 0.1543919742107391\n",
            "##Â·##Loop:92\n",
            "train loss= 0.2161852717399597\n",
            "##Â·##Loop:93\n",
            "train loss= 0.2255566567182541\n",
            "##Â·##Loop:94\n",
            "train loss= 0.1624738126993179\n",
            "##Â·##Loop:95\n",
            "train loss= 0.1960481703281403\n",
            "##Â·##Loop:96\n",
            "train loss= 0.2207573801279068\n",
            "##Â·##Loop:97\n",
            "train loss= 0.2014735192060471\n",
            "##Â·##Loop:98\n",
            "train loss= 0.2457646727561951\n",
            "##Â·##Loop:99\n",
            "train loss= 0.1739134192466736\n",
            "train loss= 0.1739134192466736, Acc=0.9453\n",
            "Test Acc=0.86\n",
            "[[35  2  0]\n",
            " [ 1 45  2]\n",
            " [ 0  2 41]]\n",
            "##Â·##Loop:100\n",
            "train loss= 0.1240245252847672\n",
            "##Â·##Loop:101\n",
            "train loss= 0.2414049506187439\n",
            "##Â·##Loop:102\n",
            "train loss= 0.1690875291824341\n",
            "##Â·##Loop:103\n",
            "train loss= 0.1982663571834564\n",
            "##Â·##Loop:104\n",
            "train loss= 0.2251302003860474\n",
            "##Â·##Loop:105\n",
            "train loss= 0.1336887627840042\n",
            "##Â·##Loop:106\n",
            "train loss= 0.2039127051830292\n",
            "##Â·##Loop:107\n",
            "train loss= 0.2525500655174255\n",
            "##Â·##Loop:108\n",
            "train loss= 0.2554723918437958\n",
            "##Â·##Loop:109\n",
            "train loss= 0.2102162837982178\n",
            "##Â·##Loop:110\n",
            "train loss= 0.2501936256885529\n",
            "##Â·##Loop:111\n",
            "train loss= 0.2294797897338867\n",
            "##Â·##Loop:112\n",
            "train loss= 0.2062661051750183\n",
            "##Â·##Loop:113\n",
            "train loss= 0.2967345714569092\n",
            "##Â·##Loop:114\n",
            "train loss= 0.2463283687829971\n",
            "##Â·##Loop:115\n",
            "train loss= 0.2645184397697449\n",
            "##Â·##Loop:116\n",
            "train loss= 0.1590087562799454\n",
            "##Â·##Loop:117\n",
            "train loss= 0.1960286200046539\n",
            "##Â·##Loop:118\n",
            "train loss= 0.2222751080989838\n",
            "##Â·##Loop:119\n",
            "train loss= 0.3435696363449097\n",
            "##Â·##Loop:120\n",
            "train loss= 0.1615496575832367\n",
            "##Â·##Loop:121\n",
            "train loss= 0.1776182204484940\n",
            "##Â·##Loop:122\n",
            "train loss= 0.2046070843935013\n",
            "##Â·##Loop:123\n",
            "train loss= 0.1525394320487976\n",
            "##Â·##Loop:124\n",
            "train loss= 0.1881703883409500\n",
            "##Â·##Loop:125\n",
            "train loss= 0.1551841050386429\n",
            "##Â·##Loop:126\n",
            "train loss= 0.2505689859390259\n",
            "##Â·##Loop:127\n",
            "train loss= 0.3019293546676636\n",
            "##Â·##Loop:128\n",
            "train loss= 0.1869776248931885\n",
            "##Â·##Loop:129\n",
            "train loss= 0.3486514389514923\n",
            "##Â·##Loop:130\n",
            "train loss= 0.2106213867664337\n",
            "##Â·##Loop:131\n",
            "train loss= 0.2256299555301666\n",
            "##Â·##Loop:132\n",
            "train loss= 0.1470311284065247\n",
            "##Â·##Loop:133\n",
            "train loss= 0.1999620795249939\n",
            "##Â·##Loop:134\n",
            "train loss= 0.1704306900501251\n",
            "##Â·##Loop:135\n",
            "train loss= 0.2014318555593491\n",
            "##Â·##Loop:136\n",
            "train loss= 0.2329688221216202\n",
            "##Â·##Loop:137\n",
            "train loss= 0.2612262368202209\n",
            "##Â·##Loop:138\n",
            "train loss= 0.2276114225387573\n",
            "##Â·##Loop:139\n",
            "train loss= 0.1692878603935242\n",
            "##Â·##Loop:140\n",
            "train loss= 0.1549215316772461\n",
            "##Â·##Loop:141\n",
            "train loss= 0.2838093340396881\n",
            "##Â·##Loop:142\n",
            "train loss= 0.1412386000156403\n",
            "##Â·##Loop:143\n",
            "train loss= 0.2081581652164459\n",
            "##Â·##Loop:144\n",
            "train loss= 0.1388298422098160\n",
            "##Â·##Loop:145\n",
            "train loss= 0.2885963916778564\n",
            "##Â·##Loop:146\n",
            "train loss= 0.1909253597259521\n",
            "##Â·##Loop:147\n",
            "train loss= 0.2088910639286041\n",
            "##Â·##Loop:148\n",
            "train loss= 0.2090499401092529\n",
            "##Â·##Loop:149\n",
            "train loss= 0.2286533713340759\n",
            "##Â·##Loop:150\n",
            "train loss= 0.3567616939544678\n",
            "##Â·##Loop:151\n",
            "train loss= 0.1727392673492432\n",
            "##Â·##Loop:152\n",
            "train loss= 0.2341558337211609\n",
            "##Â·##Loop:153\n",
            "train loss= 0.1823499649763107\n",
            "##Â·##Loop:154\n",
            "train loss= 0.2769501507282257\n",
            "##Â·##Loop:155\n",
            "train loss= 0.1499992311000824\n",
            "##Â·##Loop:156\n",
            "train loss= 0.2182038426399231\n",
            "##Â·##Loop:157\n",
            "train loss= 0.1907889544963837\n",
            "##Â·##Loop:158\n",
            "train loss= 0.2129468470811844\n",
            "##Â·##Loop:159\n",
            "train loss= 0.1712787449359894\n",
            "##Â·##Loop:160\n",
            "train loss= 0.3652053177356720\n",
            "##Â·##Loop:161\n",
            "train loss= 0.1719410866498947\n",
            "##Â·##Loop:162\n",
            "train loss= 0.2306960970163345\n",
            "##Â·##Loop:163\n",
            "train loss= 0.2331941127777100\n",
            "##Â·##Loop:164\n",
            "train loss= 0.2055969536304474\n",
            "##Â·##Loop:165\n",
            "train loss= 0.3130944967269897\n",
            "##Â·##Loop:166\n",
            "train loss= 0.1818001568317413\n",
            "##Â·##Loop:167\n",
            "train loss= 0.2281027436256409\n",
            "##Â·##Loop:168\n",
            "train loss= 0.2671712338924408\n",
            "##Â·##Loop:169\n",
            "train loss= 0.1475206315517426\n",
            "##Â·##Loop:170\n",
            "train loss= 0.2189728319644928\n",
            "##Â·##Loop:171\n",
            "train loss= 0.2305551618337631\n",
            "##Â·##Loop:172\n",
            "train loss= 0.2117127329111099\n",
            "##Â·##Loop:173\n",
            "train loss= 0.1403386294841766\n",
            "##Â·##Loop:174\n",
            "train loss= 0.1943918019533157\n",
            "##Â·##Loop:175\n",
            "train loss= 0.1959400624036789\n",
            "##Â·##Loop:176\n",
            "train loss= 0.3083834648132324\n",
            "##Â·##Loop:177\n",
            "train loss= 0.2533872425556183\n",
            "##Â·##Loop:178\n",
            "train loss= 0.2455377578735352\n",
            "##Â·##Loop:179\n",
            "train loss= 0.2077622264623642\n",
            "##Â·##Loop:180\n",
            "train loss= 0.2914492189884186\n",
            "##Â·##Loop:181\n",
            "train loss= 0.2329562455415726\n",
            "##Â·##Loop:182\n",
            "train loss= 0.1580281704664230\n",
            "##Â·##Loop:183\n",
            "train loss= 0.2650044262409210\n",
            "##Â·##Loop:184\n",
            "train loss= 0.1987037658691406\n",
            "##Â·##Loop:185\n",
            "train loss= 0.1411923766136169\n",
            "##Â·##Loop:186\n",
            "train loss= 0.1524039953947067\n",
            "##Â·##Loop:187\n",
            "train loss= 0.2250961363315582\n",
            "##Â·##Loop:188\n",
            "train loss= 0.1706002354621887\n",
            "##Â·##Loop:189\n",
            "train loss= 0.1626904904842377\n",
            "##Â·##Loop:190\n",
            "train loss= 0.1467376053333282\n",
            "##Â·##Loop:191\n",
            "train loss= 0.1567942202091217\n",
            "##Â·##Loop:192\n",
            "train loss= 0.2794689536094666\n",
            "##Â·##Loop:193\n",
            "train loss= 0.3059556186199188\n",
            "##Â·##Loop:194\n",
            "train loss= 0.2243645042181015\n",
            "##Â·##Loop:195\n",
            "train loss= 0.2343600988388062\n",
            "##Â·##Loop:196\n",
            "train loss= 0.2311184108257294\n",
            "##Â·##Loop:197\n",
            "train loss= 0.1783281713724136\n",
            "##Â·##Loop:198\n",
            "train loss= 0.1684953272342682\n",
            "train loss= 0.1684953272342682, Acc=0.9531\n",
            "Test Acc=0.89\n",
            "[[36  4  0]\n",
            " [ 2 41  0]\n",
            " [ 0  0 45]]\n",
            "##Â·##Loop:199\n",
            "train loss= 0.3120268881320953\n",
            "##Â·##Loop:200\n",
            "train loss= 0.2903239130973816\n",
            "##Â·##Loop:201\n",
            "train loss= 0.1669447571039200\n",
            "##Â·##Loop:202\n",
            "train loss= 0.2205042541027069\n",
            "##Â·##Loop:203\n",
            "train loss= 0.1489952206611633\n",
            "##Â·##Loop:204\n",
            "train loss= 0.2190351337194443\n",
            "##Â·##Loop:205\n",
            "train loss= 0.2502344548702240\n",
            "##Â·##Loop:206\n",
            "train loss= 0.1642343699932098\n",
            "##Â·##Loop:207\n",
            "train loss= 0.2758899927139282\n",
            "##Â·##Loop:208\n",
            "train loss= 0.2164083421230316\n",
            "##Â·##Loop:209\n",
            "train loss= 0.2256936132907867\n",
            "##Â·##Loop:210\n",
            "train loss= 0.2071459144353867\n",
            "##Â·##Loop:211\n",
            "train loss= 0.2093227505683899\n",
            "##Â·##Loop:212\n",
            "train loss= 0.2572948038578033\n",
            "##Â·##Loop:213\n",
            "train loss= 0.2494802176952362\n",
            "##Â·##Loop:214\n",
            "train loss= 0.3412765264511108\n",
            "##Â·##Loop:215\n",
            "train loss= 0.2625236511230469\n",
            "##Â·##Loop:216\n",
            "train loss= 0.2246888130903244\n",
            "##Â·##Loop:217\n",
            "train loss= 0.2395863234996796\n",
            "##Â·##Loop:218\n",
            "train loss= 0.2148424535989761\n",
            "##Â·##Loop:219\n",
            "train loss= 0.3323009312152863\n",
            "##Â·##Loop:220\n",
            "train loss= 0.2269456684589386\n",
            "##Â·##Loop:221\n",
            "train loss= 0.1574945151805878\n",
            "##Â·##Loop:222\n",
            "train loss= 0.2383431792259216\n",
            "##Â·##Loop:223\n",
            "train loss= 0.1642222851514816\n",
            "##Â·##Loop:224\n",
            "train loss= 0.2544306516647339\n",
            "##Â·##Loop:225\n",
            "train loss= 0.1905346810817719\n",
            "##Â·##Loop:226\n",
            "train loss= 0.1995867490768433\n",
            "##Â·##Loop:227\n",
            "train loss= 0.2568905055522919\n",
            "##Â·##Loop:228\n",
            "train loss= 0.1726756393909454\n",
            "##Â·##Loop:229\n",
            "train loss= 0.1812706738710403\n",
            "##Â·##Loop:230\n",
            "train loss= 0.1702025085687637\n",
            "##Â·##Loop:231\n",
            "train loss= 0.2006127238273621\n",
            "##Â·##Loop:232\n",
            "train loss= 0.2106298953294754\n",
            "##Â·##Loop:233\n",
            "train loss= 0.1690445542335510\n",
            "##Â·##Loop:234\n",
            "train loss= 0.1920163333415985\n",
            "##Â·##Loop:235\n",
            "train loss= 0.3187915086746216\n",
            "##Â·##Loop:236\n",
            "train loss= 0.2944879829883575\n",
            "##Â·##Loop:237\n",
            "train loss= 0.2663092613220215\n",
            "##Â·##Loop:238\n",
            "train loss= 0.2147449553012848\n",
            "##Â·##Loop:239\n",
            "train loss= 0.2125106006860733\n",
            "##Â·##Loop:240\n",
            "train loss= 0.1028140708804131\n",
            "##Â·##Loop:241\n",
            "train loss= 0.1976830214262009\n",
            "##Â·##Loop:242\n",
            "train loss= 0.1258033663034439\n",
            "##Â·##Loop:243\n",
            "train loss= 0.2980413734912872\n",
            "##Â·##Loop:244\n",
            "train loss= 0.1962863653898239\n",
            "##Â·##Loop:245\n",
            "train loss= 0.2849666178226471\n",
            "##Â·##Loop:246\n",
            "train loss= 0.2151019126176834\n",
            "##Â·##Loop:247\n",
            "train loss= 0.1913436055183411\n",
            "##Â·##Loop:248\n",
            "train loss= 0.2892594337463379\n",
            "##Â·##Loop:249\n",
            "train loss= 0.2022472918033600\n",
            "##Â·##Loop:250\n",
            "train loss= 0.2444263994693756\n",
            "##Â·##Loop:251\n",
            "train loss= 0.2471024096012115\n",
            "##Â·##Loop:252\n",
            "train loss= 0.1901211142539978\n",
            "##Â·##Loop:253\n",
            "train loss= 0.2003474235534668\n",
            "##Â·##Loop:254\n",
            "train loss= 0.2302362918853760\n",
            "##Â·##Loop:255\n",
            "train loss= 0.1768334358930588\n",
            "##Â·##Loop:256\n",
            "train loss= 0.2132797539234161\n",
            "##Â·##Loop:257\n",
            "train loss= 0.2011434733867645\n",
            "##Â·##Loop:258\n",
            "train loss= 0.2387292385101318\n",
            "##Â·##Loop:259\n",
            "train loss= 0.2060993760824203\n",
            "##Â·##Loop:260\n",
            "train loss= 0.2312135696411133\n",
            "##Â·##Loop:261\n",
            "train loss= 0.2296672314405441\n",
            "##Â·##Loop:262\n",
            "train loss= 0.2825551033020020\n",
            "##Â·##Loop:263\n",
            "train loss= 0.2855404615402222\n",
            "##Â·##Loop:264\n",
            "train loss= 0.3040354847908020\n",
            "##Â·##Loop:265\n",
            "train loss= 0.2112835049629211\n",
            "##Â·##Loop:266\n",
            "train loss= 0.2352344691753387\n",
            "##Â·##Loop:267\n",
            "train loss= 0.1991627365350723\n",
            "##Â·##Loop:268\n",
            "train loss= 0.2185740619897842\n",
            "##Â·##Loop:269\n",
            "train loss= 0.1976133137941360\n",
            "##Â·##Loop:270\n",
            "train loss= 0.1444534957408905\n",
            "##Â·##Loop:271\n",
            "train loss= 0.1831928491592407\n",
            "##Â·##Loop:272\n",
            "train loss= 0.1957814991474152\n",
            "##Â·##Loop:273\n",
            "train loss= 0.1351395100355148\n",
            "##Â·##Loop:274\n",
            "train loss= 0.2014724910259247\n",
            "##Â·##Loop:275\n",
            "train loss= 0.2520395517349243\n",
            "##Â·##Loop:276\n",
            "train loss= 0.2189849019050598\n",
            "##Â·##Loop:277\n",
            "train loss= 0.2597945928573608\n",
            "##Â·##Loop:278\n",
            "train loss= 0.1520975530147552\n",
            "##Â·##Loop:279\n",
            "train loss= 0.2819207906723022\n",
            "##Â·##Loop:280\n",
            "train loss= 0.2616080641746521\n",
            "##Â·##Loop:281\n",
            "train loss= 0.2211384922266006\n",
            "##Â·##Loop:282\n",
            "train loss= 0.2574600577354431\n",
            "##Â·##Loop:283\n",
            "train loss= 0.2271415889263153\n",
            "##Â·##Loop:284\n",
            "train loss= 0.2142987549304962\n",
            "##Â·##Loop:285\n",
            "train loss= 0.1730684041976929\n",
            "##Â·##Loop:286\n",
            "train loss= 0.1493382900953293\n",
            "##Â·##Loop:287\n",
            "train loss= 0.1828135848045349\n",
            "##Â·##Loop:288\n",
            "train loss= 0.2122321724891663\n",
            "##Â·##Loop:289\n",
            "train loss= 0.2298183739185333\n",
            "##Â·##Loop:290\n",
            "train loss= 0.1087561100721359\n",
            "##Â·##Loop:291\n",
            "train loss= 0.2362460345029831\n",
            "##Â·##Loop:292\n",
            "train loss= 0.1652786135673523\n",
            "##Â·##Loop:293\n",
            "train loss= 0.1628132164478302\n",
            "##Â·##Loop:294\n",
            "train loss= 0.2797407507896423\n",
            "##Â·##Loop:295\n",
            "train loss= 0.2744045257568359\n",
            "##Â·##Loop:296\n",
            "train loss= 0.1231549829244614\n",
            "##Â·##Loop:297\n",
            "train loss= 0.2375397384166718\n",
            "train loss= 0.2375397384166718, Acc=0.9141\n",
            "Test Acc=0.86\n",
            "[[38  4  0]\n",
            " [ 6 44  0]\n",
            " [ 0  1 35]]\n",
            "##Â·##Loop:298\n",
            "train loss= 0.2492688894271851\n",
            "##Â·##Loop:299\n",
            "train loss= 0.2288517653942108\n",
            "##Â·##Loop:300\n",
            "train loss= 0.1731759905815125\n",
            "##Â·##Loop:301\n",
            "train loss= 0.1911334842443466\n",
            "##Â·##Loop:302\n",
            "train loss= 0.1973129957914352\n",
            "##Â·##Loop:303\n",
            "train loss= 0.1145101413130760\n",
            "##Â·##Loop:304\n",
            "train loss= 0.2149314284324646\n",
            "##Â·##Loop:305\n",
            "train loss= 0.1815150082111359\n",
            "##Â·##Loop:306\n",
            "train loss= 0.1370246261358261\n",
            "##Â·##Loop:307\n",
            "train loss= 0.2112106382846832\n",
            "##Â·##Loop:308\n",
            "train loss= 0.2057876139879227\n",
            "##Â·##Loop:309\n",
            "train loss= 0.2198408842086792\n",
            "##Â·##Loop:310\n",
            "train loss= 0.1955542117357254\n",
            "##Â·##Loop:311\n",
            "train loss= 0.2171164453029633\n",
            "##Â·##Loop:312\n",
            "train loss= 0.2286132872104645\n",
            "##Â·##Loop:313\n",
            "train loss= 0.1894544512033463\n",
            "##Â·##Loop:314\n",
            "train loss= 0.2344573140144348\n",
            "##Â·##Loop:315\n",
            "train loss= 0.2289080619812012\n",
            "##Â·##Loop:316\n",
            "train loss= 0.1887476742267609\n",
            "##Â·##Loop:317\n",
            "train loss= 0.2160961925983429\n",
            "##Â·##Loop:318\n",
            "train loss= 0.1832466721534729\n",
            "##Â·##Loop:319\n",
            "train loss= 0.1303879618644714\n",
            "##Â·##Loop:320\n",
            "train loss= 0.1715717613697052\n",
            "##Â·##Loop:321\n",
            "train loss= 0.2291455864906311\n",
            "##Â·##Loop:322\n",
            "train loss= 0.1739541590213776\n",
            "##Â·##Loop:323\n",
            "train loss= 0.2372753769159317\n",
            "##Â·##Loop:324\n",
            "train loss= 0.3217617273330688\n",
            "##Â·##Loop:325\n",
            "train loss= 0.1880475431680679\n",
            "##Â·##Loop:326\n",
            "train loss= 0.1496451348066330\n",
            "##Â·##Loop:327\n",
            "train loss= 0.1622875630855560\n",
            "##Â·##Loop:328\n",
            "train loss= 0.2320355176925659\n",
            "##Â·##Loop:329\n",
            "train loss= 0.1441422998905182\n",
            "##Â·##Loop:330\n",
            "train loss= 0.1917870193719864\n",
            "##Â·##Loop:331\n",
            "train loss= 0.1706419587135315\n",
            "##Â·##Loop:332\n",
            "train loss= 0.3095671236515045\n",
            "##Â·##Loop:333\n",
            "train loss= 0.1749401241540909\n",
            "##Â·##Loop:334\n",
            "train loss= 0.2205496728420258\n",
            "##Â·##Loop:335\n",
            "train loss= 0.1988379806280136\n",
            "##Â·##Loop:336\n",
            "train loss= 0.2036357074975967\n",
            "##Â·##Loop:337\n",
            "train loss= 0.2194757461547852\n",
            "##Â·##Loop:338\n",
            "train loss= 0.2833826243877411\n",
            "##Â·##Loop:339\n",
            "train loss= 0.2533417046070099\n",
            "##Â·##Loop:340\n",
            "train loss= 0.1261678636074066\n",
            "##Â·##Loop:341\n",
            "train loss= 0.1995333433151245\n",
            "##Â·##Loop:342\n",
            "train loss= 0.3402311503887177\n",
            "##Â·##Loop:343\n",
            "train loss= 0.1875182092189789\n",
            "##Â·##Loop:344\n",
            "train loss= 0.1719810664653778\n",
            "##Â·##Loop:345\n",
            "train loss= 0.2241787463426590\n",
            "##Â·##Loop:346\n",
            "train loss= 0.1507502794265747\n",
            "##Â·##Loop:347\n",
            "train loss= 0.1930512189865112\n",
            "##Â·##Loop:348\n",
            "train loss= 0.2041610479354858\n",
            "##Â·##Loop:349\n",
            "train loss= 0.1843191683292389\n",
            "##Â·##Loop:350\n",
            "train loss= 0.2838623225688934\n",
            "##Â·##Loop:351\n",
            "train loss= 0.3189508914947510\n",
            "##Â·##Loop:352\n",
            "train loss= 0.1791015565395355\n",
            "##Â·##Loop:353\n",
            "train loss= 0.1715952157974243\n",
            "##Â·##Loop:354\n",
            "train loss= 0.2475427687168121\n",
            "##Â·##Loop:355\n",
            "train loss= 0.1766723245382309\n",
            "##Â·##Loop:356\n",
            "train loss= 0.2241331040859222\n",
            "##Â·##Loop:357\n",
            "train loss= 0.1734542548656464\n",
            "##Â·##Loop:358\n",
            "train loss= 0.2197266966104507\n",
            "##Â·##Loop:359\n",
            "train loss= 0.1667047739028931\n",
            "##Â·##Loop:360\n",
            "train loss= 0.2245492637157440\n",
            "##Â·##Loop:361\n",
            "train loss= 0.2029223293066025\n",
            "##Â·##Loop:362\n",
            "train loss= 0.2734918892383575\n",
            "##Â·##Loop:363\n",
            "train loss= 0.1765867173671722\n",
            "##Â·##Loop:364\n",
            "train loss= 0.1560852825641632\n",
            "##Â·##Loop:365\n",
            "train loss= 0.1839319765567780\n",
            "##Â·##Loop:366\n",
            "train loss= 0.1373385190963745\n",
            "##Â·##Loop:367\n",
            "train loss= 0.2178724259138107\n",
            "##Â·##Loop:368\n",
            "train loss= 0.1998614668846130\n",
            "##Â·##Loop:369\n",
            "train loss= 0.2078861445188522\n",
            "##Â·##Loop:370\n",
            "train loss= 0.2255418002605438\n",
            "##Â·##Loop:371\n",
            "train loss= 0.1289301663637161\n",
            "##Â·##Loop:372\n",
            "train loss= 0.1829407662153244\n",
            "##Â·##Loop:373\n",
            "train loss= 0.1906852722167969\n",
            "##Â·##Loop:374\n",
            "train loss= 0.1620391011238098\n",
            "##Â·##Loop:375\n",
            "train loss= 0.2115067988634109\n",
            "##Â·##Loop:376\n",
            "train loss= 0.2475689649581909\n",
            "##Â·##Loop:377\n",
            "train loss= 0.1734188348054886\n",
            "##Â·##Loop:378\n",
            "train loss= 0.2217046916484833\n",
            "##Â·##Loop:379\n",
            "train loss= 0.2417275905609131\n",
            "##Â·##Loop:380\n",
            "train loss= 0.1910220831632614\n",
            "##Â·##Loop:381\n",
            "train loss= 0.2272334694862366\n",
            "##Â·##Loop:382\n",
            "train loss= 0.2073194682598114\n",
            "##Â·##Loop:383\n",
            "train loss= 0.2035913467407227\n",
            "##Â·##Loop:384\n",
            "train loss= 0.1664838492870331\n",
            "##Â·##Loop:385\n",
            "train loss= 0.1881223469972610\n",
            "##Â·##Loop:386\n",
            "train loss= 0.1684481948614120\n",
            "##Â·##Loop:387\n",
            "train loss= 0.1339363753795624\n",
            "##Â·##Loop:388\n",
            "train loss= 0.2019605487585068\n",
            "##Â·##Loop:389\n",
            "train loss= 0.2608611285686493\n",
            "##Â·##Loop:390\n",
            "train loss= 0.2680429518222809\n",
            "##Â·##Loop:391\n",
            "train loss= 0.1789300441741943\n",
            "##Â·##Loop:392\n",
            "train loss= 0.1366987973451614\n",
            "##Â·##Loop:393\n",
            "train loss= 0.2520223855972290\n",
            "##Â·##Loop:394\n",
            "train loss= 0.1510157287120819\n",
            "##Â·##Loop:395\n",
            "train loss= 0.1977067887783051\n",
            "##Â·##Loop:396\n",
            "train loss= 0.2734068036079407\n",
            "train loss= 0.2734068036079407, Acc=0.9141\n",
            "Test Acc=0.88\n",
            "[[40  3  0]\n",
            " [ 5 29  1]\n",
            " [ 0  2 48]]\n",
            "##Â·##Loop:397\n",
            "train loss= 0.2214804887771606\n",
            "##Â·##Loop:398\n",
            "train loss= 0.2023558318614960\n",
            "##Â·##Loop:399\n",
            "train loss= 0.1212584748864174\n",
            "##Â·##Loop:400\n",
            "train loss= 0.2086457163095474\n",
            "##Â·##Loop:401\n",
            "train loss= 0.2230027318000793\n",
            "##Â·##Loop:402\n",
            "train loss= 0.2995822131633759\n",
            "##Â·##Loop:403\n",
            "train loss= 0.1773312240839005\n",
            "##Â·##Loop:404\n",
            "train loss= 0.2478958964347839\n",
            "##Â·##Loop:405\n",
            "train loss= 0.2293435037136078\n",
            "##Â·##Loop:406\n",
            "train loss= 0.2364604175090790\n",
            "##Â·##Loop:407\n",
            "train loss= 0.1660409569740295\n",
            "##Â·##Loop:408\n",
            "train loss= 0.1734011322259903\n",
            "##Â·##Loop:409\n",
            "train loss= 0.1525778174400330\n",
            "##Â·##Loop:410\n",
            "train loss= 0.2309492081403732\n",
            "##Â·##Loop:411\n",
            "train loss= 0.1871105134487152\n",
            "##Â·##Loop:412\n",
            "train loss= 0.3246354460716248\n",
            "##Â·##Loop:413\n",
            "train loss= 0.1845400184392929\n",
            "##Â·##Loop:414\n",
            "train loss= 0.2025585174560547\n",
            "##Â·##Loop:415\n",
            "train loss= 0.2405140250921249\n",
            "##Â·##Loop:416\n",
            "train loss= 0.2183130681514740\n",
            "##Â·##Loop:417\n",
            "train loss= 0.2279367595911026\n",
            "##Â·##Loop:418\n",
            "train loss= 0.2353729903697968\n",
            "##Â·##Loop:419\n",
            "train loss= 0.2003438174724579\n",
            "##Â·##Loop:420\n",
            "train loss= 0.1956048160791397\n",
            "##Â·##Loop:421\n",
            "train loss= 0.2286944985389709\n",
            "##Â·##Loop:422\n",
            "train loss= 0.1996811777353287\n",
            "##Â·##Loop:423\n",
            "train loss= 0.2585193514823914\n",
            "##Â·##Loop:424\n",
            "train loss= 0.1422591209411621\n",
            "##Â·##Loop:425\n",
            "train loss= 0.2133066356182098\n",
            "##Â·##Loop:426\n",
            "train loss= 0.3003396987915039\n",
            "##Â·##Loop:427\n",
            "train loss= 0.2502855658531189\n",
            "##Â·##Loop:428\n",
            "train loss= 0.2023044079542160\n",
            "##Â·##Loop:429\n",
            "train loss= 0.1807176619768143\n",
            "##Â·##Loop:430\n",
            "train loss= 0.2096509784460068\n",
            "##Â·##Loop:431\n",
            "train loss= 0.2047205269336700\n",
            "##Â·##Loop:432\n",
            "train loss= 0.1442886590957642\n",
            "##Â·##Loop:433\n",
            "train loss= 0.1900138258934021\n",
            "##Â·##Loop:434\n",
            "train loss= 0.2066564261913300\n",
            "##Â·##Loop:435\n",
            "train loss= 0.2079248577356339\n",
            "##Â·##Loop:436\n",
            "train loss= 0.1528937220573425\n",
            "##Â·##Loop:437\n",
            "train loss= 0.1786472201347351\n",
            "##Â·##Loop:438\n",
            "train loss= 0.1620994806289673\n",
            "##Â·##Loop:439\n",
            "train loss= 0.2367256581783295\n",
            "##Â·##Loop:440\n",
            "train loss= 0.2181290686130524\n",
            "##Â·##Loop:441\n",
            "train loss= 0.2089921236038208\n",
            "##Â·##Loop:442\n",
            "train loss= 0.1670888066291809\n",
            "##Â·##Loop:443\n",
            "train loss= 0.2060552239418030\n",
            "##Â·##Loop:444\n",
            "train loss= 0.2401962280273438\n",
            "##Â·##Loop:445\n",
            "train loss= 0.2605808079242706\n",
            "##Â·##Loop:446\n",
            "train loss= 0.1425067186355591\n",
            "##Â·##Loop:447\n",
            "train loss= 0.2829905450344086\n",
            "##Â·##Loop:448\n",
            "train loss= 0.1907515227794647\n",
            "##Â·##Loop:449\n",
            "train loss= 0.2085928022861481\n",
            "##Â·##Loop:450\n",
            "train loss= 0.2447171211242676\n",
            "##Â·##Loop:451\n",
            "train loss= 0.1691633611917496\n",
            "##Â·##Loop:452\n",
            "train loss= 0.1664185971021652\n",
            "##Â·##Loop:453\n",
            "train loss= 0.1552339047193527\n",
            "##Â·##Loop:454\n",
            "train loss= 0.1489540040493011\n",
            "##Â·##Loop:455\n",
            "train loss= 0.2181510329246521\n",
            "##Â·##Loop:456\n",
            "train loss= 0.2427185028791428\n",
            "##Â·##Loop:457\n",
            "train loss= 0.1945973336696625\n",
            "##Â·##Loop:458\n",
            "train loss= 0.1812091469764709\n",
            "##Â·##Loop:459\n",
            "train loss= 0.2335991859436035\n",
            "##Â·##Loop:460\n",
            "train loss= 0.1693355441093445\n",
            "##Â·##Loop:461\n",
            "train loss= 0.2968803048133850\n",
            "##Â·##Loop:462\n",
            "train loss= 0.2241463214159012\n",
            "##Â·##Loop:463\n",
            "train loss= 0.2892720401287079\n",
            "##Â·##Loop:464\n",
            "train loss= 0.2554176747798920\n",
            "##Â·##Loop:465\n",
            "train loss= 0.2494570910930634\n",
            "##Â·##Loop:466\n",
            "train loss= 0.1892923116683960\n",
            "##Â·##Loop:467\n",
            "train loss= 0.1295162588357925\n",
            "##Â·##Loop:468\n",
            "train loss= 0.2328294068574905\n",
            "##Â·##Loop:469\n",
            "train loss= 0.2276528775691986\n",
            "##Â·##Loop:470\n",
            "train loss= 0.2256262749433517\n",
            "##Â·##Loop:471\n",
            "train loss= 0.2746596336364746\n",
            "##Â·##Loop:472\n",
            "train loss= 0.2864496409893036\n",
            "##Â·##Loop:473\n",
            "train loss= 0.1956686079502106\n",
            "##Â·##Loop:474\n",
            "train loss= 0.2277453690767288\n",
            "##Â·##Loop:475\n",
            "train loss= 0.1422234922647476\n",
            "##Â·##Loop:476\n",
            "train loss= 0.1802310049533844\n",
            "##Â·##Loop:477\n",
            "train loss= 0.1596007049083710\n",
            "##Â·##Loop:478\n",
            "train loss= 0.2131034433841705\n",
            "##Â·##Loop:479\n",
            "train loss= 0.1792200207710266\n",
            "##Â·##Loop:480\n",
            "train loss= 0.2135272622108459\n",
            "##Â·##Loop:481\n",
            "train loss= 0.1564777046442032\n",
            "##Â·##Loop:482\n",
            "train loss= 0.1509803384542465\n",
            "##Â·##Loop:483\n",
            "train loss= 0.1564313471317291\n",
            "##Â·##Loop:484\n",
            "train loss= 0.1434283703565598\n",
            "##Â·##Loop:485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uB902g-LbFOf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "!mkdir my_net_cwe\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4U1KDGvB7n85",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rm -r my_net_cwe15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O-BhXcyiF2Rz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mv checkpoint save_cwe_rnn.ckpt.data-00000-of-00001 save_cwe_rnn.ckpt.index save_cwe_rnn.ckpt.meta my_net_cwe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rUWFPzUgd4P8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rm tomekLinked_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9CBe6OrLhjpe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "file_name='scaler_rnn_cwe'\n",
        "fileObject = open(file_name,'wb')\n",
        "pickle.dump(scaler,fileObject)\n",
        "fileObject.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x-wmhhv7j4OY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Generate Predictions for the raw data by batch\n",
        "batch_size = 64\n",
        "batch_num = len(dataX)//batch_size\n",
        "nn_dataX = None\n",
        "print(batch_num)\n",
        "#restore rnn session\n",
        "sess = tf.Session()\n",
        "saver.restore(sess, 'my_net_cwe_central/save_cwe_rnn.ckpt')\n",
        "for i in range(0,batch_num+1):\n",
        "  print(i)\n",
        "  if(i!=batch_num):\n",
        "      batch_X = dataX[i*batch_size:(i+1)*batch_size,]\n",
        "      batch_X = scaler.transform(batch_X).reshape([-1,window_size,1])\n",
        "      batch_pred = sess.run(pred,feed_dict={tf_x: batch_X})\n",
        "      if nn_dataX is None:\n",
        "        nn_dataX = batch_pred\n",
        "      else:\n",
        "        nn_dataX = np.vstack([nn_dataX,batch_pred])\n",
        "      \n",
        "  else: \n",
        "      batch_X = dataX[i*batch_size:]\n",
        "      batch_X = scaler.transform(batch_X).reshape([-1,window_size,1])\n",
        "      batch_pred = sess.run(pred,feed_dict={tf_x: batch_X})\n",
        "      nn_dataX = np.vstack([nn_dataX,batch_pred])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
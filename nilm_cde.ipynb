{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nilm_cde.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RhysWangJunfei/nilm/blob/master/nilm_cde.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "YR6U_iIt_P2z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import io\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split \n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-E8b-zMV_SXW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''Sliding window function'''\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX = []\n",
        "    for i in range(len(dataset)-look_back+1):\n",
        "        a = dataset[i:(i+look_back)]\n",
        "        dataX.append(a)\n",
        "    return np.array(dataX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ABrYmT54_UYL",
        "colab_type": "code",
        "outputId": "5b5b0b8d-9c91-4d3c-e526-8e75fa76a49b",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "'''Load data'''\n",
        "WHE_data = pd.read_csv(io.BytesIO(uploaded['Electricity_WHE.csv']))['P']\n",
        "#WHE_data = pd.read_csv('Electricity_WHE.csv')['P']\n",
        "#uploaded = files.upload()\n",
        "#CDE_data = pd.read_csv(io.BytesIO(uploaded['Electricity_CDE.csv']))['P']\n",
        "CDE_data = pd.read_csv('Electricity_CDE.csv')['P']\n",
        "'''\n",
        "CDE_data = pd.read_csv(base_dir+'Electricity_CDE.csv')['P']\n",
        "CWE_data = pd.read_csv(base_dir+'Electricity_CWE.csv')['P']\n",
        "DWE_data = pd.read_csv(base_dir+'Electricity_DWE.csv')['P']\n",
        "FRE_data = pd.read_csv(base_dir+'Electricity_FRE.csv')['P']\n",
        "HPE_data = pd.read_csv(base_dir+'Electricity_HPE.csv')['P']\n",
        "HTE_data = pd.read_csv(base_dir+'Electricity_HTE.csv')['P']\n",
        "'''"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a1fbf82c-5c80-4242-a961-b5ff4ef1d5f7\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a1fbf82c-5c80-4242-a961-b5ff4ef1d5f7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Electricity_WHE.csv to Electricity_WHE (1).csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nCDE_data = pd.read_csv(base_dir+'Electricity_CDE.csv')['P']\\nCWE_data = pd.read_csv(base_dir+'Electricity_CWE.csv')['P']\\nDWE_data = pd.read_csv(base_dir+'Electricity_DWE.csv')['P']\\nFRE_data = pd.read_csv(base_dir+'Electricity_FRE.csv')['P']\\nHPE_data = pd.read_csv(base_dir+'Electricity_HPE.csv')['P']\\nHTE_data = pd.read_csv(base_dir+'Electricity_HTE.csv')['P']\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "X9bRBWac_mHu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "window_size=60\n",
        "\n",
        "dataX = create_dataset(WHE_data.as_matrix(), window_size)\n",
        "\n",
        "#1-100,101-400,401-4400,4401-5200,5200+\n",
        "\n",
        "cde_Y = CDE_data[window_size-1:].values.reshape([CDE_data.shape[0]-window_size+1,1])\n",
        "categorized_cde_Y = np.zeros(cde_Y.shape)\n",
        "categorized_cde_Y[[np.where(cde_Y>5200)[0]],:]=5\n",
        "categorized_cde_Y[[np.where((cde_Y>4400)&(cde_Y<=5200))[0]],:]=4\n",
        "categorized_cde_Y[[np.where((cde_Y>400)&(cde_Y<=4400))[0]],:]=3\n",
        "categorized_cde_Y[[np.where((cde_Y>100)&(cde_Y<=400))[0]],:]=2\n",
        "categorized_cde_Y[[np.where((cde_Y>0)&(cde_Y<=100))[0]],:]=1\n",
        "cdeY=categorized_cde_Y[categorized_cde_Y>0].reshape(-1,1)\n",
        "cdeX=dataX[[np.where(categorized_cde_Y>0)[0]],:][0]\n",
        "\n",
        "\n",
        "encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
        "cdeY_1hot = encoder.fit_transform(cdeY)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(cdeX, cdeY_1hot, test_size=0.1, shuffle=True)\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train.astype(float))\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BJhZJcATH4ax",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''Hyper parameters for deep learning'''\n",
        "# Hyper Parameters\n",
        "LR = 0.001               # learning rate\n",
        "#cfg_list = nf.model_configs()\n",
        "#error_list = []\n",
        "\n",
        "#hyperparameters\n",
        "batch_size=512\n",
        "unit_num=128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z9nSbtUdH8tw",
        "colab_type": "code",
        "outputId": "7fefaa25-a2e3-43e3-c645-769681e972fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "'''RNN Model Definition'''\n",
        "#define inputs\n",
        "tf_x = tf.placeholder(tf.float32, [None, window_size,1])\n",
        "tf_y = tf.placeholder(tf.int32, [None, 5])\n",
        "#Transform from 3d to 2d\n",
        "#X = tf.reshape(tf_x, [-1, 1])\n",
        "#X = tf.reshape(tf_x, [-1, window_size])\n",
        "\n",
        "\n",
        "'''\n",
        "add_layer('l1',X,window_size, 128, activation_function=tf.nn.sigmoid)\n",
        "l2 = add_layer('l2',l1, 128,32 , activation_function=tf.nn.sigmoid)\n",
        "l3 = add_layer('l3',l2, 32,8 , activation_function=tf.nn.sigmoid)\n",
        "pred = add_layer('l4',l3, 8,1 , activation_function=None)\n",
        "'''\n",
        "#X_in = tf.reshape(tf_x, [-1, 1])\n",
        "lstm_cell =tf.contrib.rnn.BasicLSTMCell(num_units=unit_num)\n",
        "outputs, (h_c, h_n) = tf.nn.dynamic_rnn(\n",
        "    lstm_cell,                   # cell you have chosen\n",
        "    tf_x,                      # input\n",
        "    initial_state=None,         # the initial hidden state\n",
        "    dtype=tf.float32,           # must given if set initial_state = None\n",
        "    time_major=False,           # False: (batch, time step, input); True: (time step, batch, input)\n",
        ")\n",
        "l1 = tf.layers.dense(outputs[:, -1, :],64,activation=tf.nn.leaky_relu)\n",
        "l2 = tf.layers.dense(l1,32,activation=tf.nn.leaky_relu)\n",
        "l3 = tf.layers.dense(l2,16,activation=tf.nn.leaky_relu)\n",
        "#l4 = tf.layers.dense(l3,8,activation=tf.nn.leaky_relu)\n",
        "#l5 = tf.layers.dense(l4,4,activation=tf.nn.leaky_relu)\n",
        "#l6 = tf.layers.dense(l5,32,activation=tf.nn.leaky_relu)\n",
        "#l7 = tf.layers.dense(l2,8,activation=tf.nn.leaky_relu)\n",
        "pred = tf.layers.dense(l3,5,activation=tf.nn.relu)\n",
        "#pred = add_layer('dense_1',outputs[:, -1, :], unit_num, 1, activation_function=tf.nn.leaky_relu)\n",
        "'''\n",
        "#dense_2 = add_layer('dense_2',dense_1, 32, 16, activation_function=tf.nn.leaky_relu)\n",
        "#dense_3 = add_layer('dense_3',dense_2, 16, 4, activation_function=tf.nn.leaky_relu)\n",
        "#dense_4 = add_layer('dense_4',dense_1, 1024, 512, activation_function=tf.nn.relu)\n",
        "#dense_5 = add_layer('dense_5',dense_4, 512, 256, activation_function=tf.nn.relu)\n",
        "#dense_6 = add_layer('dense_6',dense_5, 256, 128, activation_function=tf.nn.relu)\n",
        "#dense_7 = add_layer('dense_7',dense_1, 128, 64, activation_function=tf.nn.relu)\n",
        "#dense_8 = add_layer('dense_8',dense_7, 64, 16, activation_function=tf.nn.relu)\n",
        "#dense_9 = add_layer('dense_9',dense_1, 8, 4, activation_function=tf.nn.relu)\n",
        "#pred = add_layer('output', dense_3,4, 1, activation_function=None)\n",
        "'''\n",
        "with tf.name_scope('loss'):\n",
        "    cross_entropy =  tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_y, logits=pred) \n",
        "    loss = tf.reduce_mean(cross_entropy)\n",
        "    tf.summary.scalar(\"loss\",tensor=loss)\n",
        "\n",
        "train_op = tf.train.AdamOptimizer(LR).minimize(loss)\n",
        "\n",
        "accuracy = tf.metrics.accuracy(          # return (acc, update_op), and create 2 local variables\n",
        "    labels=tf.argmax(tf_y, axis=1), predictions=tf.argmax(pred, axis=1),)[1]\n",
        "\n",
        "'''\n",
        "gvs = optimizer.compute_gradients(loss)\n",
        "capped_gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
        "train_op = optimizer.apply_gradients(capped_gvs) \n",
        "'''\n",
        "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer()) \n",
        "sess = tf.Session()\n",
        "sess.run(init_op)\n",
        "merged = tf.summary.merge_all()\n",
        "writer = tf.summary.FileWriter(\"logss/\", sess.graph) # tensorflow >=0.12\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-d65318d83a9d>:17: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uYaNNydtIE1i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263407
        },
        "outputId": "975574c0-0b39-486f-ca00-5ea58dcae499"
      },
      "cell_type": "code",
      "source": [
        "batch_num = len(X_train)//batch_size\n",
        "for j in range(0,5000):\n",
        "    print('###epoch: '+str(j)+'###')\n",
        "    for i in range(0,batch_num+1):\n",
        "        if(i!=batch_num):\n",
        "            batch_X = X_train[i*batch_size:(i+1)*batch_size,].reshape([batch_size,window_size,1])\n",
        "            batch_Y = y_train[i*batch_size:(i+1)*batch_size,]\n",
        "        else: \n",
        "            batch_X = X_train[-batch_size:].reshape([batch_size,window_size,1])\n",
        "            batch_Y = y_train[-batch_size:,]\n",
        "        sess.run(train_op,{tf_x:batch_X,tf_y:batch_Y})\n",
        "        cost_ = sess.run(loss, {tf_x: batch_X, tf_y:batch_Y})\n",
        "        acc_train = sess.run(accuracy,{tf_x: batch_X, tf_y:batch_Y})\n",
        "        acc_test = sess.run(accuracy,feed_dict={tf_x: X_test.reshape([X_test.shape[0],window_size,1]), tf_y:y_test})\n",
        "        if i%10 == 0:\n",
        "            rs = sess.run(merged,feed_dict={tf_x: batch_X, tf_y:batch_Y})\n",
        "            pre = sess.run(pred,feed_dict={tf_x: batch_X, tf_y:batch_Y})\n",
        "            writer.add_summary(rs, i+j*batch_num)\n",
        "            y_lables_argmax = tf.argmax(tf_y,axis=1)  \n",
        "            y_pred_argmax = tf.argmax(pre,axis=1)\n",
        "            print('###Batch: '+str(i)+': train loss= %.4f' % cost_+', Acc=%.2f'% acc_train)\n",
        "            print('Test Acc=%.2f'% acc_test)\n",
        "            if acc_train>0.985:\n",
        "              save_path = saver.save(sess, \"my_net/save_net_rnn.ckpt\")\n",
        "              #if acc==1:\n",
        "              break\n",
        "sess.close()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "###epoch: 0###\n",
            "###Batch: 0: train loss= 1.5748, Acc=0.53\n",
            "Test Acc=0.53\n",
            "###Batch: 10: train loss= 1.3139, Acc=0.53\n",
            "Test Acc=0.53\n",
            "###Batch: 20: train loss= 1.2558, Acc=0.52\n",
            "Test Acc=0.52\n",
            "###Batch: 30: train loss= 1.1967, Acc=0.52\n",
            "Test Acc=0.52\n",
            "###epoch: 1###\n",
            "###Batch: 0: train loss= 1.1309, Acc=0.53\n",
            "Test Acc=0.53\n",
            "###Batch: 10: train loss= 1.0208, Acc=0.54\n",
            "Test Acc=0.55\n",
            "###Batch: 20: train loss= 0.6730, Acc=0.57\n",
            "Test Acc=0.57\n",
            "###Batch: 30: train loss= 0.6409, Acc=0.59\n",
            "Test Acc=0.60\n",
            "###epoch: 2###\n",
            "###Batch: 0: train loss= 0.5905, Acc=0.61\n",
            "Test Acc=0.61\n",
            "###Batch: 10: train loss= 0.4239, Acc=0.63\n",
            "Test Acc=0.64\n",
            "###Batch: 20: train loss= 0.3750, Acc=0.66\n",
            "Test Acc=0.66\n",
            "###Batch: 30: train loss= 0.4136, Acc=0.68\n",
            "Test Acc=0.68\n",
            "###epoch: 3###\n",
            "###Batch: 0: train loss= 0.3125, Acc=0.69\n",
            "Test Acc=0.69\n",
            "###Batch: 10: train loss= 0.2586, Acc=0.71\n",
            "Test Acc=0.71\n",
            "###Batch: 20: train loss= 0.2209, Acc=0.73\n",
            "Test Acc=0.73\n",
            "###Batch: 30: train loss= 0.2101, Acc=0.74\n",
            "Test Acc=0.74\n",
            "###epoch: 4###\n",
            "###Batch: 0: train loss= 0.2113, Acc=0.75\n",
            "Test Acc=0.76\n",
            "###Batch: 10: train loss= 0.1679, Acc=0.77\n",
            "Test Acc=0.77\n",
            "###Batch: 20: train loss= 0.1541, Acc=0.78\n",
            "Test Acc=0.78\n",
            "###Batch: 30: train loss= 0.1639, Acc=0.79\n",
            "Test Acc=0.79\n",
            "###epoch: 5###\n",
            "###Batch: 0: train loss= 0.1746, Acc=0.80\n",
            "Test Acc=0.80\n",
            "###Batch: 10: train loss= 0.1192, Acc=0.80\n",
            "Test Acc=0.80\n",
            "###Batch: 20: train loss= 0.1621, Acc=0.81\n",
            "Test Acc=0.81\n",
            "###Batch: 30: train loss= 0.1536, Acc=0.82\n",
            "Test Acc=0.82\n",
            "###epoch: 6###\n",
            "###Batch: 0: train loss= 0.1553, Acc=0.82\n",
            "Test Acc=0.82\n",
            "###Batch: 10: train loss= 0.1002, Acc=0.83\n",
            "Test Acc=0.83\n",
            "###Batch: 20: train loss= 0.1309, Acc=0.83\n",
            "Test Acc=0.84\n",
            "###Batch: 30: train loss= 0.1476, Acc=0.84\n",
            "Test Acc=0.84\n",
            "###epoch: 7###\n",
            "###Batch: 0: train loss= 0.1452, Acc=0.84\n",
            "Test Acc=0.84\n",
            "###Batch: 10: train loss= 0.0996, Acc=0.85\n",
            "Test Acc=0.85\n",
            "###Batch: 20: train loss= 0.1264, Acc=0.85\n",
            "Test Acc=0.85\n",
            "###Batch: 30: train loss= 0.1325, Acc=0.86\n",
            "Test Acc=0.86\n",
            "###epoch: 8###\n",
            "###Batch: 0: train loss= 0.1393, Acc=0.86\n",
            "Test Acc=0.86\n",
            "###Batch: 10: train loss= 0.0882, Acc=0.86\n",
            "Test Acc=0.86\n",
            "###Batch: 20: train loss= 0.1308, Acc=0.87\n",
            "Test Acc=0.87\n",
            "###Batch: 30: train loss= 0.1342, Acc=0.87\n",
            "Test Acc=0.87\n",
            "###epoch: 9###\n",
            "###Batch: 0: train loss= 0.1283, Acc=0.87\n",
            "Test Acc=0.87\n",
            "###Batch: 10: train loss= 0.0761, Acc=0.87\n",
            "Test Acc=0.87\n",
            "###Batch: 20: train loss= 0.1265, Acc=0.88\n",
            "Test Acc=0.88\n",
            "###Batch: 30: train loss= 0.1265, Acc=0.88\n",
            "Test Acc=0.88\n",
            "###epoch: 10###\n",
            "###Batch: 0: train loss= 0.1291, Acc=0.88\n",
            "Test Acc=0.88\n",
            "###Batch: 10: train loss= 0.0733, Acc=0.88\n",
            "Test Acc=0.88\n",
            "###Batch: 20: train loss= 0.1278, Acc=0.89\n",
            "Test Acc=0.89\n",
            "###Batch: 30: train loss= 0.1203, Acc=0.89\n",
            "Test Acc=0.89\n",
            "###epoch: 11###\n",
            "###Batch: 0: train loss= 0.1243, Acc=0.89\n",
            "Test Acc=0.89\n",
            "###Batch: 10: train loss= 0.0690, Acc=0.89\n",
            "Test Acc=0.89\n",
            "###Batch: 20: train loss= 0.1223, Acc=0.89\n",
            "Test Acc=0.89\n",
            "###Batch: 30: train loss= 0.1180, Acc=0.90\n",
            "Test Acc=0.90\n",
            "###epoch: 12###\n",
            "###Batch: 0: train loss= 0.1185, Acc=0.90\n",
            "Test Acc=0.90\n",
            "###Batch: 10: train loss= 0.0645, Acc=0.90\n",
            "Test Acc=0.90\n",
            "###Batch: 20: train loss= 0.1174, Acc=0.90\n",
            "Test Acc=0.90\n",
            "###Batch: 30: train loss= 0.1151, Acc=0.90\n",
            "Test Acc=0.90\n",
            "###epoch: 13###\n",
            "###Batch: 0: train loss= 0.1173, Acc=0.90\n",
            "Test Acc=0.90\n",
            "###Batch: 10: train loss= 0.0608, Acc=0.90\n",
            "Test Acc=0.90\n",
            "###Batch: 20: train loss= 0.1178, Acc=0.91\n",
            "Test Acc=0.91\n",
            "###Batch: 30: train loss= 0.1142, Acc=0.91\n",
            "Test Acc=0.91\n",
            "###epoch: 14###\n",
            "###Batch: 0: train loss= 0.1142, Acc=0.91\n",
            "Test Acc=0.91\n",
            "###Batch: 10: train loss= 0.0577, Acc=0.91\n",
            "Test Acc=0.91\n",
            "###Batch: 20: train loss= 0.1169, Acc=0.91\n",
            "Test Acc=0.91\n",
            "###Batch: 30: train loss= 0.1101, Acc=0.91\n",
            "Test Acc=0.91\n",
            "###epoch: 15###\n",
            "###Batch: 0: train loss= 0.1151, Acc=0.91\n",
            "Test Acc=0.91\n",
            "###Batch: 10: train loss= 0.0588, Acc=0.91\n",
            "Test Acc=0.91\n",
            "###Batch: 20: train loss= 0.1208, Acc=0.91\n",
            "Test Acc=0.91\n",
            "###Batch: 30: train loss= 0.1073, Acc=0.92\n",
            "Test Acc=0.92\n",
            "###epoch: 16###\n",
            "###Batch: 0: train loss= 0.1128, Acc=0.92\n",
            "Test Acc=0.92\n",
            "###Batch: 10: train loss= 0.0534, Acc=0.92\n",
            "Test Acc=0.92\n",
            "###Batch: 20: train loss= 0.1137, Acc=0.92\n",
            "Test Acc=0.92\n",
            "###Batch: 30: train loss= 0.1012, Acc=0.92\n",
            "Test Acc=0.92\n",
            "###epoch: 17###\n",
            "###Batch: 0: train loss= 0.1121, Acc=0.92\n",
            "Test Acc=0.92\n",
            "###Batch: 10: train loss= 0.0477, Acc=0.92\n",
            "Test Acc=0.92\n",
            "###Batch: 20: train loss= 0.1058, Acc=0.92\n",
            "Test Acc=0.92\n",
            "###Batch: 30: train loss= 0.0967, Acc=0.92\n",
            "Test Acc=0.92\n",
            "###epoch: 18###\n",
            "###Batch: 0: train loss= 0.1044, Acc=0.92\n",
            "Test Acc=0.92\n",
            "###Batch: 10: train loss= 0.0432, Acc=0.92\n",
            "Test Acc=0.92\n",
            "###Batch: 20: train loss= 0.0961, Acc=0.93\n",
            "Test Acc=0.93\n",
            "###Batch: 30: train loss= 0.0947, Acc=0.93\n",
            "Test Acc=0.93\n",
            "###epoch: 19###\n",
            "###Batch: 0: train loss= 0.0962, Acc=0.93\n",
            "Test Acc=0.93\n",
            "###Batch: 10: train loss= 0.0410, Acc=0.93\n",
            "Test Acc=0.93\n",
            "###Batch: 20: train loss= 0.0905, Acc=0.93\n",
            "Test Acc=0.93\n",
            "###Batch: 30: train loss= 0.0874, Acc=0.93\n",
            "Test Acc=0.93\n",
            "###epoch: 20###\n",
            "###Batch: 0: train loss= 0.0920, Acc=0.93\n",
            "Test Acc=0.93\n",
            "###Batch: 10: train loss= 0.0395, Acc=0.93\n",
            "Test Acc=0.93\n",
            "###Batch: 20: train loss= 0.0891, Acc=0.93\n",
            "Test Acc=0.93\n",
            "###Batch: 30: train loss= 0.0878, Acc=0.93\n",
            "Test Acc=0.93\n",
            "###epoch: 21###\n",
            "###Batch: 0: train loss= 0.0926, Acc=0.93\n",
            "Test Acc=0.93\n",
            "###Batch: 10: train loss= 0.0402, Acc=0.93\n",
            "Test Acc=0.93\n",
            "###Batch: 20: train loss= 0.0952, Acc=0.93\n",
            "Test Acc=0.93\n",
            "###Batch: 30: train loss= 0.0855, Acc=0.93\n",
            "Test Acc=0.93\n",
            "###epoch: 22###\n",
            "###Batch: 0: train loss= 0.0918, Acc=0.93\n",
            "Test Acc=0.93\n",
            "###Batch: 10: train loss= 0.0356, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###Batch: 20: train loss= 0.0881, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###Batch: 30: train loss= 0.0799, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###epoch: 23###\n",
            "###Batch: 0: train loss= 0.0958, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###Batch: 10: train loss= 0.0370, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###Batch: 20: train loss= 0.0871, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###Batch: 30: train loss= 0.0801, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###epoch: 24###\n",
            "###Batch: 0: train loss= 0.0896, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###Batch: 10: train loss= 0.0398, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###Batch: 20: train loss= 0.0897, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###Batch: 30: train loss= 0.0810, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###epoch: 25###\n",
            "###Batch: 0: train loss= 0.0912, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###Batch: 10: train loss= 0.0368, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###Batch: 20: train loss= 0.0880, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###Batch: 30: train loss= 0.0772, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###epoch: 26###\n",
            "###Batch: 0: train loss= 0.0956, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###Batch: 10: train loss= 0.0365, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###Batch: 20: train loss= 0.0850, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###Batch: 30: train loss= 0.0777, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###epoch: 27###\n",
            "###Batch: 0: train loss= 0.0760, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###Batch: 10: train loss= 0.0383, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###Batch: 20: train loss= 0.0813, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###Batch: 30: train loss= 0.0754, Acc=0.94\n",
            "Test Acc=0.94\n",
            "###epoch: 28###\n",
            "###Batch: 0: train loss= 0.0748, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 10: train loss= 0.0365, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 20: train loss= 0.0833, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 30: train loss= 0.0759, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###epoch: 29###\n",
            "###Batch: 0: train loss= 0.0817, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 10: train loss= 0.0341, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 20: train loss= 0.0850, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 30: train loss= 0.0770, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###epoch: 30###\n",
            "###Batch: 0: train loss= 0.0800, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 10: train loss= 0.0337, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 20: train loss= 0.0786, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 30: train loss= 0.0741, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###epoch: 31###\n",
            "###Batch: 0: train loss= 0.0898, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 10: train loss= 0.0335, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 20: train loss= 0.0775, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 30: train loss= 0.0741, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###epoch: 32###\n",
            "###Batch: 0: train loss= 0.0743, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 10: train loss= 0.0337, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 20: train loss= 0.0770, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 30: train loss= 0.0732, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###epoch: 33###\n",
            "###Batch: 0: train loss= 0.0782, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 10: train loss= 0.0324, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 20: train loss= 0.0728, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 30: train loss= 0.0711, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###epoch: 34###\n",
            "###Batch: 0: train loss= 0.0834, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 10: train loss= 0.0331, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 20: train loss= 0.0765, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 30: train loss= 0.0673, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###epoch: 35###\n",
            "###Batch: 0: train loss= 0.0733, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 10: train loss= 0.0300, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 20: train loss= 0.0750, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 30: train loss= 0.0670, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###epoch: 36###\n",
            "###Batch: 0: train loss= 0.0763, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 10: train loss= 0.0314, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 20: train loss= 0.0696, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###Batch: 30: train loss= 0.0647, Acc=0.95\n",
            "Test Acc=0.95\n",
            "###epoch: 37###\n",
            "###Batch: 0: train loss= 0.0654, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 10: train loss= 0.0320, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 20: train loss= 0.0758, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 30: train loss= 0.0678, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###epoch: 38###\n",
            "###Batch: 0: train loss= 0.0757, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 10: train loss= 0.0283, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 20: train loss= 0.0686, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 30: train loss= 0.0643, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###epoch: 39###\n",
            "###Batch: 0: train loss= 0.0690, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 10: train loss= 0.0314, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 20: train loss= 0.0671, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 30: train loss= 0.0595, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###epoch: 40###\n",
            "###Batch: 0: train loss= 0.0686, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 10: train loss= 0.0314, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 20: train loss= 0.0635, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 30: train loss= 0.0591, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###epoch: 41###\n",
            "###Batch: 0: train loss= 0.0749, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 10: train loss= 0.0315, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 20: train loss= 0.0655, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 30: train loss= 0.0613, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###epoch: 42###\n",
            "###Batch: 0: train loss= 0.0746, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 10: train loss= 0.0326, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 20: train loss= 0.0641, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 30: train loss= 0.0552, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###epoch: 43###\n",
            "###Batch: 0: train loss= 0.0636, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 10: train loss= 0.0304, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 20: train loss= 0.0636, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 30: train loss= 0.0532, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###epoch: 44###\n",
            "###Batch: 0: train loss= 0.0699, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 10: train loss= 0.0332, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 20: train loss= 0.0619, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 30: train loss= 0.0569, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###epoch: 45###\n",
            "###Batch: 0: train loss= 0.0624, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 10: train loss= 0.0285, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 20: train loss= 0.0654, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 30: train loss= 0.0626, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###epoch: 46###\n",
            "###Batch: 0: train loss= 0.0635, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 10: train loss= 0.0354, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 20: train loss= 0.0698, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 30: train loss= 0.0619, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###epoch: 47###\n",
            "###Batch: 0: train loss= 0.0586, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 10: train loss= 0.0311, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 20: train loss= 0.0634, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 30: train loss= 0.0591, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###epoch: 48###\n",
            "###Batch: 0: train loss= 0.0657, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 10: train loss= 0.0286, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 20: train loss= 0.0630, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 30: train loss= 0.0586, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###epoch: 49###\n",
            "###Batch: 0: train loss= 0.0630, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 10: train loss= 0.0320, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 20: train loss= 0.0638, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 30: train loss= 0.0561, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###epoch: 50###\n",
            "###Batch: 0: train loss= 0.0621, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 10: train loss= 0.0275, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 20: train loss= 0.0578, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 30: train loss= 0.0582, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###epoch: 51###\n",
            "###Batch: 0: train loss= 0.0619, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 10: train loss= 0.0264, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 20: train loss= 0.0558, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 30: train loss= 0.0574, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###epoch: 52###\n",
            "###Batch: 0: train loss= 0.0602, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 10: train loss= 0.0247, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 20: train loss= 0.0534, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###Batch: 30: train loss= 0.0578, Acc=0.96\n",
            "Test Acc=0.96\n",
            "###epoch: 53###\n",
            "###Batch: 0: train loss= 0.0611, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0253, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0547, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0602, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 54###\n",
            "###Batch: 0: train loss= 0.0620, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0232, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0531, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0600, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 55###\n",
            "###Batch: 0: train loss= 0.0560, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0252, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0622, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0552, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 56###\n",
            "###Batch: 0: train loss= 0.0542, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0259, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0559, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0540, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 57###\n",
            "###Batch: 0: train loss= 0.0618, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0223, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0520, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0524, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 58###\n",
            "###Batch: 0: train loss= 0.0546, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0227, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0554, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0547, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 59###\n",
            "###Batch: 0: train loss= 0.0574, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0251, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0508, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0517, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 60###\n",
            "###Batch: 0: train loss= 0.0562, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0244, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0515, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0522, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 61###\n",
            "###Batch: 0: train loss= 0.0549, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0224, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0472, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0482, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 62###\n",
            "###Batch: 0: train loss= 0.0644, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0194, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0487, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0495, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 63###\n",
            "###Batch: 0: train loss= 0.0554, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0198, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0539, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0495, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 64###\n",
            "###Batch: 0: train loss= 0.0559, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0209, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0469, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0538, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 65###\n",
            "###Batch: 0: train loss= 0.0522, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0210, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0506, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0488, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 66###\n",
            "###Batch: 0: train loss= 0.0583, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0178, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0489, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0468, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 67###\n",
            "###Batch: 0: train loss= 0.0564, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0242, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0472, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0491, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 68###\n",
            "###Batch: 0: train loss= 0.0497, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0194, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0441, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0459, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 69###\n",
            "###Batch: 0: train loss= 0.0515, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0184, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0512, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0533, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 70###\n",
            "###Batch: 0: train loss= 0.0485, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0232, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0432, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0471, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 71###\n",
            "###Batch: 0: train loss= 0.0509, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0214, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0427, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0513, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 72###\n",
            "###Batch: 0: train loss= 0.0458, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0168, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0412, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0475, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 73###\n",
            "###Batch: 0: train loss= 0.0546, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0206, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0473, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0530, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 74###\n",
            "###Batch: 0: train loss= 0.0447, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0224, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0431, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0510, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 75###\n",
            "###Batch: 0: train loss= 0.0444, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0203, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0421, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0480, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 76###\n",
            "###Batch: 0: train loss= 0.0416, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0208, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0411, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0471, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 77###\n",
            "###Batch: 0: train loss= 0.0430, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0216, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0380, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0496, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 78###\n",
            "###Batch: 0: train loss= 0.0412, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0201, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0425, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0487, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 79###\n",
            "###Batch: 0: train loss= 0.0383, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0214, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0391, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0477, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 80###\n",
            "###Batch: 0: train loss= 0.0391, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0195, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0383, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0436, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 81###\n",
            "###Batch: 0: train loss= 0.0381, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0193, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0389, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0452, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 82###\n",
            "###Batch: 0: train loss= 0.0406, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0204, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0368, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0469, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 83###\n",
            "###Batch: 0: train loss= 0.0362, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0214, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0358, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0409, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 84###\n",
            "###Batch: 0: train loss= 0.0432, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0192, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0401, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0430, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 85###\n",
            "###Batch: 0: train loss= 0.0382, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0168, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0360, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0430, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 86###\n",
            "###Batch: 0: train loss= 0.0374, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0207, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0346, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0419, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 87###\n",
            "###Batch: 0: train loss= 0.0382, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0182, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0335, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0387, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 88###\n",
            "###Batch: 0: train loss= 0.0434, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0183, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 20: train loss= 0.0352, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 30: train loss= 0.0374, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###epoch: 89###\n",
            "###Batch: 0: train loss= 0.0394, Acc=0.97\n",
            "Test Acc=0.97\n",
            "###Batch: 10: train loss= 0.0187, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0341, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0341, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 90###\n",
            "###Batch: 0: train loss= 0.0388, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0185, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0361, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0451, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 91###\n",
            "###Batch: 0: train loss= 0.0376, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0160, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0327, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0416, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 92###\n",
            "###Batch: 0: train loss= 0.0353, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0163, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0304, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0342, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 93###\n",
            "###Batch: 0: train loss= 0.0403, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0172, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0313, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0376, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 94###\n",
            "###Batch: 0: train loss= 0.0322, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0157, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0275, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0333, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 95###\n",
            "###Batch: 0: train loss= 0.0313, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0203, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0247, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0379, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 96###\n",
            "###Batch: 0: train loss= 0.0359, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0189, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0301, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0362, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 97###\n",
            "###Batch: 0: train loss= 0.0473, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0158, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0330, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0350, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 98###\n",
            "###Batch: 0: train loss= 0.0391, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0174, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0281, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0342, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 99###\n",
            "###Batch: 0: train loss= 0.0353, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0190, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0388, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0363, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 100###\n",
            "###Batch: 0: train loss= 0.0384, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0177, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0309, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0353, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 101###\n",
            "###Batch: 0: train loss= 0.0364, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0162, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0297, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0361, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 102###\n",
            "###Batch: 0: train loss= 0.0341, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0161, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0264, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0294, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 103###\n",
            "###Batch: 0: train loss= 0.0334, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0128, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0252, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0208, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 104###\n",
            "###Batch: 0: train loss= 0.0302, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0122, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0217, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0173, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 105###\n",
            "###Batch: 0: train loss= 0.0272, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0143, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0219, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0195, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 106###\n",
            "###Batch: 0: train loss= 0.0308, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0107, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0204, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0150, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 107###\n",
            "###Batch: 0: train loss= 0.0305, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0142, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0219, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0200, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 108###\n",
            "###Batch: 0: train loss= 0.0325, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0094, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0240, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0289, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 109###\n",
            "###Batch: 0: train loss= 0.0301, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0136, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0558, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0180, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 110###\n",
            "###Batch: 0: train loss= 0.0422, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0138, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0312, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0284, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 111###\n",
            "###Batch: 0: train loss= 0.0303, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0152, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0280, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0200, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 112###\n",
            "###Batch: 0: train loss= 0.0299, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0077, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0210, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0180, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 113###\n",
            "###Batch: 0: train loss= 0.0315, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0093, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0243, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0179, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 114###\n",
            "###Batch: 0: train loss= 0.0283, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0091, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0211, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0163, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 115###\n",
            "###Batch: 0: train loss= 0.0258, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0071, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0243, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0155, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 116###\n",
            "###Batch: 0: train loss= 0.0266, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0141, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0239, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0257, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 117###\n",
            "###Batch: 0: train loss= 0.0249, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0113, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0201, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0229, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 118###\n",
            "###Batch: 0: train loss= 0.0300, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0085, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0198, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0216, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 119###\n",
            "###Batch: 0: train loss= 0.0318, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0219, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0349, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0303, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 120###\n",
            "###Batch: 0: train loss= 0.0312, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0080, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0262, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0198, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 121###\n",
            "###Batch: 0: train loss= 0.0301, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0089, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0206, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0123, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 122###\n",
            "###Batch: 0: train loss= 0.0277, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0086, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0180, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0198, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 123###\n",
            "###Batch: 0: train loss= 0.0256, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0131, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0192, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0131, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 124###\n",
            "###Batch: 0: train loss= 0.0236, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0072, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0177, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0110, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 125###\n",
            "###Batch: 0: train loss= 0.0269, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0071, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0167, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0128, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 126###\n",
            "###Batch: 0: train loss= 0.0230, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0068, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0189, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0188, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 127###\n",
            "###Batch: 0: train loss= 0.0218, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0081, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0172, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0119, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 128###\n",
            "###Batch: 0: train loss= 0.0239, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0061, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0142, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0175, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 129###\n",
            "###Batch: 0: train loss= 0.0233, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0081, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0137, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0164, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 130###\n",
            "###Batch: 0: train loss= 0.0268, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0125, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0234, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0259, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 131###\n",
            "###Batch: 0: train loss= 0.0252, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0049, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0184, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0179, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 132###\n",
            "###Batch: 0: train loss= 0.0265, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0122, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0195, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0114, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 133###\n",
            "###Batch: 0: train loss= 0.0209, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0093, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0176, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0111, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 134###\n",
            "###Batch: 0: train loss= 0.0236, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0063, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0174, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0100, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 135###\n",
            "###Batch: 0: train loss= 0.0201, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0069, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0138, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0075, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 136###\n",
            "###Batch: 0: train loss= 0.0219, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0062, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0127, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0088, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 137###\n",
            "###Batch: 0: train loss= 0.0201, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0060, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0166, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0069, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 138###\n",
            "###Batch: 0: train loss= 0.0206, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0072, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0182, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0305, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 139###\n",
            "###Batch: 0: train loss= 0.0247, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0090, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0115, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0104, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 140###\n",
            "###Batch: 0: train loss= 0.0224, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0064, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0067, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0054, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 141###\n",
            "###Batch: 0: train loss= 0.0181, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0064, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0063, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0087, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 142###\n",
            "###Batch: 0: train loss= 0.0206, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0133, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0048, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0114, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 143###\n",
            "###Batch: 0: train loss= 0.0354, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0125, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0157, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0133, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 144###\n",
            "###Batch: 0: train loss= 0.0201, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0212, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0260, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0142, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 145###\n",
            "###Batch: 0: train loss= 0.0203, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0062, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0156, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0110, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 146###\n",
            "###Batch: 0: train loss= 0.0207, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0046, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0055, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0084, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 147###\n",
            "###Batch: 0: train loss= 0.0178, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0060, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0041, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0119, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 148###\n",
            "###Batch: 0: train loss= 0.0162, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0053, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0043, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0056, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 149###\n",
            "###Batch: 0: train loss= 0.0166, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0062, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0038, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0096, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 150###\n",
            "###Batch: 0: train loss= 0.0129, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0077, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0157, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0079, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 151###\n",
            "###Batch: 0: train loss= 0.0174, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0062, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0033, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0062, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 152###\n",
            "###Batch: 0: train loss= 0.0157, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0046, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0033, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0059, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 153###\n",
            "###Batch: 0: train loss= 0.0143, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0036, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0042, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0040, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 154###\n",
            "###Batch: 0: train loss= 0.0157, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0059, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0027, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0073, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 155###\n",
            "###Batch: 0: train loss= 0.0152, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0036, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0039, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0116, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 156###\n",
            "###Batch: 0: train loss= 0.0146, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0059, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0244, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0350, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 157###\n",
            "###Batch: 0: train loss= 0.0169, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0087, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0178, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0202, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 158###\n",
            "###Batch: 0: train loss= 0.0172, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0062, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0047, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0081, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 159###\n",
            "###Batch: 0: train loss= 0.0160, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0032, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0032, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0056, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 160###\n",
            "###Batch: 0: train loss= 0.0129, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0049, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0058, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0046, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 161###\n",
            "###Batch: 0: train loss= 0.0108, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0057, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0023, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0033, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 162###\n",
            "###Batch: 0: train loss= 0.0115, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0066, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0028, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0049, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 163###\n",
            "###Batch: 0: train loss= 0.0120, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0040, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0035, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0066, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 164###\n",
            "###Batch: 0: train loss= 0.0124, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0065, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0023, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0092, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 165###\n",
            "###Batch: 0: train loss= 0.0132, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0062, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0034, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0137, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 166###\n",
            "###Batch: 0: train loss= 0.0105, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0119, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0154, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0194, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 167###\n",
            "###Batch: 0: train loss= 0.0168, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0078, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0046, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0121, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 168###\n",
            "###Batch: 0: train loss= 0.0196, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0079, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0058, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0150, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 169###\n",
            "###Batch: 0: train loss= 0.0122, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0071, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0053, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0106, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 170###\n",
            "###Batch: 0: train loss= 0.0128, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0031, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0030, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0041, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 171###\n",
            "###Batch: 0: train loss= 0.0120, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0053, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0033, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0106, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 172###\n",
            "###Batch: 0: train loss= 0.0091, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0043, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0019, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0026, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 173###\n",
            "###Batch: 0: train loss= 0.0094, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0049, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0027, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0026, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 174###\n",
            "###Batch: 0: train loss= 0.0079, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0042, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0024, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0042, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 175###\n",
            "###Batch: 0: train loss= 0.0094, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0036, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0032, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0025, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 176###\n",
            "###Batch: 0: train loss= 0.0079, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0037, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0067, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0030, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 177###\n",
            "###Batch: 0: train loss= 0.0152, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0055, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0030, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0067, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 178###\n",
            "###Batch: 0: train loss= 0.0135, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0028, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0026, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0068, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 179###\n",
            "###Batch: 0: train loss= 0.0072, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0039, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0034, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0061, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 180###\n",
            "###Batch: 0: train loss= 0.0108, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0047, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0044, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0110, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 181###\n",
            "###Batch: 0: train loss= 0.0102, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0038, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0025, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0033, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 182###\n",
            "###Batch: 0: train loss= 0.0110, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0022, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0048, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0018, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 183###\n",
            "###Batch: 0: train loss= 0.0087, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0122, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0062, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0052, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 184###\n",
            "###Batch: 0: train loss= 0.0106, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0027, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0041, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0061, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 185###\n",
            "###Batch: 0: train loss= 0.0086, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0035, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0046, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0048, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 186###\n",
            "###Batch: 0: train loss= 0.0082, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0025, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0033, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0036, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 187###\n",
            "###Batch: 0: train loss= 0.0087, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0015, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0039, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0039, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 188###\n",
            "###Batch: 0: train loss= 0.0067, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0017, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0026, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0034, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 189###\n",
            "###Batch: 0: train loss= 0.0089, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0028, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0056, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0088, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 190###\n",
            "###Batch: 0: train loss= 0.0074, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0030, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0032, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0074, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 191###\n",
            "###Batch: 0: train loss= 0.0075, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0022, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0055, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0098, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 192###\n",
            "###Batch: 0: train loss= 0.0097, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0041, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0035, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0040, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 193###\n",
            "###Batch: 0: train loss= 0.0087, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0024, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0031, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0035, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 194###\n",
            "###Batch: 0: train loss= 0.0129, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0023, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0266, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0044, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 195###\n",
            "###Batch: 0: train loss= 0.0084, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0048, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0045, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0039, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 196###\n",
            "###Batch: 0: train loss= 0.0087, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0022, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0022, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0033, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 197###\n",
            "###Batch: 0: train loss= 0.0099, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0036, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0026, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0036, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 198###\n",
            "###Batch: 0: train loss= 0.0090, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0024, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0017, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0023, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 199###\n",
            "###Batch: 0: train loss= 0.0094, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0030, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0032, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0023, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 200###\n",
            "###Batch: 0: train loss= 0.0103, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0039, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0031, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0075, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 201###\n",
            "###Batch: 0: train loss= 0.0076, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0029, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0029, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0019, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 202###\n",
            "###Batch: 0: train loss= 0.0073, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0030, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0015, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0019, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 203###\n",
            "###Batch: 0: train loss= 0.0079, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0021, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0031, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0022, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 204###\n",
            "###Batch: 0: train loss= 0.0075, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0010, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0042, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0031, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 205###\n",
            "###Batch: 0: train loss= 0.0092, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0027, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0033, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0046, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 206###\n",
            "###Batch: 0: train loss= 0.0098, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0012, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0033, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0054, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 207###\n",
            "###Batch: 0: train loss= 0.0076, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0032, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0049, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0088, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 208###\n",
            "###Batch: 0: train loss= 0.0227, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0024, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0030, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0069, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 209###\n",
            "###Batch: 0: train loss= 0.0091, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0064, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0023, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0023, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 210###\n",
            "###Batch: 0: train loss= 0.0069, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0014, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0033, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0017, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 211###\n",
            "###Batch: 0: train loss= 0.0071, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0013, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0021, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0020, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 212###\n",
            "###Batch: 0: train loss= 0.0064, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0009, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0020, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0019, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 213###\n",
            "###Batch: 0: train loss= 0.0071, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0007, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0030, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0015, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 214###\n",
            "###Batch: 0: train loss= 0.0084, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0013, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0041, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0031, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 215###\n",
            "###Batch: 0: train loss= 0.0077, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0020, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0057, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0249, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 216###\n",
            "###Batch: 0: train loss= 0.0166, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0175, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0068, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0285, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 217###\n",
            "###Batch: 0: train loss= 0.0119, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0183, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0202, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0099, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 218###\n",
            "###Batch: 0: train loss= 0.0097, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0037, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0064, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0055, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 219###\n",
            "###Batch: 0: train loss= 0.0099, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0020, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0028, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0014, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 220###\n",
            "###Batch: 0: train loss= 0.0067, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0010, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0024, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0022, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 221###\n",
            "###Batch: 0: train loss= 0.0067, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0012, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0028, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0012, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 222###\n",
            "###Batch: 0: train loss= 0.0067, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0002, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0020, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0010, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 223###\n",
            "###Batch: 0: train loss= 0.0066, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0005, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0027, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0022, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 224###\n",
            "###Batch: 0: train loss= 0.0069, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0009, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0025, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0018, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 225###\n",
            "###Batch: 0: train loss= 0.0078, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0014, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0024, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0012, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 226###\n",
            "###Batch: 0: train loss= 0.0067, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0005, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0030, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0015, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 227###\n",
            "###Batch: 0: train loss= 0.0068, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0006, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0022, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0009, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 228###\n",
            "###Batch: 0: train loss= 0.0074, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0009, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0038, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0017, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 229###\n",
            "###Batch: 0: train loss= 0.0074, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0029, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0032, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0020, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 230###\n",
            "###Batch: 0: train loss= 0.0085, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0011, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0024, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0019, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 231###\n",
            "###Batch: 0: train loss= 0.0078, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0015, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0023, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0019, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 232###\n",
            "###Batch: 0: train loss= 0.0075, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0016, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0020, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0398, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 233###\n",
            "###Batch: 0: train loss= 0.0083, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0098, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0040, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0255, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 234###\n",
            "###Batch: 0: train loss= 0.0079, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0029, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0024, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0037, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 235###\n",
            "###Batch: 0: train loss= 0.0089, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0019, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0045, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0026, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 236###\n",
            "###Batch: 0: train loss= 0.0082, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0011, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0038, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0030, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 237###\n",
            "###Batch: 0: train loss= 0.0071, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0005, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0038, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0022, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 238###\n",
            "###Batch: 0: train loss= 0.0066, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0006, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0017, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0019, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###epoch: 239###\n",
            "###Batch: 0: train loss= 0.0067, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 10: train loss= 0.0015, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 20: train loss= 0.0015, Acc=0.98\n",
            "Test Acc=0.98\n",
            "###Batch: 30: train loss= 0.0011, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 240###\n",
            "###Batch: 0: train loss= 0.0075, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 241###\n",
            "###Batch: 0: train loss= 0.0066, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 242###\n",
            "###Batch: 0: train loss= 0.0066, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 243###\n",
            "###Batch: 0: train loss= 0.0065, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 244###\n",
            "###Batch: 0: train loss= 0.0065, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 245###\n",
            "###Batch: 0: train loss= 0.0066, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 246###\n",
            "###Batch: 0: train loss= 0.0066, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 247###\n",
            "###Batch: 0: train loss= 0.0066, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 248###\n",
            "###Batch: 0: train loss= 0.0066, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 249###\n",
            "###Batch: 0: train loss= 0.0066, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 250###\n",
            "###Batch: 0: train loss= 0.0065, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 251###\n",
            "###Batch: 0: train loss= 0.0065, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 252###\n",
            "###Batch: 0: train loss= 0.0065, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 253###\n",
            "###Batch: 0: train loss= 0.0064, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 254###\n",
            "###Batch: 0: train loss= 0.0064, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 255###\n",
            "###Batch: 0: train loss= 0.0064, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 256###\n",
            "###Batch: 0: train loss= 0.0064, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 257###\n",
            "###Batch: 0: train loss= 0.0064, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 258###\n",
            "###Batch: 0: train loss= 0.0064, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 259###\n",
            "###Batch: 0: train loss= 0.0064, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 260###\n",
            "###Batch: 0: train loss= 0.0064, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 261###\n",
            "###Batch: 0: train loss= 0.0064, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 262###\n",
            "###Batch: 0: train loss= 0.0064, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 263###\n",
            "###Batch: 0: train loss= 0.0064, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 264###\n",
            "###Batch: 0: train loss= 0.0064, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 265###\n",
            "###Batch: 0: train loss= 0.0064, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 266###\n",
            "###Batch: 0: train loss= 0.0064, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 267###\n",
            "###Batch: 0: train loss= 0.0064, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 268###\n",
            "###Batch: 0: train loss= 0.0064, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 269###\n",
            "###Batch: 0: train loss= 0.0064, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 270###\n",
            "###Batch: 0: train loss= 0.0064, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 271###\n",
            "###Batch: 0: train loss= 0.0064, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 272###\n",
            "###Batch: 0: train loss= 0.0064, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 273###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 274###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 275###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 276###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 277###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 278###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 279###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 280###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 281###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 282###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 283###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 284###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 285###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 286###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 287###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 288###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 289###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 290###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 291###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 292###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 293###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 294###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 295###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 296###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 297###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 298###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 299###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 300###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 301###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 302###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 303###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 304###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 305###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 306###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 307###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 308###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 309###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 310###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 311###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 312###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 313###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 314###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 315###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 316###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 317###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 318###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 319###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 320###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 321###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 322###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 323###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 324###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 325###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 326###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 327###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 328###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 329###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 330###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 331###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 332###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 333###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 334###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 335###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 336###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 337###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 338###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 339###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 340###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 341###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 342###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 343###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 344###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 345###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 346###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 347###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 348###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 349###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 350###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 351###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 352###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 353###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 354###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 355###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 356###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 357###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 358###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 359###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 360###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 361###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 362###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 363###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 364###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 365###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 366###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 367###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 368###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 369###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 370###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 371###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 372###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 373###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 374###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 375###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 376###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 377###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 378###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 379###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 380###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 381###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 382###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 383###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 384###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 385###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 386###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 387###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 388###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 389###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 390###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 391###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 392###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 393###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 394###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 395###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 396###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 397###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 398###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 399###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 400###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 401###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 402###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 403###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 404###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 405###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 406###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 407###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 408###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 409###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 410###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 411###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 412###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 413###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 414###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 415###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 416###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 417###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 418###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 419###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 420###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 421###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 422###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 423###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 424###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 425###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 426###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 427###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 428###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 429###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 430###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 431###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 432###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 433###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 434###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 435###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 436###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 437###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 438###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 439###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 440###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 441###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 442###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 443###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 444###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 445###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 446###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 447###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 448###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 449###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 450###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 451###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 452###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 453###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 454###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 455###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 456###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 457###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 458###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 459###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 460###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 461###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 462###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 463###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 464###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 465###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 466###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 467###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 468###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 469###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 470###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 471###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 472###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 473###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 474###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 475###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 476###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 477###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 478###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 479###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 480###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 481###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 482###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 483###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 484###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 485###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 486###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 487###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 488###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 489###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 490###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 491###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 492###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 493###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 494###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 495###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 496###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 497###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 498###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 499###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 500###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 501###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 502###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 503###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 504###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 505###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 506###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 507###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 508###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 509###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 510###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 511###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 512###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 513###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 514###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 515###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 516###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 517###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 518###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 519###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 520###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 521###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 522###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 523###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 524###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 525###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 526###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 527###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 528###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 529###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 530###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 531###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 532###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 533###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 534###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 535###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 536###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 537###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 538###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 539###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 540###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 541###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 542###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 543###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 544###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 545###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 546###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 547###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 548###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 549###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 550###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 551###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 552###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 553###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 554###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 555###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 556###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 557###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 558###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 559###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 560###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 561###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 562###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 563###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 564###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 565###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 566###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 567###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 568###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 569###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 570###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 571###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 572###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 573###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 574###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 575###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 576###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 577###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 578###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 579###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 580###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 581###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 582###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 583###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 584###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 585###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 586###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 587###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 588###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 589###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 590###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 591###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 592###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 593###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 594###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 595###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 596###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 597###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 598###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 599###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 600###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 601###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 602###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 603###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 604###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 605###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 606###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 607###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 608###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 609###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 610###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 611###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 612###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 613###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 614###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 615###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 616###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 617###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 618###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 619###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 620###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 621###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 622###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 623###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 624###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 625###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 626###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 627###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 628###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 629###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 630###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 631###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 632###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 633###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 634###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 635###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 636###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 637###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 638###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 639###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 640###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 641###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 642###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 643###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 644###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 645###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 646###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 647###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 648###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 649###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 650###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 651###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 652###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 653###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 654###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 655###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 656###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 657###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 658###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 659###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 660###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 661###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 662###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 663###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 664###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 665###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 666###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 667###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 668###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 669###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 670###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 671###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 672###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 673###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 674###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 675###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 676###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 677###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 678###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 679###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 680###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 681###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 682###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 683###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 684###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 685###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 686###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 687###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 688###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 689###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 690###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 691###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 692###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 693###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 694###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 695###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 696###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 697###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 698###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 699###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 700###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 701###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 702###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 703###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 704###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 705###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 706###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 707###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 708###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 709###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 710###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 711###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 712###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 713###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 714###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 715###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 716###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 717###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 718###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 719###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 720###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 721###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 722###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 723###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 724###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 725###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 726###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 727###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 728###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 729###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 730###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 731###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 732###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 733###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 734###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 735###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 736###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 737###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 738###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 739###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 740###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 741###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 742###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 743###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 744###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 745###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 746###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 747###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 748###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 749###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 750###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 751###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 752###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 753###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 754###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 755###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 756###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 757###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 758###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 759###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 760###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 761###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 762###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 763###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 764###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 765###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 766###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 767###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 768###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 769###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 770###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 771###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 772###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 773###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 774###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 775###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 776###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 777###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 778###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 779###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 780###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 781###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 782###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 783###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 784###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 785###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 786###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 787###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 788###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 789###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 790###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 791###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 792###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 793###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 794###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 795###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 796###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 797###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 798###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 799###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 800###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 801###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 802###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 803###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 804###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 805###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 806###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 807###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 808###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 809###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 810###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 811###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 812###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 813###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 814###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 815###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 816###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 817###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 818###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 819###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 820###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 821###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 822###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 823###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 824###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 825###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 826###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 827###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 828###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 829###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 830###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 831###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 832###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 833###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 834###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 835###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 836###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 837###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 838###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 839###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 840###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 841###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 842###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 843###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 844###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 845###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 846###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 847###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 848###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 849###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 850###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 851###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 852###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 853###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 854###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 855###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 856###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 857###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 858###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 859###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 860###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 861###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 862###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 863###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 864###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 865###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 866###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 867###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 868###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 869###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 870###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 871###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 872###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 873###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 874###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 875###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 876###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 877###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 878###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 879###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 880###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 881###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 882###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 883###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 884###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 885###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 886###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 887###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 888###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 889###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 890###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 891###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 892###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 893###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 894###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 895###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 896###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 897###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 898###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 899###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 900###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 901###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 902###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 903###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 904###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 905###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 906###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 907###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 908###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 909###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 910###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 911###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 912###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 913###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 914###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 915###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 916###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 917###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 918###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 919###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 920###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 921###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 922###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 923###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 924###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 925###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 926###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 927###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 928###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 929###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 930###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 931###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 932###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 933###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 934###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 935###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 936###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 937###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 938###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 939###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 940###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 941###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 942###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 943###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 944###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 945###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 946###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 947###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 948###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 949###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 950###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 951###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 952###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 953###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 954###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 955###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 956###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 957###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 958###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 959###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 960###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 961###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 962###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 963###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 964###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 965###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 966###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 967###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 968###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 969###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 970###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 971###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 972###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 973###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 974###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 975###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 976###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 977###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 978###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 979###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 980###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 981###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 982###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 983###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 984###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 985###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 986###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 987###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 988###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 989###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 990###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 991###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 992###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 993###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 994###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 995###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 996###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 997###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 998###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 999###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1000###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1001###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1002###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1003###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1004###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1005###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1006###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1007###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1008###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1009###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1010###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1011###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1012###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1013###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1014###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1015###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1016###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1017###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1018###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1019###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1020###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1021###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1022###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1023###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1024###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1025###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1026###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1027###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1028###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1029###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1030###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1031###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1032###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1033###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1034###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1035###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1036###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1037###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1038###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1039###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1040###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1041###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1042###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1043###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1044###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1045###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1046###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1047###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1048###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1049###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1050###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1051###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1052###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1053###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1054###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1055###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1056###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1057###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1058###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1059###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1060###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1061###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1062###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1063###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1064###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1065###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1066###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1067###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1068###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1069###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1070###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1071###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1072###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1073###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1074###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1075###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1076###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1077###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1078###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1079###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1080###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1081###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1082###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1083###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1084###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1085###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1086###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1087###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1088###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1089###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1090###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1091###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1092###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1093###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1094###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1095###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1096###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1097###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1098###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1099###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1100###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1101###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1102###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1103###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1104###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1105###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1106###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1107###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1108###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1109###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1110###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1111###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1112###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1113###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1114###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1115###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1116###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1117###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1118###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1119###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1120###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1121###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1122###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1123###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1124###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1125###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1126###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1127###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1128###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1129###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1130###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1131###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1132###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1133###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1134###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1135###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1136###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1137###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1138###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1139###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1140###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1141###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1142###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1143###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1144###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1145###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1146###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1147###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1148###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1149###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1150###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1151###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1152###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1153###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1154###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1155###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1156###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1157###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1158###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1159###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1160###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1161###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1162###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1163###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1164###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1165###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1166###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1167###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1168###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1169###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1170###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1171###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1172###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1173###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1174###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1175###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1176###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1177###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1178###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1179###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1180###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1181###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1182###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1183###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1184###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1185###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1186###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1187###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1188###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1189###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1190###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1191###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1192###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1193###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1194###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1195###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1196###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1197###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1198###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1199###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1200###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1201###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1202###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1203###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1204###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1205###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1206###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1207###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1208###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1209###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1210###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1211###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1212###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1213###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1214###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1215###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1216###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1217###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1218###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1219###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1220###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1221###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1222###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1223###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1224###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1225###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1226###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1227###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1228###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1229###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1230###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1231###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1232###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1233###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1234###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1235###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1236###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1237###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1238###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1239###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1240###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1241###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1242###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1243###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1244###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1245###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1246###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1247###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1248###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1249###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1250###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1251###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1252###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1253###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1254###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1255###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1256###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1257###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1258###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1259###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1260###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1261###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1262###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1263###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1264###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1265###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1266###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1267###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1268###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1269###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1270###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1271###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1272###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1273###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1274###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1275###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1276###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1277###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1278###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1279###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1280###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1281###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1282###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1283###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1284###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1285###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1286###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1287###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1288###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1289###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1290###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1291###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1292###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1293###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1294###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1295###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1296###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1297###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1298###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1299###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1300###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1301###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1302###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1303###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1304###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1305###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1306###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1307###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1308###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1309###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1310###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1311###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1312###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1313###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1314###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1315###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1316###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1317###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1318###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1319###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1320###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1321###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1322###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1323###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1324###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1325###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1326###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1327###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1328###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1329###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1330###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1331###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1332###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1333###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1334###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1335###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1336###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1337###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1338###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1339###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1340###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1341###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1342###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1343###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1344###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1345###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1346###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1347###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1348###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1349###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1350###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1351###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1352###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1353###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1354###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1355###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1356###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1357###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1358###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1359###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1360###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1361###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1362###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1363###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1364###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1365###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1366###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1367###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1368###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1369###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1370###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1371###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1372###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1373###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1374###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1375###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1376###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1377###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1378###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1379###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1380###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1381###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1382###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1383###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1384###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1385###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1386###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1387###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1388###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1389###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1390###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1391###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1392###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1393###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1394###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1395###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1396###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1397###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1398###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1399###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1400###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1401###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1402###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1403###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1404###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1405###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1406###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1407###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1408###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1409###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1410###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1411###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1412###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1413###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1414###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1415###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1416###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1417###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1418###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1419###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1420###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1421###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1422###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1423###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1424###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1425###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1426###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1427###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1428###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1429###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1430###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1431###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1432###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1433###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1434###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1435###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1436###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1437###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1438###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1439###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1440###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1441###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1442###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1443###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1444###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1445###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1446###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1447###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1448###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1449###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1450###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1451###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1452###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1453###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1454###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1455###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1456###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1457###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1458###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1459###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1460###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1461###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1462###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1463###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1464###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1465###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1466###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1467###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1468###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1469###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1470###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1471###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1472###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1473###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1474###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1475###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1476###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1477###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1478###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1479###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1480###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1481###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1482###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1483###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1484###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1485###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1486###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1487###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1488###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1489###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1490###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1491###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1492###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1493###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1494###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1495###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1496###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1497###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1498###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1499###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1500###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1501###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1502###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1503###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1504###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1505###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1506###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1507###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1508###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1509###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1510###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1511###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1512###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1513###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1514###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1515###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1516###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1517###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1518###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1519###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1520###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1521###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1522###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1523###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1524###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1525###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1526###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1527###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1528###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1529###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1530###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1531###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1532###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1533###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1534###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1535###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1536###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1537###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1538###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1539###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1540###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1541###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1542###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1543###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1544###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1545###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1546###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1547###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1548###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1549###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1550###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1551###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1552###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1553###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1554###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1555###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1556###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1557###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1558###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1559###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1560###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1561###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1562###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1563###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1564###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1565###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1566###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1567###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1568###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1569###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1570###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1571###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1572###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1573###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1574###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1575###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1576###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1577###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1578###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1579###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1580###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1581###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1582###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1583###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1584###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1585###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1586###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1587###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1588###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1589###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1590###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1591###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1592###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1593###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1594###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1595###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1596###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1597###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1598###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1599###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1600###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1601###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1602###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1603###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1604###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1605###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1606###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1607###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1608###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1609###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1610###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1611###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1612###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1613###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1614###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1615###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1616###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1617###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1618###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1619###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1620###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1621###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1622###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1623###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1624###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1625###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1626###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1627###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1628###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1629###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1630###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1631###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1632###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1633###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1634###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1635###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1636###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1637###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1638###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1639###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1640###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1641###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1642###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1643###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1644###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1645###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1646###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1647###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1648###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1649###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1650###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1651###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1652###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1653###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1654###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1655###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1656###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1657###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1658###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1659###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1660###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1661###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1662###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1663###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1664###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1665###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1666###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1667###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1668###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1669###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1670###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1671###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1672###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1673###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1674###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1675###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1676###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1677###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1678###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1679###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1680###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1681###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1682###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1683###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1684###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1685###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1686###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1687###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1688###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1689###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1690###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1691###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1692###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1693###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1694###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1695###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1696###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1697###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1698###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1699###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1700###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1701###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1702###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1703###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1704###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1705###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1706###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1707###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1708###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1709###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1710###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1711###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1712###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1713###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1714###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1715###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1716###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1717###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1718###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1719###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1720###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1721###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1722###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1723###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1724###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1725###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1726###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1727###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1728###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1729###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1730###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1731###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1732###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1733###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1734###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1735###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1736###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1737###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1738###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1739###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1740###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1741###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1742###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1743###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1744###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1745###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1746###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1747###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1748###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1749###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1750###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1751###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1752###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1753###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1754###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1755###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1756###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1757###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1758###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1759###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1760###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1761###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1762###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1763###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1764###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1765###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1766###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1767###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1768###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1769###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1770###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1771###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1772###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1773###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1774###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1775###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1776###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1777###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1778###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1779###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1780###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1781###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1782###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1783###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1784###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1785###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1786###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1787###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1788###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1789###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1790###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1791###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1792###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1793###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1794###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1795###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1796###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1797###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1798###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1799###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1800###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1801###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1802###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1803###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1804###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1805###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1806###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1807###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1808###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1809###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1810###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1811###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1812###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1813###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1814###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1815###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1816###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1817###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1818###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1819###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1820###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1821###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1822###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1823###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1824###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1825###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1826###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1827###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1828###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1829###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1830###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1831###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1832###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1833###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1834###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1835###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1836###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1837###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1838###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1839###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1840###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1841###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1842###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1843###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1844###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1845###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1846###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1847###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1848###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1849###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1850###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1851###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1852###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1853###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1854###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1855###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1856###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1857###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1858###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1859###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1860###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1861###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1862###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1863###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1864###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1865###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1866###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1867###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1868###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1869###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1870###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1871###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1872###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1873###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1874###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1875###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1876###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1877###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1878###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1879###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1880###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1881###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1882###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1883###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1884###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1885###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1886###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1887###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1888###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1889###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1890###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1891###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1892###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1893###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1894###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1895###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1896###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1897###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1898###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1899###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1900###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1901###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1902###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1903###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1904###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1905###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1906###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1907###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1908###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1909###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1910###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1911###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1912###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1913###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1914###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1915###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1916###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1917###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1918###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1919###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1920###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1921###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1922###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1923###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1924###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1925###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1926###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1927###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1928###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1929###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1930###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1931###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1932###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1933###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1934###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1935###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1936###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1937###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1938###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1939###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1940###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1941###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1942###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1943###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1944###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1945###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1946###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1947###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1948###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1949###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1950###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1951###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1952###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1953###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1954###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1955###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1956###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1957###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1958###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1959###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1960###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1961###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1962###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1963###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1964###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1965###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1966###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1967###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1968###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1969###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1970###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1971###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1972###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1973###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1974###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1975###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1976###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1977###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1978###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1979###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1980###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1981###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1982###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1983###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1984###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1985###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1986###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1987###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1988###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1989###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1990###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1991###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1992###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1993###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1994###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1995###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1996###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1997###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1998###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 1999###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2000###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2001###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2002###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2003###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2004###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2005###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2006###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2007###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2008###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2009###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2010###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2011###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2012###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2013###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2014###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2015###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2016###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2017###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2018###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2019###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2020###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2021###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2022###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2023###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2024###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2025###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2026###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2027###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2028###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2029###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2030###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2031###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2032###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2033###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2034###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2035###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2036###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2037###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2038###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2039###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2040###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2041###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2042###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2043###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2044###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2045###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2046###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2047###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2048###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2049###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2050###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2051###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2052###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2053###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2054###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2055###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2056###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2057###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2058###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2059###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2060###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2061###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2062###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2063###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2064###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2065###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2066###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2067###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2068###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2069###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2070###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2071###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2072###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2073###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2074###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2075###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2076###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2077###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2078###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2079###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2080###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2081###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2082###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2083###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2084###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2085###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2086###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2087###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2088###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2089###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2090###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2091###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2092###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2093###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2094###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2095###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2096###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2097###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2098###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2099###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2100###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2101###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2102###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2103###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2104###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2105###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2106###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2107###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2108###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2109###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2110###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2111###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2112###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2113###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2114###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2115###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2116###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2117###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2118###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2119###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2120###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2121###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2122###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2123###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2124###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2125###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2126###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2127###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2128###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2129###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2130###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2131###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2132###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2133###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2134###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2135###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2136###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2137###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2138###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2139###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2140###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2141###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2142###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2143###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2144###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2145###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2146###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2147###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2148###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2149###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2150###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2151###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2152###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2153###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2154###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2155###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2156###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2157###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2158###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2159###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2160###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2161###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2162###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2163###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2164###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2165###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2166###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2167###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2168###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2169###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2170###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2171###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2172###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2173###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2174###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2175###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2176###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2177###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2178###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2179###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2180###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2181###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2182###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2183###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2184###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2185###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2186###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2187###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2188###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2189###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2190###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2191###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2192###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2193###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2194###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2195###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2196###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2197###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2198###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2199###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2200###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2201###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2202###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2203###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2204###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2205###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2206###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2207###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2208###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2209###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2210###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2211###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2212###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2213###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2214###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2215###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2216###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2217###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2218###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2219###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2220###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2221###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2222###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2223###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2224###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2225###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2226###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2227###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2228###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2229###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2230###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2231###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2232###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2233###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2234###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2235###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2236###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2237###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2238###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2239###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2240###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2241###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2242###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2243###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2244###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2245###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2246###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2247###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2248###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2249###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2250###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2251###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2252###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2253###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2254###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2255###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2256###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2257###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2258###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2259###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2260###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2261###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2262###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2263###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2264###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2265###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2266###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2267###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2268###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2269###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2270###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2271###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2272###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2273###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2274###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2275###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2276###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2277###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2278###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2279###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2280###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2281###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2282###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2283###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2284###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2285###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2286###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2287###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2288###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2289###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2290###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2291###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2292###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2293###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2294###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2295###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2296###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2297###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2298###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2299###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2300###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2301###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2302###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2303###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2304###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2305###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2306###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2307###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2308###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2309###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2310###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2311###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2312###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2313###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2314###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2315###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2316###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2317###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2318###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2319###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2320###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2321###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2322###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2323###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2324###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2325###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2326###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2327###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2328###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2329###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2330###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2331###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2332###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2333###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2334###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2335###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2336###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2337###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2338###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2339###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2340###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2341###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2342###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2343###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2344###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2345###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2346###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2347###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2348###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2349###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2350###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2351###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2352###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2353###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2354###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2355###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2356###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2357###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2358###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2359###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2360###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2361###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2362###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2363###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2364###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2365###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2366###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2367###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2368###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2369###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2370###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2371###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2372###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2373###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2374###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2375###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2376###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2377###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2378###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2379###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2380###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2381###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2382###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2383###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2384###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2385###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2386###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2387###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2388###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2389###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2390###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2391###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2392###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2393###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2394###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2395###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2396###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2397###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2398###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2399###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2400###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2401###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2402###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2403###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2404###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2405###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2406###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2407###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2408###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2409###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2410###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2411###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2412###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2413###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2414###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2415###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2416###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2417###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2418###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2419###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2420###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2421###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2422###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2423###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2424###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2425###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2426###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2427###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2428###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2429###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2430###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2431###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2432###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2433###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2434###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2435###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2436###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2437###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2438###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2439###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2440###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2441###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2442###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2443###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2444###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2445###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2446###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2447###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2448###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2449###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2450###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2451###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2452###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2453###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2454###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2455###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2456###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2457###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2458###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2459###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2460###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2461###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2462###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2463###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2464###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2465###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2466###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2467###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2468###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2469###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2470###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2471###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2472###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2473###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2474###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2475###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2476###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2477###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2478###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2479###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2480###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2481###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2482###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2483###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2484###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2485###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2486###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2487###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2488###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2489###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2490###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2491###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2492###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2493###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2494###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2495###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2496###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2497###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2498###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2499###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2500###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2501###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2502###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2503###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2504###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2505###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2506###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2507###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2508###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2509###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2510###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2511###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2512###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2513###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2514###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2515###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2516###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2517###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2518###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2519###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2520###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2521###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2522###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2523###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2524###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2525###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2526###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2527###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2528###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2529###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2530###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2531###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2532###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2533###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2534###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2535###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2536###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2537###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2538###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2539###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2540###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2541###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2542###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2543###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2544###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2545###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2546###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2547###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2548###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2549###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2550###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2551###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2552###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2553###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2554###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2555###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2556###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2557###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2558###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2559###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2560###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2561###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2562###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2563###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2564###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2565###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2566###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2567###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2568###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2569###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2570###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2571###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2572###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2573###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2574###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2575###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2576###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2577###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2578###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2579###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2580###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2581###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2582###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2583###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2584###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2585###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2586###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2587###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2588###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2589###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2590###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2591###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2592###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2593###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2594###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2595###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2596###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2597###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2598###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2599###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2600###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2601###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2602###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2603###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2604###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2605###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2606###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2607###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2608###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2609###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2610###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2611###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2612###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2613###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2614###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2615###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2616###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2617###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2618###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2619###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2620###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2621###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2622###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2623###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2624###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2625###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2626###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2627###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2628###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2629###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2630###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2631###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2632###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2633###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2634###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2635###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2636###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2637###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2638###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2639###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2640###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2641###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2642###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2643###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2644###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2645###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2646###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2647###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2648###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2649###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2650###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2651###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2652###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2653###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2654###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2655###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2656###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2657###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2658###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2659###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2660###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2661###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2662###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2663###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2664###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2665###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2666###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2667###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2668###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2669###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2670###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2671###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2672###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2673###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2674###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2675###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2676###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2677###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2678###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2679###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2680###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2681###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2682###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2683###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2684###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2685###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2686###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2687###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2688###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2689###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2690###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2691###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2692###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2693###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2694###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2695###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2696###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2697###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2698###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2699###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2700###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2701###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2702###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2703###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2704###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2705###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2706###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2707###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2708###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2709###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2710###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2711###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2712###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2713###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2714###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2715###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2716###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2717###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2718###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2719###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2720###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2721###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2722###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2723###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2724###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2725###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2726###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2727###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2728###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2729###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2730###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2731###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2732###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2733###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2734###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2735###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2736###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2737###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2738###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2739###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2740###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2741###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2742###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2743###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2744###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2745###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2746###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2747###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2748###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2749###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2750###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2751###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2752###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2753###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2754###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2755###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2756###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2757###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2758###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2759###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2760###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2761###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2762###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2763###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2764###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2765###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2766###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2767###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2768###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2769###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2770###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2771###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2772###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2773###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2774###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2775###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2776###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2777###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2778###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2779###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2780###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2781###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2782###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2783###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2784###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2785###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2786###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2787###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2788###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2789###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2790###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2791###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2792###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2793###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2794###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2795###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2796###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2797###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2798###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2799###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2800###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2801###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2802###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2803###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2804###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2805###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2806###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2807###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2808###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2809###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2810###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2811###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2812###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2813###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2814###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2815###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2816###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2817###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2818###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2819###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2820###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2821###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2822###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2823###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2824###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2825###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2826###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2827###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2828###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2829###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2830###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2831###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2832###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2833###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2834###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2835###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2836###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2837###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2838###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2839###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2840###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2841###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2842###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2843###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2844###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2845###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2846###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2847###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2848###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2849###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2850###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2851###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2852###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2853###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2854###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2855###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2856###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2857###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2858###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2859###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2860###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2861###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2862###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2863###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2864###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2865###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2866###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2867###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2868###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2869###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2870###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2871###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2872###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2873###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2874###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2875###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2876###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2877###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2878###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2879###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2880###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2881###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2882###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2883###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2884###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2885###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2886###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2887###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2888###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2889###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2890###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2891###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2892###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2893###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2894###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2895###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2896###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2897###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2898###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2899###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2900###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2901###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2902###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2903###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2904###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2905###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2906###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2907###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2908###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2909###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2910###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2911###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2912###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2913###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2914###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2915###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2916###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2917###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2918###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2919###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2920###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2921###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2922###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2923###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2924###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2925###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2926###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2927###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2928###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2929###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2930###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2931###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2932###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2933###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2934###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2935###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2936###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2937###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2938###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2939###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2940###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2941###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2942###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2943###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2944###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2945###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2946###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2947###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2948###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2949###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2950###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2951###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2952###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2953###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2954###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2955###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2956###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2957###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2958###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2959###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2960###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2961###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2962###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2963###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2964###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2965###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2966###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2967###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2968###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2969###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2970###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2971###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2972###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2973###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2974###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2975###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2976###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2977###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2978###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2979###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2980###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2981###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2982###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2983###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2984###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2985###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2986###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2987###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2988###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2989###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2990###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2991###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2992###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2993###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2994###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2995###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2996###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2997###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2998###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 2999###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3000###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3001###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3002###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3003###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3004###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3005###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3006###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3007###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3008###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3009###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3010###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3011###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3012###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3013###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3014###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3015###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3016###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3017###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3018###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3019###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3020###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3021###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3022###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3023###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3024###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3025###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3026###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3027###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3028###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3029###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3030###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3031###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3032###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3033###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3034###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3035###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3036###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3037###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3038###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3039###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3040###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3041###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3042###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3043###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3044###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3045###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3046###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3047###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3048###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3049###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3050###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3051###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3052###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3053###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3054###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3055###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3056###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3057###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3058###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3059###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3060###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3061###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3062###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3063###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3064###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3065###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3066###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3067###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3068###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3069###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3070###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3071###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3072###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3073###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3074###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3075###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3076###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3077###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3078###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3079###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3080###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3081###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3082###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3083###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3084###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3085###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3086###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3087###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3088###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3089###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3090###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3091###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3092###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3093###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3094###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3095###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3096###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3097###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3098###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3099###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3100###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3101###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3102###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3103###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3104###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3105###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3106###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3107###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3108###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3109###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3110###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3111###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3112###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3113###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3114###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3115###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3116###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3117###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3118###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3119###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3120###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3121###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3122###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3123###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3124###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3125###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3126###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3127###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3128###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3129###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3130###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3131###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3132###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3133###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3134###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3135###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3136###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3137###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3138###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3139###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3140###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3141###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3142###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3143###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3144###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3145###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3146###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3147###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3148###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3149###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3150###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3151###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3152###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3153###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3154###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3155###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3156###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3157###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3158###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3159###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3160###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3161###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3162###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3163###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3164###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3165###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3166###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3167###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3168###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3169###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3170###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3171###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3172###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3173###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3174###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3175###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3176###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3177###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3178###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3179###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3180###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3181###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3182###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3183###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3184###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3185###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3186###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3187###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3188###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3189###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3190###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3191###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3192###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3193###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3194###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3195###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3196###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3197###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3198###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3199###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3200###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3201###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3202###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3203###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3204###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3205###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3206###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3207###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3208###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3209###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3210###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3211###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3212###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3213###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3214###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3215###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3216###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3217###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3218###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3219###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3220###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3221###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3222###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3223###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3224###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3225###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3226###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3227###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3228###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3229###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3230###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3231###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3232###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3233###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3234###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3235###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3236###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3237###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3238###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3239###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3240###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3241###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3242###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3243###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3244###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3245###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3246###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3247###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3248###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3249###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3250###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3251###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3252###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3253###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3254###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3255###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3256###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3257###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3258###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3259###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3260###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3261###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3262###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3263###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3264###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3265###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3266###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3267###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3268###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3269###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3270###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3271###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3272###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3273###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3274###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3275###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3276###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3277###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3278###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3279###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3280###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3281###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3282###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3283###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3284###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3285###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3286###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3287###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3288###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3289###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3290###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3291###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3292###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3293###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3294###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3295###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3296###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3297###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3298###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3299###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3300###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3301###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3302###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3303###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3304###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3305###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3306###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3307###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3308###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3309###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3310###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3311###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3312###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3313###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3314###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3315###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3316###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3317###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3318###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3319###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3320###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3321###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3322###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3323###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3324###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3325###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3326###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3327###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3328###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3329###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3330###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3331###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3332###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3333###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3334###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3335###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3336###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3337###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3338###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3339###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3340###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3341###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3342###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3343###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3344###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3345###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3346###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3347###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3348###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3349###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3350###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3351###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3352###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3353###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3354###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3355###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3356###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3357###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3358###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3359###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3360###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3361###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3362###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3363###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3364###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3365###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3366###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3367###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3368###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3369###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3370###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3371###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3372###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3373###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3374###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3375###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3376###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3377###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3378###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3379###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3380###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3381###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3382###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3383###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3384###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3385###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3386###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3387###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3388###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3389###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3390###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3391###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3392###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3393###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3394###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3395###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3396###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3397###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3398###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3399###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3400###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3401###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3402###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3403###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3404###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3405###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3406###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3407###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3408###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3409###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3410###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3411###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3412###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3413###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3414###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3415###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3416###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3417###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3418###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3419###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3420###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3421###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3422###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3423###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3424###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3425###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3426###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3427###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3428###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3429###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3430###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3431###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3432###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3433###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3434###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3435###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3436###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3437###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3438###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3439###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3440###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3441###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3442###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3443###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3444###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3445###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3446###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3447###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3448###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3449###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3450###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3451###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3452###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3453###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3454###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3455###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3456###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3457###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3458###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3459###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3460###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3461###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3462###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3463###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3464###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3465###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3466###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3467###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3468###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3469###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3470###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3471###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3472###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3473###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3474###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3475###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3476###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3477###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3478###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3479###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3480###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3481###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3482###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3483###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3484###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3485###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3486###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3487###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3488###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3489###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3490###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3491###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3492###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3493###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3494###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3495###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3496###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3497###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3498###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3499###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3500###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3501###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3502###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3503###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3504###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3505###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3506###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3507###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3508###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3509###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3510###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3511###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3512###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3513###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3514###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3515###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3516###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3517###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3518###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3519###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3520###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3521###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3522###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3523###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3524###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3525###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3526###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3527###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3528###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3529###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3530###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3531###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3532###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3533###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3534###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3535###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3536###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3537###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3538###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3539###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3540###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3541###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3542###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3543###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3544###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3545###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3546###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3547###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3548###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3549###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3550###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3551###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3552###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3553###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3554###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3555###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3556###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3557###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3558###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3559###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3560###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3561###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3562###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3563###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3564###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3565###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3566###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3567###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3568###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3569###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3570###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3571###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3572###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3573###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3574###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3575###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3576###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3577###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3578###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3579###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3580###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3581###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3582###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3583###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3584###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3585###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3586###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3587###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3588###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3589###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3590###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3591###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3592###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3593###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3594###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3595###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3596###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3597###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3598###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3599###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3600###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3601###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3602###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3603###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3604###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3605###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3606###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3607###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3608###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3609###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3610###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3611###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3612###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3613###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3614###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3615###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3616###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3617###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3618###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3619###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3620###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3621###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3622###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3623###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3624###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3625###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3626###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3627###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3628###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3629###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3630###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3631###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3632###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3633###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3634###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3635###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3636###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3637###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3638###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3639###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3640###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3641###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3642###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3643###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3644###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3645###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3646###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3647###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3648###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3649###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3650###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3651###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3652###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3653###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3654###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3655###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3656###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3657###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3658###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3659###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3660###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3661###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3662###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3663###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3664###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3665###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3666###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3667###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3668###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3669###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3670###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3671###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3672###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3673###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3674###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3675###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3676###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3677###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3678###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3679###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3680###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3681###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3682###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3683###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3684###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3685###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3686###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3687###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3688###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3689###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3690###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3691###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3692###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3693###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3694###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3695###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3696###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3697###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3698###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3699###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3700###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3701###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3702###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3703###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3704###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3705###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3706###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3707###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3708###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3709###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3710###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3711###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3712###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3713###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3714###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3715###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3716###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3717###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3718###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3719###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3720###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3721###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3722###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3723###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3724###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3725###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3726###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3727###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3728###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3729###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3730###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3731###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3732###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3733###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3734###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3735###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3736###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3737###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3738###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3739###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3740###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3741###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3742###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3743###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3744###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3745###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3746###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3747###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3748###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3749###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3750###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3751###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3752###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3753###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3754###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3755###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3756###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3757###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3758###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3759###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3760###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3761###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3762###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3763###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3764###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3765###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3766###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3767###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3768###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3769###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3770###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3771###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3772###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3773###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3774###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3775###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3776###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3777###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3778###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3779###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3780###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3781###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3782###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3783###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3784###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3785###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3786###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3787###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3788###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3789###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3790###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3791###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3792###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3793###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3794###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3795###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3796###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3797###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3798###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3799###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3800###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3801###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3802###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3803###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3804###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3805###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3806###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3807###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3808###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3809###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3810###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3811###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3812###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3813###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3814###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3815###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3816###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3817###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3818###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3819###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3820###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3821###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3822###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3823###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3824###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3825###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3826###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3827###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3828###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3829###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3830###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3831###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3832###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3833###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3834###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3835###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3836###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3837###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3838###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3839###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3840###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3841###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3842###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3843###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3844###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3845###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3846###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3847###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3848###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3849###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3850###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3851###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3852###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3853###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3854###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3855###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3856###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3857###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3858###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3859###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3860###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3861###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3862###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3863###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3864###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3865###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3866###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3867###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3868###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3869###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3870###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3871###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3872###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3873###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3874###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3875###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3876###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3877###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3878###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3879###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3880###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3881###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3882###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3883###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3884###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3885###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3886###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3887###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3888###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3889###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3890###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3891###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3892###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3893###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3894###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3895###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3896###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3897###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3898###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3899###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3900###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3901###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3902###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3903###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3904###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3905###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3906###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3907###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3908###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3909###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3910###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3911###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3912###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3913###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3914###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3915###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3916###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3917###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3918###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3919###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3920###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3921###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3922###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3923###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3924###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3925###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3926###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3927###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3928###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3929###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3930###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3931###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3932###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3933###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3934###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3935###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3936###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3937###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3938###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3939###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3940###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3941###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3942###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3943###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3944###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3945###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3946###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3947###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3948###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3949###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3950###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3951###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3952###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3953###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3954###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3955###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3956###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3957###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3958###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3959###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3960###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3961###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3962###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3963###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3964###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3965###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3966###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3967###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3968###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3969###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3970###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3971###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3972###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3973###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3974###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3975###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3976###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3977###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3978###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3979###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3980###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3981###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3982###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3983###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3984###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3985###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3986###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3987###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3988###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3989###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3990###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3991###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3992###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3993###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3994###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3995###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3996###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3997###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3998###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 3999###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4000###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4001###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4002###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4003###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4004###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4005###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4006###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4007###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4008###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4009###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4010###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4011###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4012###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4013###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4014###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4015###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4016###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4017###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4018###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4019###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4020###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4021###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4022###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4023###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4024###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4025###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4026###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4027###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4028###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4029###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4030###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4031###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4032###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4033###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4034###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4035###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4036###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4037###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4038###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4039###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4040###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4041###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4042###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4043###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4044###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4045###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4046###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4047###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4048###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4049###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4050###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4051###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4052###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4053###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4054###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4055###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4056###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4057###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4058###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4059###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4060###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4061###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4062###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4063###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4064###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4065###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4066###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4067###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4068###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4069###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4070###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4071###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4072###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4073###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4074###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4075###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4076###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4077###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4078###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4079###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4080###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4081###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4082###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4083###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4084###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4085###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4086###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4087###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4088###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4089###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4090###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4091###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4092###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4093###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4094###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4095###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4096###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4097###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4098###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4099###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4100###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4101###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4102###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4103###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4104###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4105###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4106###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4107###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4108###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4109###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4110###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4111###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4112###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4113###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4114###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4115###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4116###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4117###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4118###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4119###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4120###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4121###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4122###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4123###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4124###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4125###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4126###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4127###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4128###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4129###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4130###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4131###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4132###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4133###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4134###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4135###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4136###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4137###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4138###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4139###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4140###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4141###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4142###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4143###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4144###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4145###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4146###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4147###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4148###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4149###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4150###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4151###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4152###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4153###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4154###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4155###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4156###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4157###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4158###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4159###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4160###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4161###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4162###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4163###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4164###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4165###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4166###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4167###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4168###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4169###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4170###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4171###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4172###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4173###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4174###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4175###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4176###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4177###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4178###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4179###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4180###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4181###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4182###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4183###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4184###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4185###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4186###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4187###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4188###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4189###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4190###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4191###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4192###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4193###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4194###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4195###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4196###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4197###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4198###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4199###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4200###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4201###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4202###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4203###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4204###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4205###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4206###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4207###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4208###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4209###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4210###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4211###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4212###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4213###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4214###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4215###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4216###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4217###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4218###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4219###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4220###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4221###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4222###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4223###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4224###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4225###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4226###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4227###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4228###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4229###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4230###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4231###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4232###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4233###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4234###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4235###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4236###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4237###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4238###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4239###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4240###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4241###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4242###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4243###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4244###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4245###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4246###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4247###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4248###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4249###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4250###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4251###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4252###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4253###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4254###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4255###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4256###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4257###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4258###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4259###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4260###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4261###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4262###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4263###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4264###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4265###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4266###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4267###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4268###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4269###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4270###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4271###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4272###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4273###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4274###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4275###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4276###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4277###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4278###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4279###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4280###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4281###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4282###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n",
            "###epoch: 4283###\n",
            "###Batch: 0: train loss= 0.0063, Acc=0.99\n",
            "Test Acc=0.99\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-02fd165a7598>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test Acc=%.2f'\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0macc_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0macc_train\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.985\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m               \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"my_net/save_net_rnn.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m               \u001b[0;31m#if acc==1:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m               \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[1;32m   1464\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m           self.export_meta_graph(\n\u001b[0;32m-> 1466\u001b[0;31m               meta_graph_filename, strip_default_attrs=strip_default_attrs)\n\u001b[0m\u001b[1;32m   1467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[0;34m(self, filename, collection_list, as_text, export_scope, clear_devices, clear_extraneous_savers, strip_default_attrs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m         \u001b[0mclear_devices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_devices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0mclear_extraneous_savers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_extraneous_savers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m         strip_default_attrs=strip_default_attrs)\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[0;34m(filename, meta_info_def, graph_def, saver_def, collection_list, as_text, graph, export_scope, clear_devices, clear_extraneous_savers, strip_default_attrs, **kwargs)\u001b[0m\n\u001b[1;32m   1798\u001b[0m       \u001b[0mclear_extraneous_savers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_extraneous_savers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m       \u001b[0mstrip_default_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrip_default_attrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1800\u001b[0;31m       **kwargs)\n\u001b[0m\u001b[1;32m   1801\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/meta_graph.py\u001b[0m in \u001b[0;36mexport_scoped_meta_graph\u001b[0;34m(filename, graph_def, graph, export_scope, as_text, unbound_inputs_col_name, clear_devices, saver_def, clear_extraneous_savers, strip_default_attrs, **kwargs)\u001b[0m\n\u001b[1;32m    998\u001b[0m       \u001b[0msaver_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mstrip_default_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrip_default_attrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m       **kwargs)\n\u001b[0m\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/meta_graph.py\u001b[0m in \u001b[0;36mcreate_meta_graph_def\u001b[0;34m(meta_info_def, graph_def, saver_def, collection_list, graph, export_scope, exclude_nodes, clear_extraneous_savers, strip_default_attrs)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m   \u001b[0;31m# Fills in meta_info_def.stripped_op_list using the ops from graph_def.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "pu5XrEIMNau8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}